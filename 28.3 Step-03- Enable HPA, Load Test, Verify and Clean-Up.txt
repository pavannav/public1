# 28.3 Step-03- Enable HPA, Load Test, Verify and Clean-Up

-: Welcome back.In this step, we are going to create a horizontal podautoscaler resource for our HPA demo deployment.So this command creates an autoscalerthat targets 50% CPU utilization for the deployment.So with the minimum of one pod and a maximum of 10 pods.So when the average CPU load is 50%,the autoscaler tries to reduce the number of podsin their deployment to a minimum of one.When the load is greater than CPU percentage 50,the autoscaler tries to increase the number of podsin the deployment up to maximum of 10.So the template for the command is going to be kubectl,autoscale, deployment, and the deployment name,and the CPU percentage, which is the metricand value is 50% and minimum replica server,and then maximum replicas are 10.So we are going to replace with our information here.The deployment name is HPA demo deployment, right?So if you want, we can crosscheck the same,kubectl get deployed.So whatever we have deployed in our previous step,the same thing, right?So now we are going to use thatand then enable the autoscaling.So let me copy this and paste it.So once the autoscaling is enabled,so we can go ahead and then describe our HPA.So using kubectl,describe HPA/HPA-demo deployment.So let me describe the HPA now.So whatever it is saying is minimum replicas is oneand then maximum replicas is 10.Okay, so now we are goingto get the horizontal pod autoscaler list.Okay, so let me copy thisand then paste it, right?So we have only one autoscaler, which we have implementedand current target is 0% currently.Okay, which means like outta 50%,it is only in 0% usage, okay?So if you want one more time,we can check here the description.So you can see that when you describe it,you get the resource CPU on pod is 0% usedand target is 50%.If it is above 50%, it is going to scale the pods, okay?Two 10 pods max scaling, okay?Currently, it is minimum, one pod.So here also when you describe any resource in Kubernetes,we already know we'll get the events information here, okay?So now you can see it here.All the information related to HPA.The HPA was able to successfully calculate a replica canfrom CPU resource utilization percentage of request.The decide count is within the acceptable range.So like that, we'll be able to see the events alsowhen we describe that respective resource.And current usage is 0%,that's the reason there is no trigger to enable it, okay?To increase the number of pods.So let's go here and then so we can run ApacheBenchto put a load on our http server,which is our engine X server,and this is our engine X URL inside the cluster.So this ApacheBench also will run inside the cluster onlyand then take the cluster IP service off our application,whatever we have deployed, which is HPA demo service.So we can see that.So clear kubectl, get SVC, right?So now you can see HPA demo service engine X.So that is the one.It is going to take it .default.svc.cluster.locallyis the complete DNS name, okay?So we are going to put a lot of loadusing this ApacheBench commandand then see what happens, okay?So let's take this, right?Copy and then paste it.And when it is running, we can go to new taband then also verify the list of HPAand also describe HPA, okay.Let's see what happens, okay.So currently, it is in 0% only.We don't see any issues so far.So we'll try one more time to generate the load.So let's see what happens, okay?So it is trying to generate the load.Earlier, we have seen 38,400 requests completedand then it got deleted automatically.But let's see what happens now, okay?So completed 50,000 requests.And in parallel, we can come hereand then crosscheck the stuff.92% CPU, we can see it here, right?So 92% CPU.Reason is CPU utilizationof the about target is cross it, right?New size, it became two servers, it became.In the same way, we can see 92% is the current sizeand replicas became two instead of one.So we can see that two pods are running here, HPAs,and still the request is generating.So let's see what happens, okay?So we'll try to put the load like this continuouslyand then keep checking, okay?So I can say we have four pods.Now you can see it, right?So automatically, four pods cameand only one pod is six minutes beforewhen we have deployed it,but rest all is latest pods which are spinning up.And one more is we can see continuously the get HPA commandto see 191% of the targets it is using.So if you see the number of pods now,so it got increased, you can see, right?So in the same way, we can also see that described commandto see what's going on in the events.See new size is four.Now the new size is eight, so it keeps increasing.So here that traffic is over,if you want we can still run that traffic one more timeand then keep monitoring our stuff, okay?So from two to four, it became four two again.It doubled to eight and then it's still waiting, okay.Current deployment pods, eightand then decide is eight and max replicas are 10, okay.So let's see what happens now.So let me run it one more time and clear.You'll see it here, get pods.So we can see now eight pods are running.So let's wait for these things to complete.So now it is only at the 30% range, why?Because the number of pods are increased, right?So automatically it is not getting above 50%to get any new pods, okay?So we'll see how it goes, okay?So we are not able to put that much load now, why?Because the requests are distributedacross eight pods, okay?But that's fine.We have seen the overall thing, right?Which means like from one pod to eight pods, it increased.And if you give a five-minute intervalmeans like if no, you can see that now.So it became 116% now,and then from eight current to 10 decide, it became.And then deployment pods also will become 10 pods now.So 10 current two 10 decide.So we reach your maximum number of pods,how much our application can take.It means like we have configured to max 10 replicasand then all those 10 we have got it.Okay, kubectl describe HPA demo deployment.So 10 and CPU resource utilizationis above the target value.So that's about it.So again, what I'm going to dois I'm going to stop this load now, right?And then I'm going to waitfor five to 10 minutes so that it'll cool downand then again bring us back to the single pod.So I'll pause the video until then.So in step six,we'll see the cooldown R scale down behavior.So the default cooldown period is five minutes.So once CPU utilization of pods is less than 50%and then those five minutes has been completed,it will start terminating the podsand will reach to minimum one pod as configured.So let's go ahead and then see the number of pods now,kubectl get pods, and we can see only one pod is running.So let's describe the deploymentand then see what are the events present there, okay?So now if you see the current CPU utilization is 0%,so the target is 50%,so which means the decide is one and current is also one.And if you see the reason here in the message new sizefrom new size ten two,it has changed it to new size one.Reason, all metrics are below this target.So that's the reason it became one.So this is about the horizontal podautoscaler implementation.So we are going to clean up the stuff now.So let's go here and then delete the HPA deployment.So let me clear this and paste itand delete the HPA deploymentand also delete the entirewhatever the manifest we have created, right?So we have deleted the HPA horizontal podautoscaler related configurationand also we are deleting the equaland deployment and then service.So we have cleaned up everything.So one more thing which we need to understandabout the same thing is in the latest versions, right?So as far as now, like Kubernetes 1.16is latest and supportedon elastic Kubernetes service EKS in AWS.But in the real world means like the current live versionof Kubernetes is 1.18.And there is a beta changes available about that,which is related to HPA, which is nothing.But so far whatever we have implemented HPA,we have done it using imperatively, right?So imperatively, you have giventhe kubectl autoscale deployment commandand then you implemented it.But in future means like when you're using the 1.18and then once this beta becomes live,so you can start using the these things, right?So which means like you can declaratively defineyour Kubernetes horizontal pod autoscaler behaviorin your YML manifest and then execute them.So for additional information about that,you can reference this respect to linkso which has the information about these things, okay?So I'll see you in the next lecturewith vertical pod autoscale topic.So until then, bye-bye.Thank you.
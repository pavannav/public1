# 1.1 Introduction

-: Hi, welcome back.I am Kalyan Reddy Daida and I will be your instructorin this EKS Kubernetes Masterclass course.So let's see the course outline on a high level.So this outline is also going to be very detailedbecause the course is also a very longer coursewhich hits close to 20 of us. An outline,also we need to understand in detail before going in.So we'll see what all concepts we are going to coveras part of this course.So we have divided the topics into four major sections.So which is Kubernetes concepts, AWS services, integrationwith EKS means like what all AWS services we can usein relation with elastic Kubernetes serviceof AWS and Dev-Ops concepts and then microservices concepts.So let's see what all covered under Kubernetes concepts.So close to 30 Kubernetes concepts are coveredas part of this entire course and wheneverwe are writing these concepts relatedYAML declarative files, we are going todo a live template writing sections wherever it is required.So in addition to that, covering all these Kubernetesconcepts, we also cover integration with close to 18or 19 AWS services in relation with EKS. Which iselastic Kubernetes service for example, you can see hereso this is EKS and then we'll have Fargatewe'll have certificate manager, we'll have Route 53,we'll have elastic block store and RDS databaseand then elastic load balancing with the classic loadbalancer, network load balancer andapplication load balancer with ingress service.So like this all, whatever the possibilities therewhich are in integration with EKS, we have tried to get themunder this course. And next thing is Dev-Ops, right?So from Dev-Ops perspective, using AWS code services.We have implemented IT Dev-Ops pipeline to understandingbetter for both the applications and alsothe Kubernetes manifest. So, which meanslike if you make any change to your Kubernetes manifestand then check in that core that will getdeployed to your Kubernetes cluster.If you make any changes to your application and then checkin your application core. So it'll builda new docker image and then deployto the Kubernetes cluster. So both ways,the pipeline is built for you.And next is microservices. So,from microservices perspective, the core conceptsin relation with Kubernetes will be service discovery,distributed tracing, and then canary deployments.So those also we have looked into before moving onto bigger things in Kubernetes.So we are going to learn both docker and thenKubernetes fundamentals in the fundamental section.So there will be a dedicated docker fundamentalsection available for us. So where we builda simple docker image, push it to docker huband then even pull from docker hub and then understandthat docker terminology like what is docker registry?What is docker hub? What is docker image? What is container?So we'll understand all those thingsin the docker fundamental section.And then we'll want to Kubernetesfundamental section wherein we will primarilyfocus on implementing Kubernetesconcepts using imperative way and then declarative way.So here we do lot of live template writingin the declarative way and then lotof Kubernetes cube CTL command in the imperative sectionand then get a full idea about Kubernetes from ports,replica sets, deployments and then services perspective.And from there we'll jump onto big course.So we will start with in this course with the EKS storagewith EBS CSI driver, which is elastic block storeand then implement and then learn as partof that we'll learn how to write a deploymenthow to write a Myer skill cluster IP serviceor how to write a note port serviceand environmental variables, how you are going to defineand volumes, volume mounts, everythingwhatever is related to this respective section.You'll do a live template writing,here and then understand all these concepts and thenprovision these things from your Kubernetes manifest.So, and then you'll understandabout what are the drawbacks of using EBS CSI driver?And what are the advantages you are going toget using RDS database. And then later,using external name service you are goingto implement it with RDS database.So now you have completed the database partwith the storage section of storage classespersistent volume claim config maps, all those things.So then you'll move on to load balances section, right?So before moving on to load balances sectionwhatever you have implemented it's equaland network diagram looks this way.So, now, anyway we know that load balancesneed to run on public subnets and then our workloadsneed to run on private subnets.So to do so what you are going to do immediatelyyou are going to delete this respective worker notes hereand then move your workloads to your private subnets.So you are going to do this and then ensurethat you create a classic load balancer in your publicsublet and then access it. So now you haveimplemented your classic load balancer related manifest.Also, in addition to your, this whole manifest whatever youhave built earlier. And then you willmove on to also creating a networkload balancer manifest and then testing it.So now you have used classic and then network load balancer.So now you'll move on to the ingress servicewhich is super advanced and thenwith the tons of features inside that.So with the ingress service you aregoing to implement context part based routing.Using means like with three applicationsyou are going to deploy and then you'llimplement the context part based routingwith slash app. One should go to app one.App two should go to app two and then anythingother than that should go to user management microservice.In addition to that, in the same ingress serviceyou'll implement SSL. So you'll enablethe SSL for your application here.Okay, and then you'll also implement HTTP two,HTTPS redirection using SSL redirect.And finally, in ingress load balanceof ALB ingress load balancer you are alsogoing to implement external DNS.So external DNS, what it does is automaticallyfrom the Kubernetes manifest you are going toregister your domain name in the Route 53 service.So that also you are going to do.So all these things once complete it means like the,we have completed the database part,we have completed the deployment partand we have completed the load balancer part.So then what comes next, right?So how to run these in Fargate serverless.So we will move on that section. Okay,so in Fargate serverless what we do islike we will run our workloads in a mixer mode.In such a way that we'll run few workloadson our regular manager note groups with easy two instances.And then we'll also run our Kubernatesthat is parts on Fargate. So we are goingto implement this with again three applications, app oneapp two and then UMS in a mixer mode deployment.So wherein app one is running on the EKS manage node groupsand UMS and then app two is running on EKS Fargate profiles.So this one also we are going to look into in detail.And then once we complete the Fargate, so we'll move onto understanding about elastic container registry.So in relation with EKS elastic Kubernetes service.So for that purpose what we do is like we'll move onwith the creating a new docker image and then push itto the elastic container registry and thenuse the docker image in our Kubernetes clusterby deploying the workloads. So that one,we are going to test and as usual we'll continuewith our ingress load balancer for all these sections also.Any way we have implemented earlier here, soin our application load balances section.So we'll continue to use that ingress load balancerin all the upcoming demos for getting complete Hands-Onon that respective section two.Then we'll move on to the Dev-Ops sectionand understand the release processes, source build, testand then production. And we'll alsounderstand about continuous integrationcontinuous delivery, continuous deployment,and then infrastructure as code concepts.And then move on to understandabout how we are going to implement the Dev-Ops conceptsin AWS in relation with elastic Kubernetes service.So we'll understand about code commitchecking the sample code hereand we'll do the code bill meanslike we'll generate the artifacts and then we'll deploy themto our respective EKS cluster using cube CTLand code build combination. And then weare going to monitor our applicationsusing Cloud Watch container insights.So we are also going to implement this Dev-Ops use caseright? And then we'll move on to the microservices sectionwith two independent microservices built exclusivelyfor testing microservices, service discoveryand then microservices distributed tracingand then microservices canary deployments.So we are going to use these two servicesuser management microservice andthen notification microservice andthen implement the full use case.Okay? So whenever you as a developerwhen you use Postman client and create a userit'll call the notification APIand then send an email to end user.So these two microservices using service discovery.How you are going to deploy to AWS,EKS and then this is the way we are going to deploy.So here we will have EMS note, port servicemy collection name, service notificationcluster IP service. So, entire service discoveryhow you are going to handle it in, in relation with EKS.You are going to implement end to end.And then you'll move on to the next sectionof distributed tracing. So for distributed tracing,you need to deploy your demo sets with X reports.So using Kubernetes demonstrates conceptyou are going to deploy the X reportsand this user management microservice applicationand then notification microservice application.What we have done here is like,so we have implemented x-ray using x-ray SDKin those things. So when you deploy those applicationsso how the x-ray is going to behave and then what happens.So using distributed tracing, we are going to see in detail.So whenever distributed tracing is enabledyou can see the service map such a way that the requestfrom client comes to user management microserviceand then calls the notification microservice.So everything you are going to see in detail. From thereyou'll move onto traces also in extra tracesif you see here, so the request came to user managementmicroservice and inside that application it went toget notification app info, method, and from there it wentto Kubernetes,Kubernetes service notification cluster service.And from there again it calledthe V one notification microservice, whichin called the means like inside that notificationapp version service method was called.So these traces also we are going to lookinto in detail as part of this section.And then finally for microservices,we are also going to do the canary deployments, right?So whenever we call that user management microservice.There will be two versions of notification servicewill be live and the traffic will be distributed basedon how much we configure 50, 50 or 75, 25 like that.So it is going to do the traffic distributionto V one notification and thenV two notification microservices.And using Kubernetes out of the box features,whatever is available with the pod number changing.We are going to implement this canary deployments.So from there, we'll move on to horizontal pod autoscaler,vertical port autoscaler and also cluster autoscaler.So all the HPA, VPA and then CA concepts,we will implement in detail. And then we'llmove on to the container insights, concepts which is nothingbut Kubernetes monitoring and then logging section.So we are going to use Cloud Watch agent demo setin our Kubernetes cluster to get the metricsoff all of our Kubernetes clusterand then applications deployed inside that.In addition to that, we are also going to deployfluent D demonstrate, which will get the application logsand then Kubernetes cluster logsfor us inside the Cloud Watch.So as a developer you are going to see whatwhat container map and then container resources,performance dashboards, log groups, log insights,and then alarms. So you are goingto implement all these things in a detailed manner.You'll, you'll implement alarmsyou'll understand about log insights.And then from log insights you aregoing to create the dashboards.So all these things you are going to doas part of container insights.So this is a quick view about the container insights map.So in EKS demo cluster, you can seethat in Amazon Cloud watch namespace, you can see fluent Dand then Cloud Watch agent parties runningin cube system name space, you can see cubeDNS node and then cube proxy related ports are running.And in default name space, whateverthe application you have deployed.So those are running. Sample engine service, sample enginesdeployment related part. So all those things are running.So all in all, we are going to do allthese things as part of this course.So in our next lecture we are going to see how GitHub repoand then understand how to move on with this course.So I'll see you in the next lecture.Until then, bye bye. Thank you.
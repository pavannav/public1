# 22.9 Step-08- NLB InternalLB Demo using k8s Service

-: Welcome back.In this demo we are going to create the,internal network load balancer using Kubernetes service.And for this purpose we will change the,load balancer scheme,in our Kubernetes load balancer service manifest,from internet facing to internal.And we will also ensure that we will remove all other,annotations which are unrelated for this use case.And we will ensure that we'll have only LB type external,which will help us in reconciling,this respective load balancer service,with latest load balancer controllerand we'll use the target type instanceand we'll use the standard,health check settings here, right?And now once we deploy this,Kubernetes load balancer service,it is going to create the network load balancer,internal load balancer.So how are we going to test this?So we are going to test this using a curl pod.So we will deploy a curl pod in the EKS clusterand as a Kubernetes admin using the kube CTL client,I will connect to this curl pod.And from curl pod I will run the curl commands to,access this network load balancer,which is internally created and test the sample application,which is nginx app three related page.So let's also see the network design for same thing.So in AWS cloud when we create,the EKS cluster control plane,it creates the VPC, public subnets, private subnetsand we also create a EKS private node group,with the worker nodes created in the private subnets.And these communicate to the EKS cluster control plane,outbound via a NAT gateway.And we'll also deploy our app three deployment,in our EKS private node groupand we create the network load balancer,in the private subnets itself.So as we changed the load balancer scheme,from internet facing to internal.So this network load balancer is created,in the private subnet for us.And to access the sample application app three,inside this sub private subnets,we just deploy a curl pod in this same EKS clusterand we connect using K ats admin,using kubectl client to this pod.And this will go to the network load balancerand from there, from this part you'll run the curl commandand it goes to this network load balancer,via this it goes to app threeand access the sample index.html from that, right?And this is the AWS load balancer scheme related annotation,which we are going to change from,internet facing to internal.And from curl pod perspective we are going to define a,simple pod, API version V1,kindisk pod and metadata name is curl podand we are using the curl container to do thatand we cannot connect to internal LB directly,from the internet to test it.So we are going to use this curl pod,to connect to that internal LB endpoint.And these are some of the commands,we are going to use to deploy the curl podand connect to that curl podand from the curl pod we are going to run the,curl internal network LB DNS,so that we'll be able to get the sample page,from the app three nginx pod.So this completes the introduction to our internal LB.So now let's go back to our GitHub repository, right?So we are in 1905 LBC NLB internaland let's go ahead and then review the,load balancer scheme annotation.So let's go to the visual studio codeand we are in 1905 LBC NLB internaland inside that we are in 02 LBC NLB load balancer serviceand 01 nginx app three deployment is going to be same as is.So let's come back here and if you see here,service beta kubernetes iver load balance scheme is internaland you can see the name of the service is going to be,internal LBC network LBand the load balancer name also going to be sameand the load balancer type is externaland NLB target type is instance.So these are standard health check settingsand these are resource tags.In addition to that, we also commented the,load balancer source ranges which is 0 0 0 0/0 0.Why because, the VPC CIDR will be used,if we are going to use the load balancer scheme as internal.so whatever the VPC CIDR is there,so by default it will take it automatically.So now let's go back hereand deploy all the kube manifests and then verify.So let's go to terminal and we are in 19 ELB,network load balancer with LBC.So we'll go inside, this is the fifth demo in NLB,which is CD 1905 LBC NLB internal.And you can also verify that kube manifests hereand we will run the command kube CTL,apply hyphen kube manifest.So this should create the internal load balancer for us,which is internal network load balancer.So we can see here app three engineers deployment,is completed and LBC network,internal LBC network LB also created.So I'll say kube CTL get pods,first to check the sample application,app three nginx is running.We will also verify that get SVC,the service got created or not.So it is in the pending state.So let's wait for it.So we can see here internal LBC network LB,is in the pending state.Why it is in the pending state?We are going to see now, right?Kube CTL describe and SVC which is serviceand this is the service.This is another important thing to know.So that's the reason we have added thisand then testing it in this manner, right?So kube CTL describe SVC internal,whenever we describe it,it is saying that fail to deploy the model,due to validation error.So the load balancer name internal so and so,cannot begin with internal hyphen.Why because it is anywhere going to append,internal for this,so that's the reason we should not start with,internal hyphen.So now let's come back here and what I'll do is,so kube CTL get SVC and I will delete this,kube CTL delete SVC and this is the SVC,we are going to delete service, right?Paste it, right?And after that we'll change the nameand then redeploy it.I'll say get SVC and there is no nothing like that.So now let's come back here and we will say LBC,network LB internal will add internal at the end, right?And hyphen internal, the error is related to,load balancer name usually validation error.So load balancer name which means,if you change only this one, that should ideally sufficient,but we'll change and put it as a standard one,LBC network LB internal internaland we will run the command,clear kube CTL apply hyphen F kube manifests, right?So we changed both the metadata nameand also the load balancer nameand we will run the command kube CTL get SVC it got created,so we'll run the command, get SVCand you can see the external IP is allocated now, right?So let's come back hereand we can see if you want you can verify the,load balancer controller pod locks which is nothing but,AWS load balancer controller pod locks,to see that whether this service is,reconciled with this respective,load balancer controller or not.So those are fine, we will leave as is,but we'll come back hereand do a NS look up for this, right?So NS look up for thisand it should not have any external IPs,so it should have a internal IPs for us.So maybe it might take,see it is taking time for provisioning the load balancer.So let's wait for it to change to active state,so that we'll go ahead and do the NS look upand you should have some internal IPs associated with it,not the external internet facing IPs.So let's wait for it.We can see here now the load balancer is in active state.So let's copy this DNS name and let's come back hereand say NS look up and DNSand we can see it is resolving to,some internal IPs 192, 168 some 64.61and then 116.38.So now in addition to that we thought that,whenever we have seen the validation error,when the load balancer name is,starting with internal hyphen,so we moved it to the end of itand thought that it is going to upend someor prepend some internal here but it didn't do that.So that is fine.So now let's come back hereand move to the next step which is deploy curl podand then test internal NLB.So we'll go here and in 1905 LBC NLB, so let me close this,you can find the Kubernetes manifest curl.So where in, in 01 curl pod you can see the,curl pod related Kubernetes manifest,for this respective pod.So we will come back to our terminal hereand say kube CTL apply hyphen F,kube manifests hyphen curl, right?So this should deploy the curl pod for usand once the curl pod is deployed,so we will connect to that curl pod,using kube CTL exec hyphen IT curl pod which is pod nameand hyphen hyphen SH,which means with SH command we are going to,connect to that, right?So let me connect to that curl podand if you want you can run kube ctl,get pods and also verify that before connecting, right?So we'll say kube CTL get podsand you will find that right?So this is the curl pod runningand you can also say kube CTL get SVC,so that you will get that this respective load balancer,network load balancer, internal LB.So first I'll say clear will come from the top.So I'll say kube CTL, SVCand I'll copy this DNS name, right?And I will connect to the curl pod with kube ctl exec,hyphen IT pod name and hyphen hyphen SH, right?So from this pod I will say curland I'll run the command,which is related to my internal load balancer DNS name.And you can see we are able to get the,welcome to stack simplify Kubernetes fundamentals demoand application version V1.So this DNS, if you access in the browser,you don't have the internet edge,we will not able to access it,but with curl pod we are able to do that right?So from curl pod,from inside EKS cluster itself, we are accessing it.So now let's come back here and delete the kube manifestand also delete the kube manifest curl exit clearand we'll say kube CTL delete hyphen F kube manifest.So we have successfully tested our,created the internal network load balancerand tested it with curl pod now.So we'll clean up these thingsand verify if the load balancer is deleted successfullyand we'll also delete the kube manifest curl podand come back here and refresh.We can see here network load balancer,is successfully deleted after deleting the kube manifests.So this completes the this respective demo.In the next demo we are going to focus on,using the target type as IPand also ensure that we deploy our app three nginx,on the fargate podand ensure that this network load balancer,is able to connect to the fargate pod.So this is another important feature,which is working in this respective,latest AWS load balancer controller,for the network load balancer use case.So I'll see you in the next lecture.Until then, bye bye.Thank you.
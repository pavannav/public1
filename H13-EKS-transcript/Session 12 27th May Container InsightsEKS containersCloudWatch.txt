ript


12:11
Good morning everyone. So let's start with a quick revision. Uh in last class
12:16
we learn about how we can launch EKS cluster with a Fargate. And if you
12:21
launch EKS cluster with a Fargate then what is the difference between uh if you
12:26
use a Fargate and if you don't use a Fargate. So we will discuss one by one. Okay. So uh let's start with a quick
12:34
revision. Let me first share screen.
12:46
I hope screen is visible. Okay. So Amazon uh Elastic Kubernetes EKS is a
12:53
managed Kubernetes service. So if you want to launch uh if if you want to
12:59
launch a Kubernetes uh cluster then we have a multiple way available. One one of the way is EKS. EK is a managed
13:06
service for Kubernetes which is a ma which is a managed by AWS and that make
13:11
it easy to run Kubernetes on the top of AWS cloud. It is a managed service. So
13:17
you don't need to worry about installing part, configuring part and managing part of the Kubernetes. Okay. So, EKS is a
13:24
one of the service that is elastic humanities service is a one of the service in the AWS cloud which is a
13:32
uh which we which is a help us to run Kubernetes cluster on on the top of AWS cloud
13:38
and uh uh if you talk about any cluster then we have a total two part we can say uh one of the one part is a master node
13:46
part and another part is a work worker node part in Amazon EKS Amazon uh AWS
13:52
manage the control plane that is uh also known as a master node uh of ETSs uh for
13:58
you. Okay. So uh this work uh master node and control plane will uh manage by
14:05
AWS and AWS take care of provision part managing part and maintaining the
14:10
control plane for you. This include managing managing uh managing the underlying infrastructure ensuring high
14:17
availability of the control node components and performing updates and patches. Um if you use EKS then we don't
14:26
need to worry about the managing part of the master node. It will done by uh it
14:32
will done by AWS at the back end. Okay. But uh another part is a worker node and
14:38
if uh and uh we are responsible for this part. Okay. So if you use EKS then by
14:44
default we have to uh managing manage the worker node and that worker node run
14:50
the container. You need to provisioning and manage the EC2 instance. Worker node
14:55
is nothing but the instance is nothing but the system. So for launching the worker node we have to use a EC2
15:02
instance and we have to manage that EC2 instance. We have uh again we have a um
15:08
um multiple method. One of the method we have to manage manually and another method is autoscaling group. Okay. So
15:16
this is one of the method for for managing the EC2 instance to ensure that the desired number of worker nodes are
15:22
available to run the containers. Okay. So this is uh this is the one of the
15:27
method for the EKS cluster and we can say this is a method without the farget. Okay. But if you want to manage master
15:35
node also and worker node also uh by the AWS if you want to manage both
15:41
the control node that is a master node and worker node by the AWS then far
15:47
service comes into the picture. Okay. So far uh Fargate is again one of the service in the in the AWS which is a
15:55
serverless service and if you want to manage a control node uh that is a
16:01
master node and worker node then Fargate comes into the picture. AWS Fargate is a
16:07
serverless compute engine for container provided by the AWS. It allows you to
16:12
run container without managing or underlying infrastructure. With the Fargate you don't need to provision or
16:19
manage EC2 instance it will u done by AWS if you use a Fargate
16:25
when you use uh when using Amazon EKS with a farate AWS manage both control
16:30
plane and worker node for you we don't need to worry about control plane also
16:35
and uh worker node also you no longer have to worry about the provisioning part then scaling part then patching
16:42
part the worker node farm automatically ally take care of the infrastructure
16:47
management including scaling the compute resource based on container requirement.
16:53
As soon as requirement increase then automatically uh it will uh scale. Okay.
17:00
And as soon as requirement decrease then it will automatically scale in. Okay. So that part will manage by a far.
17:08
So again if you want to create a cluster uh EKS cluster with the fargate then this is a command. So, Ekkl create
17:16
uh cluster then using a hyphen - name command name keyword we can pass the cluster name then we can see here a new
17:23
option come up that is a hyphen fargate. If you use this option then it will be
17:29
uh then uh EKS will launch um with the fargate. Okay. Then as soon as we create a cluster then
17:36
automatically some few cluster nodes uh will launch. So when you create a EKS
17:43
cluster with the Fargate then by default two nodes launch for internal purpose. Okay. So this node are used to run the
17:50
Kubernetes control plane. So this is the node is used for the uh Kubernetes control plane which is responsible for
17:56
managing the cluster resource. So if you want to see the name space then cubectl
18:02
get name space command will use that. And if you want to see the uh pod in the
18:08
cube-en system name space then this is a command. So automatically two pod will
18:14
uh launch when we launch the cluster with the target. Okay. If you want to
18:20
see the pod uh with the name of which uh node they launch. So we can use option
18:26
hyphen o wide wide option. Okay. So uh here you can see this is a pad name and
18:32
this is a node name. Okay. This is a node ID. Now if you want to create a
18:37
deployment, so this is a command cubectl create deployment name of the deployment and name of the image. And when you
18:45
create a pod in a EKS cluster with the fargate, the pod will initially be in a pending state. If you see uh if you see
18:52
here uh we can see it is a uh in it is in a pending state. Uh why? So because
18:58
the fire scheduleuler need to first launch the worker node. As soon as we launch the pod then uh it will need some
19:05
time to launch the worker node. So first it will launch the worker node before it can launch the pod. Once worker node is
19:13
launched the pod will transition to running state. Okay. So as soon as uh
19:18
node launch we can see the new node come up. If we see the previous we have only
19:25
two node. Okay. We have only two node. After launching the deployment, after
19:30
launching the pod, uh new node will come up and pod have uh pod have just been
19:37
launched. Okay. So this is the status of pod. We can see it is running. Now if we
19:42
try to scale the pod, we can observe that observe that the node will uh node
19:47
will also increase. Now if we um scale the uh scale the pod using cubectl scale
19:53
command then we can see the node uh number of node will also increase. Okay.
20:01
Now we are going to put some request for resource in the document below. So this is a yml code for launching the
20:06
deployment and in the below we can see we request for some CPU and some uh
20:12
memory. Okay. So 4096 MB we requesting for that deployment and 4,000 m uh for
20:20
the CPU we requesting for that part. Okay. And using this YML code we deploy
20:27
the application using cubectl apply command and using hyphen app option and pass the name of the yml code. Now we
20:34
will get a new node as soon as as we already discussed as soon as we launch a
20:40
new pod new node will launch. So as soon as a new node will as soon as a new pod
20:45
will launch new uh new node will come up. Okay. So if you see the cubectl get
20:51
nodes another node will come up and that pod will also come up. And if you
20:56
describe the pod whichever pod will launch here if you describe the pod we can see the request for that resource
21:03
and the node will also launch with some default resource in order to meet those requirement. If if you describe that
21:09
node cubectl uh describe pod and name of the pod then we can see the uh request
21:14
which we pass um here okay in the document.
21:20
Okay. Now if we create a new name space for creating a new nameace we use command as a cubectl create ns that is a
21:28
name space and name of name of that name space and if you want to see the name that name space then we can use a
21:35
command as a cubectl get nameace okay
21:40
then after uh creating that nameace if you if you want to deploy the
21:46
application in that name space in that created namespace okay so we Use the option hyphen n and name of the name
21:52
space. And this is a command for deployment. And after launching that deployment, if you look at the
21:57
description of the pod after application has launched, we can see the pod is fail. Okay. So this is a event. We can
22:05
see here the pod is fail. Why it is a fail? So it means that the name space
22:13
where the pod was scheduled has a tent that the pod is unable to tolerate. So what is mean by tent? So tent are used
22:19
to prevent pods from being scheduled on specific name space in Kubernetes. Okay. So tent is a
22:27
uh tent is used to prevent the the particular part for being scheduled on specific name space. Um and and and for
22:35
that uh for this tent we have a solution named as a toleration. Okay. So uh it
22:41
allows to uh it allows ports to tolerate those tents and schedule on tent nodes.
22:48
So far in Amazon EKS only supports pod in a default name space or cube system
22:54
name space. If you want to launch a pod in a cube system uh in a kubernetes if
23:00
you use a target um then uh we have to we have only two option default name
23:06
space and cube system name space. If you want to launch then we have to launch in a default or cube system name space. But
23:13
if you want to launch a some another um name space then we have uh another uh
23:20
service we can say that is a far profile is a subservice of target. So far
23:25
profile comes into the picture. Okay. So far profile in Amazon EKS is a configuration that defines which pod in
23:32
your cluster should run on AWS target. It allows you to specify which name
23:38
space and pod selector should be associated with the target enabling those part pod to launch and manage by
23:45
the fargate infrastructure. Okay. So when you create Amazon EKS cluster with
23:50
the Fargate the default Fargate file automatically created if you see here so
23:56
we can see the Fargate profile name as FV - default and it it will only support
24:02
default name space and cube system nameace. Okay. So pods in other name
24:08
space will not schedule on fire by default. Why? Because we create by default um when we launch the cluster
24:15
then it will create automatically one target profile and that far profile only
24:20
support default name space and cube system namespace. That's why we are not able to launch u deployment or pod in
24:29
another uh name space. But if you want to launch uh some pod or deployment in
24:35
another name space then then we have to create another fire profile. So for creating another fire profile we have a
24:42
command ekl create profile name of the fire profile name of the cluster and
24:49
name of the name space. Okay. So if you want if you have launch an app inside
24:55
the name space after creating this fire profile then it will launch successfully. So first launch the fire
25:02
profile for whichever uh name space we want and after that launch uh another
25:08
new deployment in that name space. After that we can see the node will launch uh
25:15
new node will launch and new part will launch in that name space. Okay. So
25:20
that's it guys. If you have any queries uh for this particular um revision then
25:27
you can ask me in the chat box.
26:53
Yes guys, if you want to launch EKS cluster then we can say we have a total
26:58
two-way with the far or without a farget. If you use a target then uh then
27:04
uh control node uh only managed by uh AWS. We have to manually uh we have to
27:11
manage manually uh worker node means um
27:17
uh means uh um EC2 instance automatically launch but we have to manage uh manually means after means if
27:24
uh if some of the requirement come up or uh some of uh if requirement increase
27:31
then we have to manage EC2 instance manually we have to increase the size okay so this is a manual way and this is
27:37
a without a target. If you don't use a target then it will only manage manage the master node means
27:46
for example um it will uh for example uh if you want to
27:52
manage for example u master node will manage by AWS and uh if you want um if
28:00
something come up and master node um um size of master want want to increase
28:06
then it will done by AWS but size of the EC2 instance size of the worker node
28:11
want to increase then we have to manage manually. Okay. But this thing also we
28:16
want automatically then far comes into the picture. Okay. So Fargate will man
28:22
if you use a Fargate with the EKS then it will manage master node as well as
28:27
worker node. Okay.
29:20
Yes guys, sir will start the session in few minutes.
29:45
Yes par you are right. Okay. So when you create a cluster um using a EKS CDL with
29:52
the help of Fargate then it will create one by default Fargate profile and that fire Fargate profile means um if you see
30:00
the Fargate profile. Okay that F that that far profile allow only the uh pod
30:07
which will um in in a name space called as default name space and cube system name space.
30:14
Okay. Parish.
32:06
Yes, Pares. Uh if you use a Fargate or if you don't use a Fargate, uh master
32:12
node will always manage by AWS. Okay. Here thing is about uh control uh sorry
32:19
uh worker node. If you want to manage worker node also then we have to use a fire. Okay.
34:44
Now page if if you want to create a service or a load balancer then we have
34:50
a uh code uh we can use a yml code for launching the service. Okay, that is a
34:55
load balancer.
35:28
Okay guys, I think Mimar is here. Old user
35:50
Hey guys, uh very good morning and uh let's continue with the next part. very very important class and uh lots of
35:56
interesting practicals we are going to uh perform today in in container world
36:02
or I can say in the EKS right so was uh I think there's two or three topics one
36:09
of the main topic I'm going to look to start with is about how we can monitor
36:15
the container in the AWS world or container technology in the AWS world
36:22
and guys there's the lots of way you can
36:27
uh manage the container in AWS world. One of the native service of AWS called ECS,
36:35
elastic container service. Okay. But mostly nowadays we want to use uh EKS
36:43
that is just a service for Kubernetes. Okay. Or I can say manage service for
36:48
AWS for Kubernetes. Uh so this service manage kubernetes and
36:54
kubernetes will manage container but technically it is going to manage the container.
37:00
Okay. Now point is guys if I talk about the management perspective right so in
37:06
the management perspective one of the very core and critical area is that we
37:11
have to do a lot because launching the cluster is one time setup right maybe
37:17
inside the cluster launching the uh maybe uh your
37:24
your uh port and application can be maybe one time setup but but there's one
37:30
thing that we have to do almost every time every moment that is called monitoring.
37:36
Okay. And mering is very very critical and in monitoring there's multiple thing we can monitor right one of the two
37:42
things that is mostly uh we always do okay for example you know what is
37:48
kubernetes this is one prerequisite for this today's class and again very important class I'm going to do lots of
37:55
demos today okay and plus today would be the last class guys for EKS last class
38:02
for the serverless guys last class for developer track and last class for M mastering uh guys also. Okay. So those
38:10
who belong to these training with me uh would be the last class for today and there's will be
38:17
some interesting demonstration we will uh see today. Okay.
38:23
So um you know you guys know about EKS. So EKS
38:29
is a service. EKS is a service who going to launch a Kubernetes and they launch
38:35
some master node that is fully managed by AWS. They're going to launch some worker node that is kind of launched by
38:42
EKS but we have to manage. But if you don't want to manage this worker node also then we can integrate EKS with
38:49
farget. What is forget? That was the class I did in detail in my some last few days back. Right? If you miss this
38:55
class, you can get the recording. But this is what we discussed. But this is your your
39:02
EKS uh cluster. But this worker node also known as slave node or the compute
39:08
node is the one who will handle your workload. It means if you draw the worker node
39:14
here. Okay. So whenever you want to launch any
39:19
application, right? You know you have the image and from the image you will ask the image to be deployed and your
39:26
final port will be deployed okay on the top of worker node
39:32
it means your port is going to use RAM and CPU from the worker node or for the
39:37
compute node. Okay. So my point is this particular
39:43
pool how much RAM and CPU they use at this point in time
39:49
RAM and CPU is the thing that keep on changing but at this point in time I want to see I want to monitor how much
39:56
RAM and CPU they they they are using or utilized
40:01
okay that is called metrics. So I want to know the matrix of my this particular
40:07
port or maybe all the port or maybe if you know guys Kubernetes in
40:12
the cubernetes we have a name spaces right. So guys in my case Kubernetes already installed with EKS tool and EKCL
40:19
get cluster I already have a cluster in Mumbai region.
40:25
Okay, this cluster is running and this cluster guys if you run the qc till command get node
40:32
some two I think two worker node is running over here okay and this is the new cluster so
40:39
there's no port running and in the cubernetes guys we have a name spaces like a area where we launch
40:47
a port normally we launch a port in default but we mostly
40:54
as a good practice What we can do? We can create a name space. Let's say this
40:59
is a Linux world project. Name space like a project.
41:05
Okay. So this name space created and it's good practice uh any project
41:11
related to Linux world I can launch in in this name space. So we can add a lot of security and many more things. So
41:17
again this is not the Kubernetes class purely but those who know Kubernetes they know uh about name spaces plus why
41:26
we create the name space and all many more things we can do. Okay. But this is name space we have.
41:33
Okay. And right now if you talk about this name space how many port we running in this name
41:40
space. So I can give my nameace name. Let's say Linux world project. So in
41:46
this name space there's no port running. But when you want to launch a port you can launch the port in this in name
41:53
space. Okay. So I can uh I can go and launch the port in this particular name space.
41:59
So what I want to do here I want to monitor okay that this is a name space in this
42:07
name space I want to know the metrics in this many name space how many port is
42:13
running what is the name of the port how much total uh memory is been utilized by
42:19
this name space or this port or maybe this particular worker node maybe so in this worker node maybe 100 is running
42:26
out of 100 port total rendered port how much total memory has been used. So my point is at
42:34
any point in time if you want to know about the port
42:40
about the container or you want to know the container details this container
42:45
insights. Okay. So in the AWS guys we have a
42:52
dedicated service from the cloudatch. The cloudatch is
42:57
main for guys in AWS for monitoring purpose. Right. So we have dedicated service or the sub component of the
43:04
cloudatch called container insight. Okay. By this contain side tool any
43:12
container platform in AWS EKS or ECS. Okay. You can uh take this container
43:18
inside tool and that is meant dedicated for the container monitoring purpose.
43:23
Right. And you can monitor your container infrastructure. Right now if you notice here if I go to
43:31
cloud watch okay cloud watch.
43:36
So in the cloud watch uh is one service guys in AWS for for monitoring purpose.
43:43
Okay. But here if you go down there's a inside and
43:48
there's called container inside not lambda inside different is different different different I'm talking about the inside container inside.
43:56
So container inside is a dedicated u uh service for monitoring ECS EKS and
44:05
cubernetes. Okay. They also support P by chance if you know Prometheus they also support
44:11
Prometheus also somehow to be integrate but this is what they do and any
44:18
container resources right you can you can monitor from here right now you
44:25
can't see anything here okay why there's a possibility either
44:31
your EKS service not running but in my case EK is actually running okay I
44:37
already have one cluster running at this point in time. See here this is running right now.
44:43
Okay. But still you can't see anything here in the container inside.
44:49
Okay. Why I will discuss this point. But this is a one important service we are going to discuss today.
44:56
Okay. And it give you lots of information. It's not only about metrics also.
45:02
Okay. Here we can also uh also monitor
45:08
the logs. Okay. So your maybe port or maybe your worker node what log they generate.
45:17
Okay. That also we can monitor. Okay. Monitor. So so multiple things we can monitor.
45:25
That's what I'm talking about. So if you want to monitor the metrics
45:31
okay we can monitor if you want to monitor log you can monitor for example what is log maybe worker node they will
45:38
have their own logs let's say in worker node behind the scene because port is a container I can
45:45
say inside the port we launch a container container need a container engine maybe docker for example so we
45:52
start the service and stop the service docker they generate the logs
45:57
Okay. Or maybe many more logs of maybe sometime port also when when you launch let's say you launch uh database port
46:05
they also generate the log web server port they also generate log. So log also
46:10
guys you can monitor from this cloud watch. But my point is
46:16
okay for knowing the container insight we have this tool
46:23
okay dedicated tool for especially for the containers. Okay. Now nothing is visible here. Why?
46:32
Because if you want to know the container inside or in inside I can say okay what you
46:41
have to do what you have to do so let's say this is a worker node
46:48
okay and worker node is a one where your container engine is running it can be
46:54
docker or something like this you can identify very quickly so you can say
47:00
cubectl describe all of your nodes right now.
47:07
So this is the worker node I'm just trying to describe and this worker node say uh I'm running somewhere and I'm
47:14
using containerd as my runtime not the docker so they're using container I think in
47:20
some of my initial class of ease also that time I was talking about this is what the container engine they using but
47:27
does not matter what whichever they use at this point in time okay and this is a
47:33
system where we launch the port
47:39
but what we want okay any log generated by port or any RAM and CPU used by the
47:47
port for in particular name space or individual port maybe okay and it is not
47:53
only any other component of u of uh uh
47:58
EKS you want to see the services you want to know the deployment Anything you want to
48:05
monitor your content inside can help you. Okay. But for this what we have to do
48:11
for this on the top of worker node. Okay. Here we have to install one
48:19
program. That program is mostly work as a program for you.
48:27
Any activity happening in the worker node let's say having IP 1.2.3.4 for let's say system number A any activity
48:34
related to container this agent program is keep on monitoring
48:39
this keep on fetching the information okay and this information they keep on
48:46
sending to the cloud watch where to the container inside so in the cloud watch
48:53
in this container inside this car graphical tool they keep on sending the information
48:59
okay so The duty duty of this agent program is is to keep on collecting the
49:07
container or port or cubernetes related things and keep on sending pushing to
49:12
the to the uh container inside
49:18
and then you will see this detail over here. Okay. For which agent we have to
49:25
installed depend what you want actually. Okay. Because in the monitoring world
49:30
there's a lot of things we can monitor. You want to monitor the tracing, you want to monitor the logs, you want to
49:37
monitor the matrixes. Okay, if you're interested in
49:43
monitoring the the the matrices
49:49
about the EKS mat means how much RAM and CPU they use, how how many port is
49:55
running, how many service is running, how much replica of that particular
50:01
deployment is is been at this point in time. So those are known as the metrics.
50:07
Okay. So for this we have a special agent for uh that you have to deploy on the top of worker node is called fluent.
50:15
So fluent is a one program okay if you search this
50:21
program over here fluent okay is a program
50:28
okay that we can launch is opensource program to collect the data okay it's
50:34
not dedicated for eks or kubernetes or or for the AWS it's a third party tool
50:41
but this is a tool that what AWS recommend to uh deploy here.
50:48
Okay. So, Fluentd is one program that we are going to deploy uh to collect this
50:55
information. Okay. And it is not only for metrics. You can use fluentd for for
51:03
uh for getting the logs also. So depend upon right what you want depend upon
51:08
what what kind of setting you will do with fluent. Okay. So this is one thing.
51:16
Now uh there's one more thing we can do here is uh if you want to get the logs
51:23
okay then we can use cloud watch and vice versa also depend upon how we
51:30
set up. Okay so let's say for the fluent okay let me use fluent for the log. If
51:38
you want to collect the log of the container thing, we can use fluent.
51:44
Okay. And for you can also do one more thing if you want it's not compulsory. If you want to
51:50
collect the metrics then there's one powerful tool in the AWS we have is called cloudatch. So here
51:57
cloud watch also have the agent size. Okay. So we can install the cloud agents
52:04
to collect the metrics. Okay. depend upon how which tool has their part of
52:09
capabilities. The fluentd is a one agent that we deploy on the top of worker node
52:17
that we collect the log send to cloud watch. Okay. And the cloud agent is also
52:23
one kind of program. Okay. That we can install again in the worker node and and
52:36
Okay. And uh we are uh we are sending the uh
52:43
metric information from the worker node or from the EKS cluster I can say to the cloudatch
52:49
but all the main cloud sorry all the container related information you can see in the in the container inside over
52:58
here but it's not visible right now. Okay. in the content inside
53:05
because we didn't install any okay we didn't install any agent in the in the uh in
53:14
your cluster which your cluster you have you have to install this agents right so
53:20
let's start guys doing this part how we can install uh this agent and my point
53:26
is this agent we have to store per worker node Okay, per worker node. What I mean by
53:34
this? If you have one worker node or maybe two worker node and there's a possibility guys, you have many world
53:40
worker node also and most you have a lot of worker nodes, right? So this worker node number A, worker node number B,
53:47
worker node number uh C. Okay. So obviously your port can be launched
53:53
here, your port can be launched here, your port can be launched here. It is not actually normally we don't control.
54:00
We have a way to control but normally most of cases we might not control. Okay. Where to schedule is it has been
54:07
planned by cube scheduleuler. Okay. But my point is wherever the port launch I
54:14
would like to monitor. Okay. It means we have to install our agent here also. So
54:20
agent for fluenti and cloudatch install in this area also. Fluenti and cloudatch
54:28
will install over here. Fluentd to collect the log from this worker node and cloud watch to collect the metrics
54:34
from this worker node install over here. So fluent or cloudatch agents.
54:42
Okay, we have to install it on all the worker node. This is one thing. Second
54:49
thing is they are the program but because this program guys is is trying
54:55
to identify some information about Kubernetes
55:00
Kubernetes. So is best practice or better practice would be not I can say
55:05
best practice. So right approach would be I can say this program we have to
55:12
launch as a container and this container would be a port in the in the
55:18
Kubernetes. Same thing this agent also is a program we have to launch as a port in the Kubernetes.
55:24
So finally for the Kubernetes perspective, Fluentd is a port cloud watch is a port and again for the
55:30
Kubernetes perspective this Fluentd is a one container running in C. Cloud watch
55:36
agent is one program but as a port they're running on the top of C.
55:41
They're finally going to deploy as a port. So it means if you want to launch a Fluentd agent or the Cloudword agent,
55:50
you need some image and from the image you can deploy it. But where to deploy in the worker node?
55:56
Which worker node? In all the worker node. How many worker node you have? Right now three. But how many you will have? We don't have no guarantee.
56:04
Maybe we have set some autoscaling groups here or HPA here.
56:11
Okay. Not SP I can say but autoscaling group where sudden load increase and worker node will increase. Okay.
56:18
Let's say D. So what we can do guys in the EKS okay
56:24
there's a two main facility available there's one concept called
56:29
autoscalers that use autoscaling group concept from
56:35
AWS and what they do as a load increase they auto increase add many more worker
56:41
nodes or there's one more tool guys called carpenter
56:46
is also one tool right that also to help you with more optimized way and better
56:52
way fast and many more facilities they have. Okay. So the load increase
56:57
automatically add more worker node. If load decrease the delete the worker node like autoscaling. So you can use any of
57:04
the tool. Okay. My point is here this is normal
57:10
setup autoscaling group or the carpenter we always has uh in the cubernetes world
57:16
or in maybe ease here. But the challenge is okay.
57:33
Okay. Now in this scenario if you have a requirement
57:39
that if the worker node going to come up let's say one more going to come up let's say e worker node and this fluent
57:49
and cloud was there two independent port two independent program and agent I want they will launch automatically you don't
57:56
have to worry about it okay here guys the replica also does not work in in the kubernetes right because
58:04
replica We need to tell how much replica to launch five or 10 but we don't know how many worker
58:10
node we're going to have in the future. So in this use case where if four worker
58:17
node four fluent agent will run 100 worker node 100 cloud watch port will
58:22
run only that number only on that particular node also right A will have
58:28
one port B will have one CA will have one D will have one and so on. Okay. So
58:34
in the Kubernetes perspective there's one concept in the Kubernetes who will handle this situation and in the this is
58:41
concept for the Kubernetes and this is called demon set.
58:47
So demon set is one resource in the cubernetes if we search for cubectl
58:53
get d a e demon set.
59:00
Okay demon set is one kind of resource I don't have right now. But the resource is there we will create
59:06
today is a one concept it is more like a
59:11
deployment deployment also one concept you guys know
59:17
okay but the only difference is if I say deployment 10 replica say they can launch 10 replica all 10 replica might
59:23
go in one worker do also so that is for different purpose you know the replica use of the port but
59:31
deon set is also But in the demonstrate we never tell we never tell our number of replicas. So in
59:40
the demonstrate what happen what happen? Okay demon set automatically identify if
59:47
you have a two worker node they launch two ports. Interesting thing one port
59:52
they launch here and one port they launch here. One more node going to come up in the future they automatically add
59:59
one more port here. What is that? I asked them in the demon set.
1:00:05
So there one cubernetes concept but normally in this kind of situation use case we use the demon set that we going
1:00:13
to use today. Okay. So because we are going to monitor every worker node. So we want to install
1:00:21
one agent. Today we are going to install two agent. One is fluent and the cloud watch agent. Fluently for locked or for
1:00:28
watch metric purpose but who will help us to launch this board not the
1:00:34
deployment not the replica set not the replica controller if you know about replica controller replica set it's
1:00:40
again kubernetes concepts but we are going to launch with the help of demon set
1:00:47
that's the whole idea okay and one more thing guys over here
1:00:53
to to know okay is because this port
1:01:01
is going to monitor. Okay, your underlying worker node. This
1:01:07
port is going to monitor other ports. Okay, means one port we have to give we
1:01:16
have to give this particular port a power to monitor your worker node or
1:01:21
that local system other cubernetes thing other ports.
1:01:26
Okay. So this particular port we have to give some power some access power and
1:01:34
because they are belongs to cube so we have to give this power from the cuber perspective.
1:01:40
Okay. So if you guys know the concept of role binding in Kubernetes. So role binding is a concept okay through which
1:01:47
we can give particular pool by creating some service account.
1:01:54
Okay. So we can create one service account give this account to this one and this account or user we can give
1:02:02
them a role. This called our back concept. Okay. And again guys we are into the EKS
1:02:10
training okay and these this concept is purely related to Kubernetes. So we are
1:02:16
not going to discuss about ARB and uh service account. So if you want to learn this you can learn the pure cubernetes
1:02:23
training CK and CKD training of Kubernetes where you can learn all the thing from very basic to all at once.
1:02:29
Okay but I'm just trying to give you a brief here. Okay, we have to give this port
1:02:36
a account this go service account and that account we give some power. Okay,
1:02:41
that that you are the port you belongs to you belongs to this account and this
1:02:49
account at this power and according this power you can go to other port you can go to worker node and you can collect
1:02:55
the logs you can collect the metrics and you can do something whatever minimum requirement you need to do here you have
1:03:01
to give some power and then power normally we do with a role binding this are big concept in cubernetes okay role
1:03:08
based access control role based access Okay. So this is also we have to do. So
1:03:15
I think this much information enough guys to start with the demo. Okay. So
1:03:21
finally we are going to uh launch the
1:03:28
the uh agents on the worker node. Okay. But
1:03:34
before we launch the agent, let me do one thing. Let me launch some application here. Okay. And for
1:03:41
launching the application, what I'm going to do, I'm not going to launch into default node today. The default
1:03:46
name space that's what you know already. Let me launch our application in a different project or different uh name
1:03:54
space called Linux world project. Mhm. I don't have right now. I'm going to
1:03:59
deploy even though I don't have a deployment also. So I'm going to deploy one project first
1:04:07
and at your choice. Okay. depend upon the level of specific Kubernetes is which application you want to launch. It
1:04:14
can be your application, it can be microservices or it can be uh some multi- multi-
1:04:22
uh tier application right one of the good example can be WordPress. So I'm going
1:04:29
to guys launch a WordPress application here that very very simple to launch.
1:04:34
Okay. So those who by chance does not know the WordPress is. So in WordPress they contain two different application
1:04:41
and so that we need two different port one we launch you we we launch a MySQL
1:04:48
database and one port we launch as a PHP front end or back end. Okay there where
1:04:54
the WordPress application is running. WordPress is a blogging site.
1:05:00
Okay. So any customer from the outside world can hit to this port they can show the
1:05:07
website and when the customer write a blog this WordPress website can get the
1:05:12
blog and finally entire data they stored in the database
1:05:17
MySQL database. Okay. So now it is your choice this
1:05:23
MySQL database you launch in a Kubernetes as a code
1:05:31
or you can also launch MySQL in AWS as a
1:05:36
RDS service. So MySQL running as RDS service in AWS
1:05:43
and this port application working as a port in the cub this also we can integrate. I'll give
1:05:49
you this idea also today how we can do this. But right now let me launch as a port.
1:05:55
Okay. So there's two port running and both the port work together and create one final WordPress application. So this
1:06:02
called multi-ode application or multi-ter application.
1:06:09
Okay. So that's what we're going to launch. Now for this there's a multiple multiple
1:06:15
way we can launch guys. One way approach would be I can go and launch the MySQL
1:06:21
port individually. I can go and launch the WordPress port individually. Then finally I go and connect these two guys.
1:06:28
So this also can work. Okay. But normally guys what happen?
1:06:34
Okay. In lot of main use cases what is commonly used in the market like for
1:06:39
example this is the example of WordPress. Okay. And we know in the WordPress we need two port one for
1:06:45
WordPress, one for MySQL. We need we we have to give some storage. We need we have to finally connect these two guys.
1:06:52
Okay. We need some services also in Kubernetes services. Okay. So, so rather
1:07:01
than we launch this port and launch the service for this guy, launch this port, launch the service for this guy. Okay.
1:07:08
then connect this port with the service into MySQL. Okay, rather we do this part
1:07:15
one by one. Okay. Or in the market a lot of
1:07:21
communities guys what they have done they create this entire setup as automated setup.
1:07:28
Okay. And this automated setup they have created with a tool called helm
1:07:35
and where this setup in the helm is known as chart helm charts. So you can think chart is more like a
1:07:41
template but is beyond the template actually those who know the template concept in kubernetes. So one chart
1:07:47
chart can contain multiple template. One template going going to launch this one template going to launch this one
1:07:53
template going to connect this something like this. So, Helm is a tool used a lot
1:08:01
in Kubernetes or maybe in the open in this kind of Kubernetes environment
1:08:06
where it help us to automate and launch this one big application or maybe
1:08:12
microser also okay in one go one click and they will install for you
1:08:19
okay and helm is a one tool that is a kind of free tool
1:08:25
okay so you search for helm download. In my case, I am using Windows. You can go to this URL
1:08:33
or you can go to Git. Okay. Download the the help. Please
1:08:39
don't download guys. Version two. Version three is new. Version two and three has a huge difference. Version two
1:08:45
had to do a lot of many thing extra to perform. But version three is very simple and straightforward and have new
1:08:51
features also. So go here. Okay. You can download tool depend upon
1:08:57
your operating system which operating system you are using. In my case I have Windows. So I have
1:09:04
downloaded this tool. Okay for the Windows operating system. Download it.
1:09:10
Double click and install it. So very simple download and double
1:09:16
install. Okay. And after install it is actually a
1:09:21
kind of uh they create a folder actually. So I think in my system I
1:09:27
already download the gas software and this software is there u in somewhere in my one guys let me
1:09:35
stop sharing so this software is there in one of my I
1:09:41
don't know where I downloaded one minute guys give you one minute
1:09:48
helm
1:10:08
So after you download guys uh after download double click and extract. This
1:10:13
is the one software after download double click extract. This is one folder they're going to create
1:10:19
and in this folder okay they give this binary. So nothing
1:10:25
to install actually they give finally a binary that we can directly run it to to
1:10:30
to run this either you can set the path or you can go to this particular folder from there you can go and uh run the
1:10:36
help so I'll go to this particular folder okay and in this folder we have helm and
1:10:43
you can run it okay so to run we can give helmx and just let me check the version so
1:10:51
right now I'm using the version 3 above that's okay if you I have to group on change to three otherwise lot of things
1:10:58
you have to extra add. Okay. So um this is what guys uh we have
1:11:05
here. Now we can use helm. Okay. Uh so helm is again again tool
1:11:13
that work on the top of cubernetes or I can say cubectl. So instead I can say cubectl to create
1:11:21
the deployment. Okay. And I say just create a deployment
1:11:27
for MySQL then create a deployment for PHP then launch a service and do many
1:11:33
things. Okay. So rather we do this part H will
1:11:39
give away that's called chart and with chart we can deploy the entire setup this entire big setup this entire multi
1:11:45
application in one go. Only thing is we need a chart. Now either you can create
1:11:50
a chart by yourself that normally we learn this concept in cubernetes training or we can get a lot of chart
1:11:55
available uh over the internet
1:12:01
okay or I can say we can get some chart repository from the internet repository
1:12:06
means so in internet there's a lot of communities who have created a contire
1:12:12
repository
1:12:17
Okay. And from this repository they give you lots of chart. One chart for WordPress launching, one part chart for
1:12:25
maybe gig PHP, one chart for be zoomla setup, one chart maybe for ll, one chart
1:12:32
maybe many more thing where all the common use cases chart you will find.
1:12:38
Okay. Only thing is uh in the helm. Okay. We have to set the repository.
1:12:47
So we I already have one repository of this guy.
1:12:52
Okay, because I launch a EKS or maybe I think this maybe previously
1:12:58
in my local computer. It's not from EKS actually. It's maybe there in my system but but we can add many more repository.
1:13:05
How? For example, if you just quickly search over the internet. Okay, we have a Helm chart
1:13:14
repository. Okay. And one of the famous reporter is Bit Nami.
1:13:21
Okay. Okay. So here you can get some link. So
1:13:26
maybe this one. So rep is you can think like a area
1:13:34
where you have lot of softwares. Here the software is called app. Health software app is known as chart.
1:13:40
So this is a one link of the so we can
1:13:45
we can write here. So I can copy paste and
1:13:52
put over here. That's all guys. Let me use our proper helm.exe. In my system guys I have two
1:13:59
version of helm. One is helm 2 also. So if I don't use the full command they
1:14:04
might take the helm two for my path. So the thing will conflict. So I'm using this full command name.
1:14:12
So this has been added. Okay. You can see this one more
1:14:18
repository added. Now in this repository there's lots of there's lots of
1:14:26
um charts available. Okay. So you can search
1:14:34
you can search Helm
1:14:40
search repo. Let's say I'm searching for WordPress.
1:14:50
So they they say yes they have the WordPress chart available. is a most popular blogging
1:14:57
tool and they have a chart available of WordPress with this part of the chart version.
1:15:04
Okay, so they have the WordPress available. That's what they're talking about. Same way you can search for kick, PHP and many more chart available.
1:15:13
Okay, but how to install is very very simple. You can install with the command. That's all. Okay, so what we
1:15:19
can do? We can tell my helm.ext ext that I would like to install
1:15:28
this particular chart and what this chart will do it will set up the entire multi- application for you
1:15:38
okay where in your current cubernetes system and right now in my case guys I'm
1:15:45
using this kubernetes so they will going to launch in this
1:15:50
cubernetes in this cub cubernetes. Okay. So, cube guys behind the scene use
1:15:58
cube config file to check where the cube is running. Similarly, Helm also use
1:16:04
your local cube config file. The same file what this cube is actually using to
1:16:10
know where your cubernetes is running. So, they're going to launch in your current cubernetes cluster. In my case,
1:16:16
it's called EKS Kubernetes cluster. Okay. So finally if you run this command
1:16:22
it will launch for you and here what I can do let me give this helm
1:16:31
uh what I say a name because you have to give the name also according to syntax
1:16:36
the name first you need to give the name then the chart name okay so name say let's say my Linux
1:16:43
world WordPress app and by helm will launch into a default
1:16:51
name space. But here my plan was to launch into the LW project
1:17:00
and right now this project we have no deployment, we have no services, we have no ports, nothing is there.
1:17:11
Okay. So I'm going to launch in the name space called LW project.
1:17:20
That's all guys. So entire setup what you normally used to do with one by one
1:17:26
right step by step has been done by this one command
1:17:31
one command the entire micros service setup entire you know uh setup of your all the port
1:17:40
connects right has been done in one go they also print something to you that
1:17:46
may be useful in some minute okay but they launch and how I know is they launch Now if you go to
1:17:53
your your normal cubernetes you can see in this name space the some port they
1:18:00
launch so they are launching WordPress and they're launching MARB it is more like a mysql it they launch a services
1:18:08
for you and because you know guys this is a EKS
1:18:14
cluster and in the EKS cluster if you give my service name load balancer so behind the scen they launch AWS ALP load
1:18:21
balancer that what they launch here that's what discussion we have done already in detail
1:18:26
okay and they also launch a deployment for the WordPress
1:18:33
okay so so one click guys everything has been properly
1:18:40
you know this in default name actually has been uh launch over here
1:18:46
okay then pending state it shouldn't be uh let me check why they into the
1:18:55
pending state. Okay, they're pending state
1:19:03
and uh let me describe this port from here.
1:19:10
Okay. Nothing is been
1:19:16
visible while the bending state.
1:19:21
Let's wait for some time. It will come up. But this is a again my focus area is again this is not the
1:19:28
Helm class guys. Neither the WordPress or port launching that you guys know from the cubernetes perspective. I'm
1:19:35
just trying to give a different approach here that we mostly use Helm. But this is not actually plan. But yeah, it will
1:19:41
launch otherwise we'll try to find out why then pending state. No pending state
1:19:46
mostly come when you're looking for the some storage. Storage was not there. You're
1:19:52
looking for um some u worker node. Worker node is not available and this
1:19:59
may more cases maybe that we can find out in some minute. Okay. Plus when you
1:20:05
run the helm command they also give you this output. this project has been deployed.
1:20:12
Okay. And your WordPress site can be accessible by this URL or but in my case we have a uh we have a
1:20:21
what I say uh load balancer. So we can access from outside world with the help
1:20:26
of load balancer. So these are the commands they give you that we know get command to see the status of my
1:20:32
WordPress load balancer IP address and we can use this IP address to connect.
1:20:39
after connect WordPress they ask the login a password username is this one
1:20:44
and password you can get from this command. So here they also created some secret of the kubernetes from there you
1:20:50
can get the password of the uh of the
1:20:57
WordPress site after they launch. Okay. So this page I will use sometime after
1:21:02
my WordPress launch is they are in the pending state uh to check out what
1:21:09
resource this truck because of this pending state would be we'll check in sometime if we need it but this is not
1:21:15
the main topic I just launch one application randomly here
1:21:20
okay so uh that's one thing we have done main topic is today is not
1:21:28
the WordPress nor neither the helm main topic is the container inside.
1:21:33
So our intention is to launch this application so can I can monitor this
1:21:39
application on the top of container inside tool
1:21:45
and for the container inside what we need to do. Okay. So for the container inside we
1:21:52
have to uh uh launch
1:21:58
we have to launch uh what I say we have to launch the fluentd
1:22:06
and and the cloudatch agent this is the requirement.
1:22:12
So technically if you have a two worker node. So in
1:22:18
both the worker node I have to launch puendi agent and and um
1:22:26
the um uh what I say the uh cloud watch
1:22:32
agent in both the worker mode. Okay for this
1:22:37
we have to do one more thing here. Okay. What we have to do?
1:22:43
We have to attach some rule.
1:22:48
Okay, because right now, okay, your
1:22:54
code is going to run on the top of worker node.
1:22:59
So I can say this pool is belong to worker node.
1:23:05
It means what a power we give to work on node in AWS talking about right. So again let
1:23:14
me explain this point I think in some of the class also we discussed but let me again reexlain. So this is a worker node
1:23:20
and for the as perspective this worker node is one EC2 instance
1:23:26
and if you want this instance will go to cloudatch.
1:23:33
Okay. and the cloud watch. Okay, this worker node they collect some
1:23:38
information the score metrics memory logs and they ask the cloud watch
1:23:45
to save there technically we want to put but cloudatch a defense service is
1:23:51
different service we can't connect guys we can't not connect is there but we can't we can we can't go and say just
1:23:58
put some data is not allowed so what we have to do we have to create a role
1:24:06
And this role we can we have to say EC2 you have a power to go to cloudatch and put the metrics there and put the put
1:24:15
the uh uh logging information there in the cloudatch.
1:24:20
This role we have to attach to our to our worker node. Why worker node? The
1:24:27
fluent and cloud version is a program actually maybe it's a p
1:24:33
but is a container and container is actually behind the scenes a kind of program running on the worker node if
1:24:39
you give a power to work or node technically this power goes to your to your container to board in this case the
1:24:47
board is uh is a fluent or maybe the cloud watch agent
1:24:52
okay so for this what can we do we have to create the role can attach this role to
1:24:58
the worker node. But interesting thing you know what happened guys if you launch your worker node with the help of
1:25:05
EKS there's internally some role they already created for you
1:25:12
and attached to this worker node okay no they already have
1:25:18
okay only thing is we should know the role name and just go and edit this role so
1:25:24
you don't have to get the IM role some rule is already there maybe have different some power.
1:25:31
So my requirement is I would like to know the name of that role.
1:25:38
So I can edit this role that is already pre-created by launching the EKS cluster.
1:25:44
Okay. How can identify? Okay. So for this what can we do? Uh
1:25:52
we have launched guys EKS with EKCL command. This is a command who launch this cluster.
1:26:00
And you guys know in this cluster we have a node group. Okay. So the worker node guys is
1:26:06
launched inside the node group. So if you want to know uh in this cluster
1:26:15
name my cluster one my cluster one. How many node group we
1:26:23
have? So there's only one node group I have. And in this node group I have a two nodes. Therefore we can see here two
1:26:29
node at this point I have three. Okay.
1:26:36
Now uh if you want to know this node group sorry this node group in
1:26:44
this cluster having two worker node which role they have attached with.
1:26:51
Okay. So for this what can you do? You can describe it or you can run the command called O output in JSON format.
1:26:59
So this command output here they give you in the JSON format a little bit more
1:27:04
in detail. Here they give you little bit more in detail uh some extra information. Mhm.
1:27:13
Okay. And what is information they give you here? Okay. They give you one information here
1:27:18
is this is a uh this is the cluster. There's a node group active to worker
1:27:24
node is running right now with M5 extra large and many more things they give you
1:27:30
here. They does not give you the name of the role even though they give here I think.
1:27:36
Yeah, they give the role uh that has been um
1:27:44
and that has been attached to this uh worker node
1:27:50
or you can do in the one more way to find out the detail of the role name
1:27:56
attached to the worker node. This is one of the way. Okay. Other way would be uh
1:28:03
you guys might know EKS behind the scene use cloud form
1:28:08
stack the name of the cloud for stack to launch the EKS cluster. So cloud
1:28:14
formation is the one who set up the entire EKS. Okay. Okay. So we can also ask cloud for
1:28:21
uh can you tell me um the detail about this stack which
1:28:27
role they create which role you create actually while launching the cluster.
1:28:33
Okay this also one of the way let me quickly show to you. So for cloud for is
1:28:38
a is a is a service from AWS. So we have AWS command you can install can this
1:28:43
command to local computer. Okay. And the cloud formation is one service here.
1:28:51
And the cloud formation what can we do? We can describe our stack. This called
1:28:57
ST resources. So one command that you can find in the manual of this cloud form
1:29:04
resources. And here I can give my ST name. You see you can see same thing from the
1:29:10
graphical also but I'm just trying to do from the command line.
1:29:18
So this is stack or there's a cloud for kind of automation program known as
1:29:24
stack here is the one who launched the EKS cluster for you they are the one who
1:29:31
launch all the worker they are the one who create a role they the one who attest the role and many more things they have done
1:29:38
so here guys they have created a lot of resources and here if you notice here
1:29:46
Okay, you will find the name of your IM
1:29:51
role somewhere. I think they might provide you if they provide it. Okay, so they will provide or where to
1:29:59
go more detail but there's many more way. This is one of the way I'm trying to show you. So, so here they might give
1:30:09
you the node role. Yeah, here it is node role and uh this yeah this is what node
1:30:16
role I'm talking about. Okay, so they give you this node role
1:30:22
here. This is what the role they use. So they say they launch a uh node group.
1:30:33
Okay. and node group will launch a worker node and worker node that is to this particular
1:30:40
role name. Okay, this particular role name and if you not guys is almost same, right? So
1:30:47
you can use this tool, you can use this tool is the same, no difference, right? Exactly same. But I need this role name.
1:30:54
Why? Because this is a rule attached to your EC2 instance and this rule is the
1:31:00
one who decide what power they have. Okay. So even though just if you can
1:31:06
copy paste this role even though let me copy not from this part this is your account name after slash you can copy
1:31:12
this role name and if you go to AWS cloud
1:31:18
okay and search for IM I am a service who give power to one
1:31:24
services to other services in AWS. So if you go to AM
1:31:32
and the role and if you search for uh a role
1:31:39
this one you can see this role is there right and if you click in this role this role
1:31:46
is talking about okay talking about that this anyone who have this role they have
1:31:52
these power they have power something to VPC for
1:31:58
networking. They power something on SSM or some cloud registry, container registry for getting the image and
1:32:05
uploading the image maybe. Okay. But they have no power with a cloud watch.
1:32:12
Okay. So this rule say I have no power for the uh cloud watch.
1:32:20
Okay. It means maybe in your worker node
1:32:29
maybe in the worker node you installed your agents they can collect the data but if you if
1:32:35
you're trying to send this data to cloudatch I have no power because this worker node attached his role and this
1:32:41
role have no power. So what you can do? You can add the uh
1:32:49
role. Okay. How to add? You can add from here or you
1:32:54
can add from the command line whatever you feel like. So if you know the command line way to add, you can use IM
1:33:01
atest kind of command. You can add or you can come add from this particular uh
1:33:09
graphical way. So let me add with a graphical way. All right. to make it things faster. So what I'm going to do
1:33:17
I'm going to add from the permission add policy. If you
1:33:24
search for cloud watch there are a lot of uh cloud watch
1:33:30
related uh thing come up and uh here you
1:33:36
can install this policy agent server policy.
1:33:43
Okay. So either you can uh attach the server policy depending upon guys what kind of thing power you need. So either
1:33:50
you can test the server policy or you can also you know admin policy also.
1:33:59
What difference? If you see the difference in here we have a power
1:34:05
in cloud was to put the matrix that's power we need.
1:34:12
Okay. And in the admin policy, we again power to put the metrics.
1:34:19
Okay. And put the logs also. And plus some extra power. They might also give you little SSM. I don't need
1:34:27
this. I think server policy is enough because I looking for to put the logs
1:34:33
and put the matrix. So server policy is a one predefined permissions. We can add
1:34:39
this. That's all. Right.
1:34:44
Okay. So this role we add one more power.
1:34:50
Okay. Ready to cloud was. Okay. And this role is already been attached to the
1:34:55
worker node. And in all the worker node why? Because this worker node is launched by node group. So we it
1:35:01
attached to node group. Technically attached to worker nodes. It means now all these worker node have a power. they
1:35:08
can contact two crowd watch to put the logs and put the metrics. That's what we're looking for.
1:35:15
Okay, it's a one time setup we have done. So what I did guys, I asked EKCL tool
1:35:24
to tell me the ARN of my worker node and I will go to this ARN or I can say IM ro
1:35:30
ARN I'm going to say and to add some power.
1:35:36
Okay. So this is one thing we have done and last thing is that is is the main
1:35:41
part of this entire game is to launch the agents.
1:35:50
So we are going to launch a fluent agent. We are going to launch the cloud watch matrix agent.
1:35:58
Okay. Plus those agents I or those port I can say agent will run as a port but
1:36:03
those port I'm going to launch with the demon set okay demon set. So this entire setup
1:36:11
setup I want to do and plus many more thing we have to do okay uh this port we
1:36:17
have to give a service account then attach some role of the cubernetes. So this port can go to other port other
1:36:23
things in the inside the cubernetes power if you want to give we can give with our of kubernetes.
1:36:31
So we have to create a service account we have to create a ser cluster role
1:36:36
role binding launching edge and lots of thing we have to do over here okay and
1:36:42
these things are pure cubernetes things to launch so I'm not going to write the cubernetes code I have the code with me
1:36:49
at this point in time this pure cubernetes code I'm going to run this code okay I'll share this code to you
1:36:58
okay so Let me get this code
1:37:12
that this is how uh this code look like. It's a pure cubernetes though we know Kubernetes is a very very simple code
1:37:18
nothing uh big. So technically uh we are going to get a separate name space
1:37:26
why nothing special because we are going to launch multiple port one for cloud watch agent one is fluent. So everything
1:37:33
we're going to manage in different name space in Kubernetes. We're going to create a service account
1:37:39
that's why I was talking about we're going to create a c cluster role.
1:37:45
Okay. So this role we give some power that anyone who have this role
1:37:52
will do something or put nodes or something in the kubernetes and what
1:37:59
they can do they can only see only see because I want looking for the information right about the logs and the
1:38:05
metrics that they can they can only see so this cluster role we are creating
1:38:11
okay and this cluster role we are binding to the service account. Okay. So, we are binding the power to the
1:38:19
service account or giving this power to the service account. Okay. And then
1:38:27
what we are doing look I'm going to create a cloudatch agent. So cloudatch agent guys has a
1:38:33
config file. So I'm going to create a config file for this guy as a config map. And here I asked them that my agent
1:38:41
is running in the region of Mumbai. If your reason is different, you can change here.
1:38:48
Okay. And they're going to collect the matrix. So I'm the Cloudatch Agent file. My requirement is to collect the matrix
1:38:54
from my EKS cluster. Only thing is guys here my cluster name is different. So you can ask EKCTL get
1:39:03
cluster command. Not EKL again. See yeah EKT EKS CL get cluster because you might
1:39:10
have multiple cluster in Mumbai. So I say my cluster one is the name of my
1:39:17
cluster. So this cluster running in Mumbai in my case
1:39:24
go here and and this is a Kubernetes cluster collect the metrics every 60
1:39:30
seconds. Okay, this what they're doing. And
1:39:37
finally uh this config map we create config map is like a configuration file
1:39:43
in the kubernetes we create then we're going to launch a
1:39:49
agent as a container. So this is a cloudatch agent we are
1:39:55
launching who is going to collect the matrix as a container.
1:40:03
Okay. As a container and container become a port and this port we are
1:40:09
running not as a deployment as a demon set.
1:40:14
Okay. And why demon set? I explained to you three node running three port will launch 100 nodes running worker node 100
1:40:21
port auto launch per worker node one port
1:40:26
that's what we launch here. So this is this this file is almost like a deployment code you know deployment only
1:40:33
thing I just changed this term to deployment to uh to demonstrate otherwise the same the this this code is
1:40:40
same as the deployment code okay the agent we limit the resources agent
1:40:47
doesn't use more resources okay otherwise nothing
1:40:53
important here okay next thing is
1:40:58
is this is a a generated thing. We giving some extra uh folder path and all
1:41:03
the things right and next thing is in this container I'm going to create one
1:41:10
more uh config map for the logs.
1:41:15
Okay. And here my cluster name is my cluster. Let me update again. So for this cluster
1:41:22
in the Mumbai region we are going to create one more config map that will
1:41:27
store your cluster information. What is the cluster information we store in different config map
1:41:33
okay and I'm going to create one more service account this for fluent D.
1:41:39
Okay. So we have two port or two agent both the agent running different port
1:41:45
and every port we are going to give a different power. So two different service account we
1:41:50
create one service account we already created one service account for fluent.
1:41:56
Okay. Uh fluent and again this account I want to give some power. What a power
1:42:03
fluent need fluent is more for log. So in my cluster whoever generated the log
1:42:11
I will give those resources a power so they can get the log
1:42:16
and this power I'm going to give to a fluent account this role binding. So
1:42:21
fluent account will will have this power okay or this power I guess.
1:42:28
Okay then this is the config map and this is a config map for the fluentity. So fluenti is a third party tool. They
1:42:35
also have the config U uh config file. So the config file
1:42:41
look like this. The pure pure config file for the
1:42:47
fluent whatever they're doing in the config file is not right now important. Uh but this internal conf file for the
1:42:54
fluent they're collecting the metric from somewhere in some format. So the fluent pure configuration file.
1:43:04
Okay. But here they using this keyword, right?
1:43:10
Okay, this keyword. So they are fetching the information of AW region or the cluster name from a config map, right?
1:43:20
So the config map I created here uh over here where it is
1:43:29
this one. So from this config map
1:43:35
they are retrieving the information about your cluster name your region name
1:43:43
okay that's what they write in the code fluent
1:43:48
okay and many more thing in the fluent we can do and configure okay that's what they're doing here it's
1:43:54
a log big file for the fluent fluent has no relation with AWS neither with
1:43:59
cubernetes independent tool we can install separately also in other system to get the data
1:44:06
and again I'm also launching fluent as a demon set okay so we are going to use some image
1:44:15
one image they're using and on the top of the image we are going to launch the fluenty again as a demon set okay so
1:44:23
that's what we using this account this account give power to fluent
1:44:29
deport port they can get something and we are using some flu and deleted
1:44:34
commands okay and launching in the same region where they we are using the as cluster
1:44:42
no AKS cluster okay that's all guys so look like big
1:44:49
file look like complex but is not okay if you know kubernetes
1:44:56
then then you we can very quickly understand this code. Otherwise, this is
1:45:02
a kind of standard file. You can get from the internet also in GitHub also. I also download from somewhere in the GitHub only.
1:45:09
Okay, it's a kind of standard file. Only thing is you have to use this file. Do some small changes. What are the change
1:45:15
I ask you to do? Do your changes and run it. That's all. Sorry. How to run? So,
1:45:22
this file right now in my download folder.
1:45:28
Okay. and I'm going to run. Okay, one more thing I have to change here in this
1:45:34
file uh to change in this file because I am
1:45:40
using a different name is piece.
1:45:46
So I am going to launch my everything in a different name space
1:45:54
even though I don't need to render the name space I believe. Walmart let me check which name is they're using this
1:46:00
name space is okay that's what I asked in the top two to launch there
1:46:06
but let me check uh
1:46:12
cluster name space cloudatch cloudatch cloudatch
1:46:19
I'm just checking the name space I think they there might not be use some other name spaces demands are
1:46:26
also cloud that's So thing is good right? Uh so let me guys run this. So how to run simple
1:46:32
cubectl apply this file that's all. This is a
1:46:38
kind of standard file guys. Okay. Uh just go and apply. Finally one
1:46:44
file what they do they will launch
1:46:49
two independent agents.
1:46:55
Okay. the two different port in a different name space. So if you search for cubernet get name space. So first
1:47:02
they launch this name space.
1:47:08
Okay in this name space they launch lot of thing about security in the cubernetes perspective and finally they
1:47:14
launch a demon set. Okay. So in this name space if we search
1:47:20
for DM and demon set in the name space called
1:47:26
cloud watch you can see this name this uh dimension
1:47:32
created and interesting about demon set is they say this clatch
1:47:38
I launch as a demon set. It means it will finally launch a port. But
1:47:43
interesting thing is demonstrate will automat identify how many nodes you have
1:47:49
because you have two nodes to two agent they launch of cloudatch and two agent
1:47:54
they launch influently and they always launch guys
1:48:00
format they always launch in a different different worker node. So if you see oile
1:48:07
okay you never see that both will run in same worker node right
1:48:14
so here this will launch a different worker node and this will launch a different worker node and this will run
1:48:20
again different different worker node right and automate identify how many worker
1:48:26
nodes they have they have two worker node so one guy launch here one launch of the one guy launch in first they
1:48:32
launch second because the demon And finally, if you notice, my port is
1:48:38
running successfully. Okay. And what this port has, this port
1:48:44
internally has uh one service account
1:48:50
attached. This service account attached to this one. Fluent service account
1:48:55
attached to this port. And this service account has some role binding.
1:49:04
Okay, some power and what power they have? So this port
1:49:09
can go inside the Kubernetes. This power we are given to Kubernetes perspective. This can go inside the Kubernetes get
1:49:16
some information on metrics. This can go inside the Kubernetes to get the information about logs.
1:49:25
Okay. But these are a port container running on the worker node.
1:49:33
Now after they take the matrix they're trying to send the matrix to cloudatch
1:49:38
but worker node where they guys are running they're running on this worker node worker node has IM ruler test and
1:49:45
because the IM role this as a port but technically for the worker node perspective is a container or service or
1:49:51
a program running on the worker node. So with the power of work node IM power they can connect to cloudatch.
1:50:00
Okay. And send the matrix and log information there.
1:50:06
It means whatever have set up I have done till now guys if is it is right if
1:50:12
I didn't miss anything here especially in the security perspective maybe. Okay.
1:50:17
So what you will see now if you go to cloud
1:50:22
watch. Okay. Last time there was nothing.
1:50:29
Okay. Even though even though there's a guys one more thing in the car was called log
1:50:36
in the log if you go go and check okay you can see this thing right it was
1:50:42
not there it is just yet created right okay you can see the information of my
1:50:48
cluster one is coming right this your cluster name okay and all the logs that been sent by
1:50:56
fluentd store over here. Okay. And this is what this folder just
1:51:03
now created. Plus if you go to go to
1:51:08
container inside okay last time guys there was nothing right even though still there's nothing
1:51:15
but make some time actually it will come up right it will come in sometime okay some
1:51:22
information to be uploaded here or let me check some other information like container perform monitoring
1:51:28
in sometime you will see yeah see here name come up right this one come up so
1:51:34
if You see the performing automatically your cluster name also populate here they know your cluster name and plus you
1:51:41
they will say what you want to know. So now from here guys all the EKS things
1:51:47
going to come up here how much EKS node we have. So this is a node related information.
1:51:53
Okay. So all the information related to node going to come up here. See this also come up right the entire visibility
1:52:01
of the cluster we have here. They say web cube system
1:52:08
name spaces. If one of you s see also right we have a
1:52:14
no this cube system name spaces. Okay have running with these ports. Uh
1:52:22
this name space running with this port. Okay. Or maybe can sign next for how to check
1:52:30
next. But you can see this information going to come up. from the uh system and you can sort by
1:52:37
CPU sort by memory okay all those thing uh you can do so
1:52:42
all the thing guys you know metrics information going to come up right or there's a kind kind of graph they create
1:52:47
or dashboard they create you can customize it or we can see about
1:52:53
name spaces okay so we can see the CPU per name
1:53:00
space wise memory by name space wise space details. Okay, so there's a name space detail uh
1:53:07
going to come up name space and how many port they're using, how much CPU. So this name space using this percent of
1:53:13
CPU at this point in time. Okay, so it's very straightforward now.
1:53:21
Okay, lots of things we can check. Uh E ECS we don't have. I'm talking we have
1:53:27
to EKS, right? And if you talk about the port perspective,
1:53:36
okay, so these much CPU and memory or network used by a port at this point in
1:53:43
time, okay, and they're coming on the real time guys. Maybe some delay of 60cond
1:53:49
that what we can change also in the cloud cloud watch matrix conf file in the
1:53:57
config map but this is what they are populating here right like I said these
1:54:03
information coming purely from EKS cluster right but in it is lended to
1:54:09
your your container set okay you can change this
1:54:15
this remaining thing is pure cloud watch thing right. So you guys know in the
1:54:20
cloud watch this is the d going to come up. Okay this is from
1:54:26
performance mon going to come up. Okay we can change the timer. All right
1:54:34
we can add to dashboard. All the thing we can do from here we can also view in
1:54:40
map. This is very beautiful thing they give you here. They create entire map actually. So in this cluster
1:54:48
okay the cluster name my cluster one they tell you the entire CPU memory utilized by this entire cluster
1:54:55
okay and plus they also give this map this is a beautiful thing right so in
1:55:00
this name space these are the port running in this name space this is total
1:55:06
utilization of RAM and CPU and these are two port running and there's a per port wise detail so entire map they show you
1:55:14
about the cluster. Okay, this about the cluster.
1:55:22
Okay, but only information has come to this guy is depend upon the cloud agent
1:55:27
and the fluent depend which name space they're reading, which name space they're correcting the
1:55:32
information. So we change the cloud watch agent file.
1:55:38
Okay. So those who just part of my as training like CS level training there I explained about how to configure the
1:55:45
cloud config file how to configure it. If you change something in the config file depend upon whatever you are
1:55:52
fetching those information will be uh come up here. This is interesting guys
1:55:58
graph they give you more clarity. We click here that particular details going
1:56:04
to come and now because the information is coming in the in the cloud watch
1:56:12
okay you can create dashboard or you can create alerts also so we can write the if any part goes
1:56:20
about 80% send the notification so we can get alerts
1:56:26
alarms and for sending the alerts we can use SNS.
1:56:32
Okay. So this metric information guys you can collect and send the send the alerts or for creating the alerts you
1:56:39
can use this part right from here. Alarms you can set the alarms.
1:56:45
Okay. So everything going to come as a matrix. You can see here there's a new name
1:56:51
space going to create in a matrix of of cloud watch contain inside. And here the
1:56:57
all the information going to come up. So you want to see the information per node wise for example
1:57:04
this inform going to come up. So in this cluster okay the port number of
1:57:10
container restart or or there's a port name code DNS cube
1:57:18
proxy there's a lot of port uh this is a port we launch right now so all the information are going to come up here
1:57:26
okay come up here even though if you launch your own port also that's information going to come up here till now my my
1:57:33
WordPress does not launch because there might be some uh where I launch actually I launch in
1:57:40
LW project
1:57:45
okay still in pending state I have to check maybe they're looking for some storage I don't have but those who was
1:57:52
part of my EK training initial class I talk about PVC and all the things so if it is the PBC story class they may be
1:57:59
one challenge they are still waiting okay so but to just take this thing demo
1:58:06
very quick. Let me create deployment manually. So I'm going to create a deployment my d
1:58:13
I'm using the image let's say httpd
1:58:18
and launching my default name space right now. Okay. So what guys in some
1:58:23
time the information about this port okay will be
1:58:31
will be uh populated to the uh to the
1:58:36
cloud watch okay and this port okay for example this port code one port running
1:58:42
somewhere how much memory they use
1:58:48
and click here after click they will create this kind of graph here real
1:58:54
time. I can monitor or I can do some actions.
1:59:00
So here's a CSV file, right? Or I can see the logs of this guy or I can write
1:59:07
a graph matrix or I can write alerts.
1:59:13
Okay. And when you when you create alerts then you can connect to any SQS
1:59:19
or SNS and all the AWS kind of thing right. So those who know AWS then you
1:59:26
guys know SNS and SQS how to create the alert side. So from the here alarm
1:59:35
you can go and create the alarms and here you can select the metrics from
1:59:40
the contain side. Let's say let's say I want to connect with the
1:59:48
name space perspective. So my cluster is one name space.
1:59:53
So my cluster is a one cluster name and in this cluster name there are a lot of name spaces they have. Okay,
2:00:01
this is what they have. So in this name space if my this particular
2:00:07
detail select material I want to select okay and if my memory go above
2:00:16
this let's say 100 for example then I will do something what I will do I will
2:00:24
send a email right so SMS so again this is not the class of guys cloud was
2:00:30
neither alarm so those who know basic CS1 level training there we discussed this topic in very detail set up
2:00:35
everything I'm not going to set up this part right now very simple just go and create SMS topic okay
2:00:43
and uh send the emails so any will any port will go about this particular memory they'll send the SMS to us okay
2:00:52
or email to us or many more thing with SNS we can attach we can attach with SQS also to collect some data and send to
2:00:59
SQSQs or other processor Okay, that also we can do. But my main
2:01:05
point here is now information is collecting and reaching to cloud watch. After
2:01:12
information reach to cloud watch. Okay, reach to cloud watch. Okay, you
2:01:19
can perform any activity whatever cloudatch can do. Cloudatch is great in
2:01:25
monitoring purpose, great in creating dashboard, graph reporting, creating
2:01:30
alarms, all the things Cloudatch can do. Now you can utilize the entire Cloud Watch
2:01:37
skills, okay, to uh to to do any further
2:01:44
automation maybe or any other uh you know alarms and uh notifications all the
2:01:50
things you can do from here. Okay. Now this this is what guys this uh this is a content map that I will explain to you
2:01:58
over here. So this is how you can install the agent of fluent. Even though you can see the the uh logs also here
2:02:07
log group in the logs group lots of log is going
2:02:12
to come up. See a lot of log is coming up. So if you talk about the log of the host
2:02:18
okay so the log of the host going to come
2:02:24
okay and just quickly if you see the host this log see because two nodes we
2:02:30
have right host means worker node worker 94 worker node 117 so both the logs also
2:02:36
coming to us if you see the message log so these are the logs going to come up
2:02:46
So if you guys know in the worker node is a Linux system and Linux has a log file called message file and message
2:02:52
file is one file very important in the log in a Linux OS that contain lots of
2:02:57
important messages service start all the log of the worker
2:03:02
node is coming to us who picked this node fluent and send in the cloud watch
2:03:09
log okay our performance also data clean log
2:03:14
also two node we have all the
2:03:19
worker node logs come to us okay so the log related to data plane
2:03:27
means more about EKS some operation field they are trying to
2:03:33
mount or maybe guys this is also a location where you can find out maybe some of my port is looking for mount
2:03:39
something uh they They got the mount point they mounted. They might not get
2:03:44
the mount point they fail. So he can use this locks to further troubleshoot any
2:03:51
challenges he face. Okay. So again this is not a locking
2:03:57
class. So nothing nothing much I want to discuss but but my point here is
2:04:03
okay. This is how your setup has been done. This file I will provide to you.
2:04:08
Only thing is you change your cluster name or the region name otherwise this file is standard file. Some more change
2:04:15
you can do if you want but this same file also you can use as it is rule watch. And this is guys about
2:04:24
cloud uh watch container insight insight I can
2:04:31
say and this is also the
2:04:37
the how to integrate with fluent and cloud vent to collect the collect the
2:04:45
logs. Okay. So that's it about this topic.
2:04:50
There's one more two more discussion I have to do guys here today's class a very small discussion then the the the
2:04:58
training will be completed right so before we do this discussion right we'll go for quick Q&A or or any uh go for a
2:05:07
small break also then we'll continue but before the break guys I will also tell you one more small thing tomorrow we are
2:05:13
launching uh one very important training okay around 12 hours Okay, some around 6
2:05:21
hour we'll do tomorrow. Next remaining 6 hour we will do next Saturday is one tool that I think most lot of guys are
2:05:28
asking from last couple of months. Okay, again this is the first batch we open for the public
2:05:35
normally we do in the corporate world but this tool is is very much required
2:05:41
in almost in all the projects. So if you if you create any bigger system design
2:05:46
any bigger architecture okay this tool is one tool that always
2:05:51
you will find and always in the job description this tool you always find
2:05:57
okay very important tool very interesting also name of the tool is called Kafka
2:06:02
okay so we are we are launching and launch actually the Kafka over here the
2:06:09
detail of the Kafka What content we are going to cover you
2:06:14
will get from our website my team will share the link to you. Okay. Interesting thing is this this Kafka come as a kind
2:06:22
of advanced tool. Okay. Even though we are going to start from very basics to all the advanc with all everything would
2:06:29
be pure de practical but because normally this tool come in as a advanced tool. So the if you just talk about the
2:06:36
market price is very high actually. Okay. Okay, we search any random site
2:06:41
who are offering this Kafka. Okay, maybe simply learn or intellipad or I just
2:06:47
checking randomly. There's no uh anything. I'm just checking randomly there some site. Okay. So price is very
2:06:55
high 15,000 20,000 for the Kafka content. So what we have done guys even
2:07:02
though from this side you can find out you know the who is the users of the Kafka right almost every company in the
2:07:07
world top company who have the bigger system design uh they're using Kafka a
2:07:12
lot and every top jobs they they use uh
2:07:18
they want Kafka developer to be as a as in the job discussion you will find a
2:07:23
Kafka to be used right so obviously this is not our website I'm just checking randomly and so there's no nothing about
2:07:32
I'm just checking randomly but what I'm trying trying to tell you here is okay we my trying to make the content such a
2:07:37
way that is cover almost everything about Kafka biggest content kind of Kafka
2:07:44
plus all the practicals or use case to be covered in the demo okay but we make
2:07:50
try to make the price very very low so anyone can afford it so we're not
2:07:56
charging 10,000 20,000 rupees uh mostly we'll try to promote all the biggest
2:08:01
content in the more affordable price so that anybody can learn it.
2:08:06
Okay. So this is the only my own live class because normally this kind of tool
2:08:12
I don't again deliver. So if you want to learn this tool live with me so this is
2:08:18
very very uh uh very much in the kind of
2:08:25
uh a comfortable price. So my team will update you guys about the pricing and the link of the content what we are
2:08:31
delivering right tomorrow we are starting uh and I recommend guys so those because you guys for micros micros
2:08:39
service background or kubernetes background system design background
2:08:45
uh AWS architecture prospective background data engineering big data any
2:08:52
of these guys maybe devops guys engineers cloud architects. So these are
2:08:58
the few top category of professional uh
2:09:04
Kafka is always recommended right so if you want to go join I will we'll share the link of the content you guys can go
2:09:12
through content and then we'll see you tomorrow in the Kafka training okay but
2:09:17
it's only batch live from my side that we will do that's all so uh so one thing
2:09:25
guys we have covered right now is um is about the cloud
2:09:33
watch insight plus the agenda right any query if you have till now you guys can ask me then we go go for a small break
2:09:40
and that's for some more information basic discussion to be implement and discussed then we'll conclude the
2:09:46
training
2:10:01
So um so can you share the entire comment? Yes. Ainas uh what we will do we
2:10:08
actually we are doing it. Okay. uh so
2:10:14
uh my team will create this PDF right that's they always do per class wise and in this PDF they will give the entire
2:10:21
flow of it and there the command also going to come up right plus this code we will provide you separate this code
2:10:28
we'll provide you separate so you can use this code or the kubernet file to perform it okay
2:10:37
you're saying something I'm 3.0 Zero student.
2:10:49
So Marin definitely you can connect me or whatever problem you have you can ping me. You might think you might have
2:10:55
my number. Okay. So you can ping me and we'll definitely surely connect today
2:11:01
evening. Right? So Mon you can ping me on WhatsApp and we'll connect. We'll discuss.
2:11:08
Can we integrate container inside with Splunk? Answer yes sort of you can do.
2:11:15
uh I don't know guys if you are sort of you part of my uh last class okay where
2:11:22
I saw uh it's not part of EKS training guys but I invited some of other groups
2:11:28
where I show how we can indicate Kinesis fire hose with plunk
2:11:36
okay so same approach uh sort of you can use
2:11:41
okay so you can use so Um um
2:11:47
uh you can use cloud watch that can feed the log d to the plung that's also
2:11:55
possible if you watch my my splunk training this is something kind of demo I show you in my splunk classes how to
2:12:01
get the log directly from the cloudatch to the splunk or you can feed the
2:12:06
cloudatch log to the kinesis fires and from the kinesis firewall you can also
2:12:12
send to a destin So called Splunk that's also a better approach you can use. So
2:12:17
answer is yes and you can integrate cloud watch tools plug when I say cloud
2:12:23
watch is cloud inside also going to come up the cloud inside sorry contain inside
2:12:28
contain side is just a way to manage the container information but technique is managed by cloudatch only
2:12:36
okay but it's a dedicated dashboard here
2:12:42
dedicated dashboard here and that is manage and giving information dedicated
2:12:47
to containers. But technically what information they giving you here is
2:12:53
metrics or the log that is a core duty of the cloud that you can see from here also in normal metrics and normal logs.
2:13:01
Okay. So whatever you can do with the cloud same thing you can do with the contain set.
2:13:08
Okay. You can think in this way
2:13:16
I'm intermed but I like the content as well. Nice.
2:13:22
Yes, I upload this codeand in the GitHub. We'll provide the link to you.
2:13:28
Ash this topic we have covered already. So those who are in the developer track
2:13:34
code commit code pipeline code deployment boto okay everything is been
2:13:41
covered and we have given the video recorded from my classroom training that I told you multiple time in my classes
2:13:48
also that most of the content I cover here live some of the content I I'm not
2:13:53
covering here in in this live training but I'm giving a recorded that two for my classroom training only so it look
2:13:59
like a live and that those content we have
2:14:04
uh provided in your hashtag portal. Even though uh instead of code commit
2:14:10
code deployment I use one serverless
2:14:15
framework to deploy and manage those things also that is also part of my uh that
2:14:21
recording right. So I asked my team they will again ping you where they can find these videos in the hashtaging portal.
2:14:29
Okay. And that's it. And boto3 guys if you actually remember
2:14:35
lot of practicals like initi lot of places I keep on using boto3 plus my in my training also you can find some
2:14:42
initial starting video of the boto3 how to use and get the boto3 programs but a lot of classes we have covered boto3. Uh
2:14:50
again this is not a pure boto3 training even though if you go to CSA developer track with very basic overview they
2:14:56
cover. Okay. But I covered a lot of thing about compared to what is there in
2:15:01
my in our developer track.
2:15:14
So Kafka training is not done for earth one or two student.
2:15:20
If Kafka was the part of one or two earth we'll definitely provide it.
2:15:26
Okay, we definitely provide let me check if a part of it
2:15:33
uh the as a content of earth one and two we'll provide a link to you you don't you don't guys then don't have to
2:15:39
register so it will be free for you if it's a part of the content of earth one and earth two okay
2:15:47
this one
2:15:53
is I am sharing my mobile number this my WhatsApp number you can ping me we'll talk if any challenge you're facing I
2:16:01
will help you okay so I'm just sharing my WhatsApp number ping me we'll talk in
2:16:06
a minute okay so while open and eks no it is not
2:16:13
similar at all open is also behind the scene is uh
2:16:20
using kubernetes engine okay ease is a kubernetes management tool.
2:16:28
Okay, Kubernetes management tool means
2:16:34
EKS will give a work on node, they give you a storage, they give you a RAM, they give you a upgrade, they give you um uh
2:16:43
load balancer. Okay, those what EKS give you is a Kubernetes management tool. Open C is a
2:16:51
entire container life cycle management tool.
2:16:57
Entire life cycle of the container in the perspective of managing the application that opens shift do. One of
2:17:04
the part of the open is is is not to manage Kubernetes. Open shift
2:17:11
part is to use the cubernetes engine behind the scene by end to end content
2:17:17
management tool. Okay. So if you launch any application what do you need?
2:17:23
For example, you have a code in GitHub. You want some web hooks.
2:17:30
Your code will download convert the code automatic in the images. It is not done
2:17:35
by EKS or other cubernetes, right? So, we download the code, convert the code
2:17:40
into contain images automatically. Then image, they store in the their personal
2:17:45
registry, then they launch that deployment. Okay. Many more things they will do. I'm just giving a very quick
2:17:51
overview and difference, right? So in the simple term OpenC is a container platform to manage entire end
2:17:59
to end life of the container or application that run on the top of container.
2:18:05
Okay, it's a full-fledged container management tool and guys open is huge in demand in the market and the demand is
2:18:12
going to increase like anything because now open is part of Red Hat. is always
2:18:18
with red but is part of IBM and all the further development of the IBM they are doing on the robot on software.
2:18:25
Okay. IBM now every company is behind the uh now has been a war of AI
2:18:32
especially in the generative AI and uh IBM has launching
2:18:38
um their product related to generative AI and this entire project they have
2:18:45
launched on the top open sift okay launch on the top of open shift
2:18:51
okay and just one example right so there's huge demand of the open sift is going to come up. A lot of guys might
2:18:58
know also open open sift here. But let me show you uh if you search one video
2:19:07
of generic AI for business. Okay. So if you search this this term in
2:19:15
YouTube, you will find this is a 13 day before announcement from the IBM. Okay.
2:19:22
You guys might know the Watson is a product from from IBM but they launch Watson X
2:19:28
okay with lots of capability especially for the business purpose
2:19:34
okay business purpose and uh this entire Watson X
2:19:41
okay entire X guys if I very quickly share the sound also they're deployed on
2:19:49
the top Hello,
2:19:56
welcome welcome by somebody asking just to share this
2:20:01
data just think carefully about whether that's the world you want to live in as
2:20:07
an AI value creator on the other hand you have multiple entry points you can
2:20:13
bring your own data and AI models to Watson X or choose from a library of
2:20:19
tools tools and technologies you can train or influence training if you want.
2:20:25
You can tune you can have transparency and control over the governing data and
2:20:30
AI models. You can prompt it too. Instead of only one models, you will have a family of
2:20:38
models. And through this creative process, you can improve them and you can make them your own. your own models.
2:20:45
Foundation models that are trained with your data will become your most valuable
2:20:51
asset and as a value creator you will own that and all the value that they will create
2:20:58
for your business. So don't outsource that. You can simply control your
2:21:04
destiny with foundation models. So that is ready to be tapped to train
2:21:10
and fine-tune data. What's an X.AI. AI what's anx
2:21:15
work together seamlessly throughout the entire life cycle of foundation models
2:21:21
and true to our commitment to hybrid cloud architectures Watson X is built on
2:21:27
top of Red Hat open shift okay so that's what guys I was talking about
2:21:34
so there's a huge uh demand you know geneti going to come up everybody in the
2:21:40
behind this race IBM is again company who have a different approach. they are
2:21:45
creating the watch X for the business guys uh and they they are is a kind of
2:21:53
B2B okay and uh the underlying architecture will be they where they
2:21:58
deploy entire X will be open sift right and that may be one of the reason why in the IBM has a huge demand of open shift
2:22:05
sen happen right in the terms of job they're doing a lot of training consulting of the open sift right and if
2:22:12
IBM has this demand automatically this command command will come in other companies also. Right? So my point is
2:22:20
cube is a huge demand, container has a huge demand but to have
2:22:26
an entire container management open safe will actually the final
2:22:32
product going to use in the market. Okay. a lot. So those lot of guys might know
2:22:40
the open sip but somebody asking me just wanted to tell you uh this
2:22:46
this u you know information over here generative AI uh guys we have launched
2:22:53
generative AI course in Linux world and not only generative AI we launch a very
2:22:59
different kind of concept in generative AI this called generative AI ops
2:23:06
Okay. And same thing why this the guys the guy is also talking about over here what this guy is talking about they say
2:23:12
company everyone is talking about gen AI is a pre-created tools
2:23:18
okay but company need their own custom models okay and those custom model also to be
2:23:25
automated so they are building X to create their custom model per use case wise like microA solutions
2:23:33
and there we need generic AI ops Okay. In similar line guys, even this
2:23:38
announcement was around 13 days ago, but before the 13 days, we Linux word has launched their own generative AI ops as
2:23:46
a as a training program. But that program is not open for public right now. Generative AI ops.
2:23:55
Okay, it is only open for in our we launched this thing first time but is
2:24:01
only open for our summer program, right? So anyone who part of summer program
2:24:07
summer intensive program I can say is open for them and that only for offline
2:24:13
no online. So this time guys Japur we are getting a big very big summer program
2:24:19
uh okay four to five days for engineing student where uh these guys can come
2:24:25
learn under me. I will be also there physical right with these guys and where
2:24:31
they can learn they will research lots of new innovation products we will build
2:24:37
and sec showcase to the industry investors and many more plans we had and
2:24:42
more main focus area for this year guys in our summer program would be on generative AI ops and how to build the
2:24:50
tool from the scratch. So lots of things we are doing there but it is not online
2:24:56
it is only offline then AI for offline yes you can join our machine learning course that we have launched
2:25:04
okay uh you guys can join machine learning that cover all missing about the machine
2:25:10
learning but if you talk about genetic AI ops as a dedicated concept is there
2:25:16
only in my offline right now
2:25:21
so probably there's no plan for some month at least to deliver geni ops online. You can learn machine learning,
2:25:28
deep learning, reinfor learning, NLPs, right? And transformer GANs and
2:25:34
something about JDI basic level to my uh
2:25:39
machine learning course that we launch. But but
2:25:45
uh AI ops is not launch online. Offline is is the only option.
2:25:56
So can you please provide the JDI offline online? I I I like to live far
2:26:01
from Japur 36 hour journey. Okay. I didn't know Hindi. No R don't worry. uh
2:26:08
if if you want to come offline, I think almost from every corner of India
2:26:13
students coming from Kerala, from Agatala, from Jammu, from Bangaluru, uh
2:26:20
Chennai, Pune, Goa, I think every city, state
2:26:26
like everyone is coming to Japur uh and stay here for 45 days and we we
2:26:32
will be there here to train you. uh offline I also there offline and if you
2:26:40
say I don't know Hindi does not matter a lot of guys from from multiple area they just don't know Hindi so language won't
2:26:46
be the bar barrier here right so whatever the basic knowledge of English if you have that's okay to to communicate to to the local
2:26:54
peoples
2:27:02
so any of the queries related to today's topic
2:27:14
So I'm currenting doing my intent DevOps engineer. All thanks to you sir for this achievement. Right. Nice. No hit. Great.
2:27:22
Okay. So so Ravi will update by evening about the
2:27:28
Kafka for Earth 102. Don't worry by the evening we'll update it in your group.
2:27:33
So that's all guys. Let's go for quick break around 20 minutes or 25 minutes
2:27:38
and there's some more thing to be had to discuss then we'll come to uh conclude this training right I see so after 25
2:27:45
minutes we'll continue
2:56:57
Okay. So, good afternoon everyone. Uh if you have any queries till now, you can ask here and Vimula would be starting
2:57:04
the session uh after 20 minutes.
2:59:51
Uh yes, someone is asking about entire topics of Kafka covered under 12 hours. Uh yes that will cover all the topics.
3:02:57
Hello guys.
3:03:30
Hello guys, um sir will join in a few minutes. Before that we will see how we
3:03:36
can launch uh RDS uh in AWS cloud. So RDS is nothing but a
3:03:42
managed service in a AWS cloud. Okay. So RDS is nothing but the relational
3:03:47
database service. It is a manage service in AWS. Using that uh using this service
3:03:53
we can manage our database whichever database uh we want we can manage the
3:03:59
manage that database. Okay. So we will see the practical. So firstly uh let me share screen.
3:04:16
I hope screen is visible. Okay. So for launching the RDS database
3:04:23
uh simply search the RDS. RDS RDS is nothing but a relational database. Okay.
3:04:31
So after um after this you can see this kind of screen. After this click on
3:04:38
create database. So uh here you can see the you can see
3:04:44
uh there are total two method standard method and easy method easy uh method.
3:04:50
So here we choose a standard method and after that we will we can see there are
3:04:55
multiple um database um for example or then MySQL, Mariab, Postgres SQL, Oracle
3:05:03
here we can choose as per our requirement. Okay, for example here we choose a MySQL.
3:05:11
After this um here we can see there are multiple version. We choose a by default
3:05:17
version of the MySQL. Then there are multiple template
3:05:22
available. We choose a free tier. As we have account in a free tier so we choose
3:05:28
a free tier. Um we have another two option for template production and de uh
3:05:34
de test according to our requirement we can choose. Okay.
3:05:42
Then uh we can type our database name. For example, here we type my DB1.
3:05:50
Then uh here we uh set up our credential. Um and we type a name as a
3:05:57
master username as a admin. Okay. Then here uh for generating our
3:06:04
password we have a two option available. We can uh generate a password automatically. Okay. Or type the name of
3:06:13
the master Then u for generating password we have a two option. We can uh type u password
3:06:21
manually and autogenerate. If you click here then password password will generate automatically then we will get
3:06:28
that password after creating the database. But if you want our password we have to type if you want our password
3:06:34
uh manually then we have to type the password. So simply here we type a
3:06:40
password
3:06:45
then confirm the password.
3:06:51
After this uh next uh part is instance configuration.
3:06:56
We can choose the DB2.micro. Here we will get a 1 GB RAM and one CPU
3:07:05
storage type. Uh here we will get a multiple storage type. We will uh we can choose our according to our requirement.
3:07:11
Then this is a storage. This is a threshold. Then uh next part
3:07:16
is a connectivity. So after creating the database uh if you want our database uh
3:07:22
we can um if you want after creating database we have to connect that database right. So for connecting we can
3:07:30
connect that database to our instance. So for this we have to choose this option connect to an EC2 instance. Okay.
3:07:37
So this is the option and after um choose this option we have a option for
3:07:43
choosing EC2 instance. So if you click here then we can see there are multiple
3:07:48
instance we which we already um which we already uh launch. So we can choose one
3:07:55
of the instance. For example here we choose this instance.
3:08:02
After this we have a DB sub sub uh subnet group. We can choose uh manually
3:08:07
or we have another option that is automatic option.
3:08:13
Then if you want uh public then we can uh choose public. Then VPC.
3:08:20
This is a uh security group. We can choose default. Okay.
3:08:26
Then uh database authentication. Okay. So by default it will choose a password
3:08:32
authentication and make it uh another setting make it as a by default and simply click uh uh
3:08:39
click on create database.
3:08:45
After this uh in some time you will get your database.
3:08:50
Okay. So this is a way for creating your own database using RDS. So uh if you use
3:08:58
RDS so RDS is a manage service in AWS here we uh you don't have to manage any
3:09:04
database configuration then whatever uh we configure manually that thing we
3:09:10
don't need to do in RDS that totally think we'll manage by AWS okay so that's
3:09:17
it guys uh if you have any query for creating a database in RDS so you can
3:09:22
ask me in the chat
3:10:50
Yes, MKkesh, you can launch a database in any system or you can say in any uh
3:10:56
AWS instance there uh you will get for example if you choose a Red Hat system
3:11:01
and there you will get a software called MySQL something like that using yum uh
3:11:07
yum command yum install command you can install the um MySQL software But there
3:11:13
you will uh you will have to do some configuration. Okay. For example, um
3:11:19
setting the password, creating the database. Okay. So all of these thing you have to manage uh your own way. But
3:11:26
RDS is a one of the service in the AWS that uh uh that that provide you uh that
3:11:33
provide you a database as a service. There you don't have to install any software. Okay. there don't you don't
3:11:39
have to manage um manage about um storage okay there uh that thing you
3:11:47
will get from AWS Okay.
3:13:05
Okay guys, thank you. I think is here. Over to you, sir.
3:13:37
Okay guys, uh so let me show you one two more basic quick information about EKS,
3:13:43
right? One thing is guys, if you have some external database,
3:13:49
okay, how can you connect? What I mean by this, right? So idea is
3:13:57
there's a possibility okay and and maybe in most of scenario you might also see this kind of
3:14:02
possibility that a port is running inside the uh kubernetes in this case
3:14:11
called EKS. Okay. So you have a maybe multi-
3:14:20
application right you have where your application actual application right again let's say
3:14:26
example WordPress right so WordPress your application written in a PHP so
3:14:33
this app you're running inside the port and port is guys running inside
3:14:42
inside your um uh your Kubernetes right here the Kubernetes is EKS
3:14:49
okay this part you know okay now what I'm talking about one more guys one more
3:14:55
please so I'm talking about uh if you if you just check this part
3:15:02
here this is running in the Kubernetes and Kubernetes is there in the EKS
3:15:09
and EKS guys the entire resource EKS there they there are
3:15:14
worker node all the thing guys it run in one particular VPC.
3:15:22
So if you notice guys here in this particular EKS cluster this EKS cluster
3:15:27
at this point in time okay this cluster is running in some particular VPC
3:15:33
maybe you can say see somewhere here uh somewhere you will find this entire
3:15:39
resources okay if you got networking I can say this is running into this VPC
3:15:46
okay VPC is one networking service in AWS and One more thing about VPC what
3:15:52
VPC will do. Okay, what VPC will do? It will isolate your
3:16:00
resources. It means whatever you run in this VPC is isolate.
3:16:07
What I mean by this may more VPC guys in AWS.
3:16:13
There's a possibility you have one instance running here. This instance can be run as a database. Now this database
3:16:20
you launch or you launch this database with RDS service.
3:16:27
Okay. So if this is VPC A and this is different VPC
3:16:32
B. Okay. VPC make their resources isolated.
3:16:39
Means this particular instance or the port if they're trying to connect to
3:16:46
this part instance or the database it won't work. Okay. The VPC make the resources
3:16:53
isolated at the networking level. Okay. So our use case is what I want I
3:17:01
want my multi- application okay is not launched purely on the
3:17:07
cubernetes. I want some kind of hybrid setup. What happen if any client
3:17:16
if any client uh is trying to connect to my application over here.
3:17:23
So this they can get the access from the port. Okay. But anything the port want to
3:17:31
store. Okay. They don't store in other port. Till date you might have seen we have
3:17:37
launched one more port for the database. Now we are not going to launch any database port. If you launch any data
3:17:43
database port is a part of kubernetes. So there's no uh as such very hard in
3:17:48
the terms of connectivity. So within the cubernetes cluster
3:17:54
uh any port can connect to other port very very simply that is networking is purely managed by cubernetes.
3:18:02
Here what I'm talking about here what I'm talking about
3:18:07
is um this port is running in the cubernetes and cub in one VPC
3:18:16
and your database is not part of your cubernetes is independent database it's called known as external database
3:18:25
is running somewhere else and there somewhere else maybe or other VPC or
3:18:30
maybe your other cloud also maybe your on premises also it could be anywhere
3:18:38
okay so how your port application port is going to connect to
3:18:44
database that is external to the kubernetes how they can connect
3:18:51
okay so again application is multi-ter or multi- application
3:18:57
but if the case is database external Okay. And I'm talking about external
3:19:02
with respect to Kubernetes. This is a Kubernetes, right? Even if you launch in RDS also is one service as for
3:19:10
launching databases. Okay. Even for the Kubernetes perspective, your database is external.
3:19:16
So it can be RDS, it can be Azure cloud, it can be on premises, anything outside
3:19:22
the Kubernetes is the external. So how can you connect?
3:19:28
So right now if you see the setup your EK is running in this VPC here A47
3:19:35
and if you see the RDS I think some of my team member has launch RDS database
3:19:42
or MySQL something like this okay is belongs to different
3:19:49
this one database we launch here and this database belongs to different VPC.
3:19:54
So you go to this database sorry I go to this database and this
3:20:00
database will be part of different VPC here A39.
3:20:06
Okay. So let me write here. It means we have one VPC.
3:20:15
Okay. And we have one more VPC here in AWS perspective. And here your database
3:20:20
is running. Okay. And because database is not
3:20:27
belongs to Kubernetes or EKS cluster.
3:20:32
So for the Kubernetes perspective is external. So database external.
3:20:40
Okay. And because database external. Okay. And if you want this database to
3:20:47
connect to your pool, this can be application port app.
3:20:54
Okay. What do you have to do? Two things you require if you want
3:20:59
application port to database. Even though if you see here in my case your database running in VPC A39.
3:21:07
This is a VPC name A39. this VPC name while and
3:21:14
you are uh this VPC running is A74 in the last so is a A74
3:21:24
is A 79 actually is a different VPC
3:21:31
and the point is if any port in the Kubernetes they want to connect database external so two things we require
3:21:39
one this they should have network connectivity
3:21:45
okay now how you do the network connectivity will be your case if there were running in Azure cloud Google cloud
3:21:51
maybe you need public IP is running in on premises you need a public IP of the
3:21:56
database or outer IP maybe or load balancer IP maybe the public IP
3:22:03
or if this database is running in one VPC and and running other VPC maybe your same as account or maybe other as
3:22:10
account then we don't need any public IP address okay there's a concept of VPC pairing
3:22:17
so we can use VPC pairing concept connect my point is you need network
3:22:23
connection so you do the network connection with public IP address
3:22:29
okay maybe this database whoever launched maybe they might have launch
3:22:35
endpoint as a public IP I No, this can be public IP.
3:22:40
Okay. No, it's not accessible. Okay. But it we can enable the public IP
3:22:47
of better for security because both belongs to AWS only. So rather than we'll make it public accessible
3:22:53
sometimes not good for security, we still make it private only running in the in your VPC of AWS. Right? What we
3:23:00
can do? We can do VPC pairing. So what VPC pairing will do? So both
3:23:07
these VPC let's say this is VPC number A can connect to VPC number B okay
3:23:12
internally without exposing to public. Okay so VPC pairing pairing guys is not
3:23:19
part of this program if you know a little bit about VPC basic level training if you know so there we discuss
3:23:25
VPC pairing and we'll explain how to set up is even the way very simple
3:23:30
uh but but there we will discuss VPC pairing. My point is you just you have to give the network connection right
3:23:35
either public IP address or they belong to different VPC. So other approach would be we can use VPC pairing to
3:23:41
connect two VPCs. So this is for the networking perspective here there's no role of Kubernetes. Secondly from the Kubernetes
3:23:48
perspective what you have to do okay your database
3:23:54
running outside okay but what we have to do we have to create one service for the database
3:24:01
here. So it's a pure service in the cubernetes window create and this service is belongs to database
3:24:11
and in the service we have to tell this is not the cluster IP this is not the load balancer this is not the node port
3:24:17
there's one more type of service available is called external name service
3:24:22
so guys if you know in the kubernetes whenever you create a service
3:24:30
okay there they ask two time
3:24:36
so these three thing you know are we used multiple time but the external name is what I'm looking for right now
3:24:44
with the external name I can tell I am service belong to Kubernetes the
3:24:50
cubernet can be EKS but with the help of external name what I can tell that my behind the scene port
3:24:59
is not p is belongs to Kubernetes is belongs to external.
3:25:06
So what I can do I can give the IP address of that particular database
3:25:11
or that particular application can so where they're running you can give the private IP if there are VPC pairings
3:25:18
there or you can give public IP if is public IP is available okay so with the help of external name
3:25:24
we can tell okay to where my database is running it
3:25:30
means for the cubernetes perspective if any application port want to connect they have to connect to the service only
3:25:35
the the approach is same. So for this application for the way they connect to database is
3:25:41
same. They always can require service only. So they can do to service only but service duty is the one who take
3:25:48
this request and get sent to the external world and get the reply. Yes. So it's entire game of service.
3:25:57
Okay. Service. So this is that's all you have to do right. So my point is if you
3:26:02
want to connect external database okay wherever the database is you need a
3:26:08
public IP or if they're running different VPC without having the public IP also you can connect with the help of
3:26:13
VPC P this one point okay and here because there is two VPCs
3:26:21
so if you go to this particular VPC here go to VPC P there you can find the option okay in the uh in this VPC
3:26:31
There's a two VPC here you know many more but this is a VPC for EKS that what I write here it's 879 this is a VPC for
3:26:40
uh 831 83984 84
3:26:46
these guys so so in the VPC guys you can go and sign uh do the VPC peering
3:26:54
okay so you can find some option there somewhere okay and how to do the VPC
3:26:59
peering U that u again I'm not going to cover over here this is a VPC pairing
3:27:05
concept okay but if you want to know this I asked my team they will share this video
3:27:11
to you of my VPC classes where I explain you how to create a VPC or of your own if you want to create then how to do VPC
3:27:17
pairing okay then after VPC pairing you do some routing also set
3:27:22
okay so create a VPC pairing and you can say this is one of my VPC let's say this
3:27:29
is the VPC 79 79 and I want to connect to other VPC
3:27:36
in my same account in the same region. Okay. And name would be let's say A39
3:27:42
that's all. So this how do you connect so without having the public IP also these can
3:27:49
these two network and all the system running in this network can communicate to each other.
3:27:56
Okay. LSMI VPC peering for cube
3:28:03
when it is 2 RDS. Okay,
3:28:10
we can do so. So this VPC pairing has been done. That's all. So networking part.
3:28:18
Okay, you can accept the request in the Excel menu. So go to Excel menu and you can accept the request. uh from here
3:28:27
accept the request and accept. So VPC ping has been done.
3:28:34
Okay. And one more thing you'll do you update the routing table in the VPC. Okay. So you get the route so both guys
3:28:41
can connect to each other. Okay. So maybe in the routing table of
3:28:48
uh this guy you create a route or maybe go to VPC and in VPC uh VPC has a subnet
3:28:57
and the subnet you can get routing. So as pure VPC concept my point is you need
3:29:03
a network connectivity however you do that will be uh by your choice.
3:29:09
Okay. But for the Kubernetes stand point of view, you have to only create a service.
3:29:15
Same service. Only thing is your type of the service will be external.
3:29:21
So for this guys, if you want to go to this entire demo, everything is same exactly what you know in AWS and in
3:29:26
Kubernetes only small change is is there in the service. There's one more new keyword going to come up. So there's one
3:29:32
interesting blog guys.
3:29:38
I'm just giving a reference to this blog. They will show you the exactly same demo
3:29:43
what I was talking about. So here they also explain you how to get a VPC from the scratch.
3:29:49
Okay. And then how to create a subnet also from the scratch if you want to create. Then um then how to get routing
3:29:56
table also if you want to create from the scratch. Okay. And then how to launch a databases RDS from the command
3:30:02
line. And then how to implement security so we can connect to database. How to
3:30:08
launch the database in RDS pure AWS concept. Nothing about EKS and
3:30:14
and Kubernetes. Okay. And then
3:30:20
launch a cluster EKS that you know already. Okay. Only thing that is a new
3:30:25
thing for you is wherever RDS is running running here for example in my case the
3:30:30
RDS running here you know tell to your
3:30:37
service file instead you use type load balancer or the cluster IP is change name cluster
3:30:44
name that's all and in the cluster in external name you to give the name of your RDS where the RDS is running or
3:30:51
external database running maybe public IP or Maybe the IP address that is pingable or connectable to
3:30:57
there's only change. Okay. Apart from this everything is same
3:31:03
and if this database having the public IP you can direct click connect. If you're not public IP and running
3:31:08
different VPC then through connectivity again you enable the public IP or we can do VPC pairing. How to do VPC ping? I
3:31:15
show to you but after this you to create a routing table also. So they also give you guys to create a routing table in
3:31:21
the VPC pairing. This part initial I show you very quickly to you after create the VPC
3:31:28
pairing then you to set up the route.
3:31:33
Again it's a pure VPC concept that's all and after do so enable security group
3:31:39
any kind of security group things and then you can connect. So you can run one
3:31:45
port in the Kubernetes and from this port if you try to connect with MySQL services it's connected it is connected
3:31:53
okay so it's good block okay
3:31:59
uh to uh do this external connectivity I'm not going for this because it look like a pure then AWS training because
3:32:06
creating a VPC pairing RDS and then routing okay So
3:32:14
I think most of you guys might know this concept already VPC pairings routing all things and by chance if you don't know
3:32:20
follow this blog or if you want to learn from my side also we will I asked my
3:32:25
team they will provide the entire video VPC pairing routing all the things to you just follow it along with my video
3:32:31
classes create this VPC pairing and then for the AWS perspective only one thing
3:32:37
you have to do only one thing is create service the way you create only type you
3:32:43
have to write this extra keyword that's all okay so this also good use case guys
3:32:50
mostly we launch the application in the kubernetes as application port
3:32:58
but database mostly we use by our internal databases or database homes
3:33:04
this kind of services okay in this case external uh service is very very important
3:33:11
concept to But it's very simple also to to implement. Okay. So this is one more thing I want
3:33:18
to explain to you and you just try this demo by yourself. Okay. Because nothing
3:33:25
special to do here. The other things is related to AWS only. Okay. So that's it guys. One more uh
3:33:32
topic I want to add even though it's not part of your program but is very important thing I believe to be
3:33:38
discussed. So if you go to EKCl guys, there's a one concept called carpenter.
3:33:45
Okay, carpenter. So what is carpenter?
3:33:50
Okay, carpenter is a autoscaling kind of pool.
3:33:58
Okay. So, uh what we can do, we can first launch a cluster that has a
3:34:06
carpenter support. Okay. Is a is a pure cuberase cluster.
3:34:14
Okay. What about carpenter do? Okay. Carpenter guys is a autoscaling
3:34:20
concept and in my autoscaling class also I discuss you there. If you want to
3:34:26
autoscale your worker node, this is worker node one. This is a worker node two of the kubernetes.
3:34:33
Okay, and as a load increase, you need more resources.
3:34:39
Okay, you can launch one more worker node
3:34:44
but either you can launch worker node manually or you can launch worker node automatically.
3:34:49
Okay, but if you want automatically then this is called autoscaling concept. Autoscaling not of the port autoscaling
3:34:56
of the worker node. Okay. And if you want to do autoscaling
3:35:02
there's two way. One way that is purely typical from the AWS is called autoscaling group
3:35:11
and those who was part of my EKS training this was the demo we have seen in my init classes.
3:35:17
Okay. Other approach also for the autoscaling we can do is with the help of a tool is open source tool called
3:35:23
carpenter this tool we can use carpenter
3:35:31
okay what the differentiation right carpenter is guys little bit faster if you compare with autoscaling group is
3:35:38
one small difference differentiation okay but there's many more differences guys about the carpenter
3:35:46
okay one differences and would be uh carpenter will optimize your resources
3:35:53
okay by looking at the requirement okay maybe rotoscaring group they want to launch one more node and typically
3:36:00
guys you know in AWS EKS we we launch one more node and put the node inside
3:36:07
one node group it means if this node group having let's
3:36:15
say 8 GB RAM here. So same 8GB will be B or again if you launch one more node
3:36:21
here even though we might not need 8GB resources but they still they launch it.
3:36:29
So if you do autoscaling group they will do within within the node group and here
3:36:35
they will have the exactly same
3:36:40
uh you know resources in the line worker nodes even though we might not need. So
3:36:46
is a pure wastage of the resources. Okay. And is al also don't worry about
3:36:51
wasters also. There may be other issues also. For example, A and B is our node group we have
3:36:57
and this node group we don't have a GPU for example. They only have CPU.
3:37:03
But let's say the one new workload come up and the workload we going to launch a port and the application need a GPU is
3:37:09
maybe kind of machine learning deep learning application for example.
3:37:15
Okay, in this case if a node come up autoscaling group can launch one more node but this node is not usable because
3:37:21
they have a CPU but I don't need I need along with CP GPU also
3:37:28
in this carpenter help us right carpenter become very smart okay by looking at the load okay they will
3:37:34
launch one more worker node by launching one more node group and that will
3:37:41
associate with the GPUs Now the point is carpent is open source
3:37:47
tool more optimized and more recommended in the kubernetes
3:37:53
any kind of kubernetes all right and and um
3:38:01
uh it helpful for the autoscaling so instead of autoscaling group concept autoscaler concept we can uh we can go
3:38:08
go for carpenter here okay that's the main point.
3:38:14
Okay. And because we're going to launch a carpenter uh so again carpenter is
3:38:20
again one kind of program it can be program and but this program guys given us as a CRDs in the in the
3:38:29
Kubernetes some custom resource definition you know we have a deployment of board these are the resources right
3:38:35
similarly we have carpenter custom resource definition are going to come up and this is the one who will keep on
3:38:41
monitoring your cluster as soon as the uh more load going to come up if you
3:38:47
need more work or not they automate a scale for you and that is the reason guys carpenter need a permission from
3:38:55
EC2 okay so we have to provide IM role to
3:39:00
the carpenter okay so that they can go to EC2 and
3:39:05
launch more instances and attach to the EKS cluster okay so the guys so how to use it very
3:39:12
very simple uh Nothing simp complex you launch a cubern cluster the way you
3:39:18
launch the same file that we we have seen till date here we have to give some IM power
3:39:24
okay and right now we initial create a one node group only with only one in
3:39:31
instance and we're using this version of carpenter
3:39:37
okay that's what we uh we are using here so when you launch this cluster this
3:39:42
what kind of file we have seen multiple time. So run this cluster and this
3:39:48
cluster will have a carpenter installed and carpenter have all the power permissions whatever we
3:39:55
looking for. Okay. After the cluster has been launched,
3:40:02
okay, customer launched, then you can launch carpenter provisioners
3:40:08
means the you know in my last class we talk about ingress provisioners. Similarly, we have a carpenter
3:40:14
provisioners. So it's like autoscaling program. They keep on running and as
3:40:20
soon as they see new load columns come up. Okay. They will go to your respective
3:40:27
cluster. Whatever cluster you launch you can change the cluster name here. Whatever cluster you launch from here.
3:40:32
Okay. In this cluster they will launch one more one more worker node.
3:40:40
And maybe guys carpenter also smart. Okay. They also keep on doing many more thing that autoscan does not group can
3:40:46
do. For example, there are 10 worker node working and all the port has been distributed
3:40:51
across all the uh worker node but we don't need so many
3:40:57
worker node. Maybe some of the port we can remove from some of the worker node and move to worker node one and two.
3:41:06
Okay. So the resource will become free. So carpet also guys do this kind of clean for you. Okay, just go consolidate
3:41:14
your resources in limited worker nodes and after they become empty after some
3:41:19
time 30 second after they will remove that particular worker nodes.
3:41:26
Okay. So instead of working on the 10 worker node maybe your work can be done in three and four worker nodes. The
3:41:32
remaining worker node they can delete. So it will save you save you money and time.
3:41:38
So this also carpet can do for you. So only thing what you have to do launch the cluster
3:41:46
the way you launch by enabling carpenter by some IM power and then launch the CRD
3:41:53
of the carpenter also as provisioner here and uh that's all remaining part
3:42:00
guys you don't have to handle has been completely handled by uh carpenter as autoscaling concept okay
3:42:08
so either you follow this lab from uh EKCTL or there's one more lab guys from AWS you can also follow this lab
3:42:17
there was a good lab wise for for the carpenter okay so there also you can also follow
3:42:25
along this lab to set up this right so maybe in this carpent this same kind of
3:42:31
code there's some more extra value they have we can also define here that you want ondemand instances hot uh sorry
3:42:38
spot instances is which type of uh instance type you are want to include
3:42:43
here with the carpenter. You can restrict only include these uh operators. All right. So those things uh
3:42:50
you can give uh provide here. Let me at least try this code in my running
3:42:55
cluster. Okay. So I'm going to let's say
3:43:02
carpenter yl. Okay. Okay, only thing I'm trying to
3:43:08
change here is my cluster name here. So I'm trying with my cluster thing might
3:43:14
be not work because of some IM permissions that you guys know how to change it or you can create a cluster
3:43:20
from the scratch. Okay, that will be a different point.
3:43:25
Okay, so EKS CL get cluster this is my
3:43:31
cluster name and same cluster. I'm going to launch the carpenter.
3:43:39
Okay. So, cubectl apply
3:43:46
this carpenter. So, then u unable move provisioner.
3:43:56
Okay. Uh then this error is coming.
3:44:01
Okay. Because uh these keyword might not be available or
3:44:07
version may be different
3:44:13
is a carpent version one alpha version alpha.
3:44:21
Okay, it's not there because I my cluster guys is not enabled with with
3:44:28
the carpenter. You have to enable this by uh while launching the cluster. Okay.
3:44:34
Otherwise you can take this lab the same kind of thing. You just launch a carpenter that's that's all nothing
3:44:40
special you have to do and just run this program and you will see in this name
3:44:45
carpenter they create they will launch one one uh provisioner for you and
3:44:52
everything now automated and the test they also give a command to test. They say you want to test launch some
3:44:58
deployment port with some 1GB request some random port you can launch 1GB
3:45:04
request okay make it replica copy of five then 5GB required and you don't
3:45:10
have a worker node initially so automatically carpenter will launch the worker node
3:45:16
so just for just for testing purpose if you want to try this lab or if you
3:45:22
want to enable the cons consolidation the way I explained to 100 or 10 worker node is running. Okay,
3:45:28
not every worker node has been fully utilized. Some of the guys are under utilized.
3:45:34
So carpenter will keep on checking and remove the port from there and they launch in the the worker node where you
3:45:40
have some space available so that the unwanted worker node will be
3:45:45
removed. So it will help you in cost 7. So this consolation feature also you can
3:45:51
enable by patching the provisioner by enabling this facility or by launching also you can enable this facility of the
3:45:58
provision. So it's also good lab guys just just do it. uh this carpenter was not part of
3:46:07
EKS training but I thought to explain this concept to you okay otherwise we
3:46:13
can I can show this demo but I have to relaunch my cluster by enabling the carpenter while
3:46:23
launching uh the way I explained to you uh while launching the carpenter where
3:46:30
where it is was here it is So just run this command and thing will
3:46:37
pass. So guys this is about the carpenter very very simple thing two
3:46:42
steps only technically launch the cluster the way you know only by enabling the carpenter this is the first
3:46:48
step only this step with the same tags also.
3:46:54
Second is the second option is um just uh
3:47:01
launch the carpenter provisioner. Okay, this is the program who do the
3:47:06
autoscaling for you. Apart from this everything is automated for the carpenter prospector. You don't need to
3:47:12
do anything apart from here. So I highly suggest guys copy paste this command from this EKSCl document or from this uh
3:47:20
Amazon uh some work workshop. You can take this example from here also
3:47:25
and do uh try to do this step. Okay, that's it guys uh from my uh side.
3:47:36
Okay, from my side and um that's all guys. uh
3:47:42
in EKS guys we have planned EKS for for limited hours but I think more than 200%
3:47:51
time we have invested on EKS that's good for learning and then lot of topic was not a part of EKS for example carpenter
3:47:58
for example ingress controller uh for example today we discuss content insight
3:48:04
so these are topic as such was not a part of the case training but as you guys demand I alo feel let let's cover
3:48:11
this topic also. So with I try try guys to cover almost everything about EKS
3:48:17
with all the complete practicals and the hands on. So EKS guys training I I'm
3:48:23
concluding today this is one thing okay those who was in my serverless training
3:48:29
okay I think serverless content we have covered more than double triple okay the
3:48:34
way because it's very simple program but we have tried to cover lots of serverless services and so I'm
3:48:40
concluding the serverless training also those who are part of my AWS developer
3:48:46
trick also again in developer trick I recall lots many things might not be part of
3:48:52
developer track from CSA level from advanced level for sysops level from serverless part also so de developer
3:49:00
training also I'm concluding today and um what else mastering training also so
3:49:06
those who are just in the mastering training is also I'm concluding today
3:49:12
okay those who are the part of AWS data analytics okay or sisops or AWS advanced
3:49:21
architecting your journey will continue for some more time. So we'll update you
3:49:26
guys when your post has been completed. But uh I always follow this this approach. Whatever the contents we have
3:49:33
given to you, we'll try to cover more content. Every content we'll try to do a hands-on and plus as demand also come
3:49:40
from your side that you also want to cover some content might be depend upon
3:49:46
your use case in your industry. So I always try my best to cover this content
3:49:52
in this training. Okay. And that's what I do. Okay. So that's all guys. Uh I would
3:49:58
like to thanks everyone to be so much present with me because I know there's multiple
3:50:05
of in my classes due to many more reasons. So but yeah we have
3:50:11
successfully complete this entire journey. All right. Otherwise uh we'll
3:50:16
see you s other training or maybe you guys are welcome to Kafka those who
3:50:24
wanted to join machine learning deep learning from very basic to all advance uh we are going to launch we have
3:50:30
already launched this program machine learning we're going to start soon you guys can join uh machine learning or
3:50:35
deep learning data science with me Kafka we are starting tomorrow and that's it
3:50:40
any queries if you have apart from This one time V. We launch already. We did
3:50:48
one batch long back but we are also planning to launch one more batch of quantum maybe I think in July month I
3:50:56
believe believe. So uh so if you want to join quantum computing also you can join
3:51:01
in July.
3:51:09
So uh so entire topic of Kafka cover this uh
3:51:15
Kafka training is more with admin perspective. Okay. So this yeah so I also want to
3:51:22
update this Kafka training. Okay. Whatever we have launched is more
3:51:28
respect to admin track. Some portion of developer tech you also see there as a developer perspective.
3:51:34
But this uh content is uh more uh with respect to uh admin track of the Kafka.
3:51:44
Okay. So this also one point somebody asking right about the Kafka some you
3:51:49
might say about the developer perspective but more about
3:51:54
it is more about the uh admin track.
3:52:04
So how to get a certificate of this training? Uh so for this Paris you can
3:52:11
connect to my team they will tell you right and to share LinkedIn mandatory
3:52:16
again Paris you can ask to my team whatever protocols they have or any kind of
3:52:23
special uh possibilities for you for getting the workshop certificate uh my
3:52:30
team will help you. So no issues if you have some concern about it just uh raise the concern they will definitely help
3:52:35
you and come with the other solution for you guys.
3:52:49
So can you provide the Kafka earth guys? So for earth student guys we will
3:52:56
we will uh update you about the kafka
3:53:01
okay so earth one earth two earth three which part of earth we are providing the
3:53:06
kafka okay and it's a free I'm talking about so by the evening guys we'll
3:53:11
update you in all the group about the kafka okay
3:53:19
so mayor thank you very much sir It's been wonderful journey learning from you. You've been one of the best mentor.
3:53:25
Thank you. I've seen the same spirit in good health. Thousand world outside can good
3:53:32
knowledge from you. Thank you very much mayor for this fantastic feedback.
3:53:38
Okay. Anything else guys you want to know about EKS and other things what we have
3:53:44
covered till date?
3:54:05
So does delete the worker node if is not required. Yeah, if you delete the code
3:54:11
worker node will delete. There's a timer over there. You can
3:54:18
change the forget config file. Okay. So after that period time your
3:54:26
worker node will delete because one port is been associated one worker node in the forget right. So delete the port
3:54:35
your worker node will be deleted. Okay, it all depend how how much time it
3:54:41
means how after how long it will delete as a time some tunable parameter I believe per you can also check the
3:54:47
document and uh there you can see u
3:54:53
that at this point in time they will they will make it deleted okay
3:55:01
now it is not similar to carpenter carpenter different approach right forget a pure surless service Okay. Uh
3:55:09
for the worker node. So far is more of a worker node, right? So you can think fate is a worker node just to make it
3:55:15
simple. Okay. Carpenter is is keep on monitoring
3:55:20
your worker node. You should have the worker node. Carpent is keep on monitoring
3:55:25
it. And as soon they find that we have a
3:55:30
uh we have a one more port going to come up. They're looking from some resources.
3:55:36
You know when you launch a port they request some resources like memory receive or whatever the request they are
3:55:42
doing is not available by chance in the worker node. So they launch one more
3:55:47
worker node for you that's called autoscaling the way I saw in my initial
3:55:53
class of EKS classes right autoscaling autoscaler concept. Okay. But interesting thing how
3:55:59
carpenter work is they auto scale depend upon the request if they're requesting
3:56:06
for GPU. the autoscaling the instances that has GPU enabled just for example
3:56:13
the same time they also keep on checking let's out of 10 worker node every worker
3:56:18
node running five or 10 ports and forget we can't do we have one port with one worker node right but every worker node
3:56:24
running five or 10 ports okay and some of the worker node is underutilized they try to remove the
3:56:31
unwanted port from it try to move to other worker node so that that worker node will complete ally become free and
3:56:39
carpenter will delete it. So autoscaling means remove and delete then then completely by carpenter in by some smart
3:56:48
uh uh way almost like autoscaling group not uh
3:56:54
autoscaling group autoscaler I can say but these facilities is not there in the autoscaling group like consolidate
3:57:01
concept is not there in the uh autoscaling group so my point is target
3:57:06
is a different thing it is like a worker node
3:57:11
Okay, serverless worker node I can say carpenter is not the worker node they're
3:57:16
launching the worker node scale in scale out they remove it and delete it
3:57:22
as the demand increase and decrease okay but maybe worker node one worker
3:57:29
node might might have 10 ports maybe 100 port maybe it's like a normal worker node
3:57:35
okay it look like similar but it is not there's a different use case they're solving Okay.
3:57:47
So that's all guys uh from my side. All the best. See you uh in some other
3:57:52
training and take care and enjoy. Practice this. We'll we'll we keep on sharing all the notes the the diagrams
3:57:59
the commands in your hash portal. Other commands whatever we shared today we also share you guys in the GitHub and
3:58:05
we'll show you the link. Okay. Bye. Good day guys. Take care. Good day. connected.


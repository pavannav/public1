ript


17:45
Uh hello uh good afternoon everyone. So let's let's uh first quickly revise uh
17:51
about the previous session and then so we'll start. So give me a minute. I'll
17:56
share my screen. Okay, I hope my screen is visible to
18:04
you. Uh, okay. So, last week we discussed about uh search discussed
18:09
about core EKS that is elastic cubernet service. So, uh I would not discuss
18:16
about the Saturday class. We already discussed on Sunday last Sunday. So, I
18:22
would be discussing only Sunday's class. Okay. So if we want to use EKS we use
18:27
the EKS CL tool. Okay. So sir discussed that we have two ways for that. One is
18:33
CLI or other way could be that we can use the code that is YAML file. Okay. So
18:40
sir discussed about node group that is that node group will manage the nodes and node group is managed by AWS only.
18:48
So it will help in the disaster recovery. Okay. So one uh topic was SSM
18:54
where that could be referred as a SSH. So during the practical su generated a
19:01
key using SSH key gen which creates the public key and the private key. Okay. So
19:07
then sir discussed about YML file that is it is a generic way of formatting and providing information. It can be
19:14
represented in the form of key value pairs. Equal spacing given in YML file
19:19
is called indentation. Okay. So node group is a kind of one array which is in
19:25
the form of hashes and dictionary. Okay. So if you want to launch cubernetus
19:30
cluster using eksl tool with the help of file then it means that we are sending a
19:36
instruction which is called a declare that is why that is known as a declarative language. Okay. So yl is a
19:43
way to declare what we are what we want to instruct. Okay. Or we are what we want to declare. Okay. So sir use SSH
19:50
key gen for generating the keys okay private key and the public key. So you
19:56
can see that uh this command by using this command we got the uh public key
20:01
and the private key. So for that creating a cluster uh we use the command
20:07
as ekplate cluster name that is the name of the cluster. You have to give your
20:13
region where you want to create your cluster its version node group name okay
20:18
and then instance types okay like we use t2x large in our case and nodes say
20:25
three and minimum nodes as two and maximum as 10. We also gave the size for
20:31
node volume by hyphen - node volume size 40 and we gave the node volume type GP3
20:38
and enabled SSM. Okay. So we wanted SSH access. So that is why we enabled that
20:44
and instance name we gave as cube worker node and then managed. Okay. So this is
20:51
how we created uh our cluster and the cluster launched successfully. So we can
20:56
see in the cluster part uh in the web UI that our cluster my basic cluster was
21:03
created. Okay. After that to uh get the clusters uh you have to use the command
21:09
ekl get cluster. Okay. And to get the node group you use the ekl get node
21:16
groupoupy cluster and you have to give the name of the cluster because we wanted the node group in that cluster
21:22
that is why we used the name of that cluster. Okay. So these are the same commands. Okay. And we can also see the
21:31
instance uh which we created. So you can see that cube worker node was create uh
21:36
running. Okay. In in the instance part. Okay. So we used it while creating that
21:42
cluster. Okay. And we also got the key pair as EKTL my basic node group. Okay.
21:49
In the key pairs tab. Okay. After that we login into that instance one of the
21:55
instance and we login by root user okay so by sudosu hyphen root and then we
22:02
checked u the cluster info in the command prompt by using cubectl cluster
22:08
info okay so we were not able to see so to see the uh further we use the cubectl
22:14
cluster info dump command okay so we were able to see the
22:20
information there To get the nodes you have to use cubectl get nodes command.
22:25
So we were able to see the nodes running in that cluster. Okay. And after that
22:32
what we did similar commands are used to show you that and to describe a
22:38
particular node you need to use that cubectl describe nodes and then you have
22:43
to give the name. Okay. So you can see that we get the information of that nodes there. So since we launched in T2X
22:51
large type instance type so it gave the information as instance type as T2.xlarge. Okay. So if we want to launch
23:00
any operating system server or any kind of application then that entire software
23:05
we bundle in one box which is called as a image. Okay. So image in container is
23:12
called the container image. So to get the image we use uh one of the famous uh
23:18
site is hub.docker.com. So you can make your account there and
23:23
you can either create your own image as well as you can also use the pre-created image. So sir used the pre-created image
23:31
that was uh Apache that was for Apache web server php. So sir used this image
23:38
uh in the practical. So if you want to launch app container or a pod with the
23:45
help of image we call it as a deployment in kubernetes. Okay. And setup which ks
23:51
gives is highly resilient and fault tolerant. This entire discussion was
23:56
already been discussed in the previous session of this. So I just mentioned
24:01
only a short line in this. So okay. So to create a deployment we use the
24:07
command cubectl create deployment the name of the deployment say in our case
24:12
we use the deployment name as my web and we use the image as 13 Apache web
24:18
server. Okay. So only you have to give the image name and the deployment name then your entire deployment will be
24:24
created. Okay. So we create you can see that deployment app my web was created successfully.
24:31
Okay. So uh we we checked uh like what are the number of pods we got after
24:37
that. So we used cubectl get pods cubectl get nodes to check the nodes.
24:42
Okay. And after that master keeps on monitoring the pod because there is a
24:48
program running in worker node. Okay. Who communicates with the master and that program is known as cubelet. Okay.
24:56
So the communication between the master and the worker nodes is done by the cublet. Okay, this is also managed by
25:03
EKS. Okay, so this is also managed by the EKS service of AWS. Fine. So after
25:10
that uh to delete a pod, you can use cubectl delete pod and that pod name.
25:15
Okay. And you can see that uh whenever we uh deleted the pod, it automatically
25:21
recreated a new pod whenever you do the cubectl get pod. So it will scale it.
25:27
Okay. And uh to describe a pod I already shared the command that cubectl describe
25:34
pods and then pod name. Okay. So you can see the description by using this
25:39
command. After that u we created a one more deployment by using a image httpd.
25:47
Okay. So same command cubectl create deployment d1 and then image name as
25:52
httpd. So we we use the command cubectl get pods for getting how many pods we are
26:00
running at that time. So we use that command for that and to check. So you if
26:05
you want to log to that terminal or we want a bash shell for that. So we use
26:11
cubectl exec that is execute uh we want interactive terminal. So we for hyphen i
26:19
refers to as interactive and t refers to as terminal and then the name and then pash. So you can see that we were able
26:26
to login and when we do ls so we were able to see all the directories there.
26:32
So we check the IP of that uh you can say uh instance there and u we were able
26:40
to curl this IP and as a result we got that it works. Okay. So we exit uh so
26:47
that means we were able to check our web server. Okay. So you can either check
26:52
this uh through the web server or web UI also. Okay. And then we use the same
26:58
command cubectl get pods. Okay. And get cluster to get the more information that we have the cluster running or not.
27:06
Okay. To scale a deployment uh we use a cubectl scale deployment deployment name
27:12
and then hyphen replicas. That means that we need to scale it to four replicas. So you can see that whenever
27:19
we do cubectl get pods we have four four of the running. Okay.
27:25
So I think uh this is clear. Okay. So after that to check the deployment use cubectl get deployment. Okay. Since we
27:33
created two deployments my web and D1. So we were able to see D1 and my web
27:38
deployment there. Okay. And we can also check the service that is S2 cubectl get
27:45
SVC. Okay. to check the service which is running there. Okay. AWS has its own
27:50
personal plug-in called VPC plug-in for K test cluster. Okay. So whenever we
27:56
launch a cluster with EKS, it launches a VPC. Okay. Internally it will launch a
28:01
VPC there. Every VPC belongs to a subnet and every subnet gives a range of IP
28:06
address. Every subnet has its own personal range of network. Okay. So you
28:12
can see that VPC was also launched whenever we launched that. Okay. So AWS
28:18
has a service called internet gateway which allows anybody in in the entire that is uh in a
28:25
particular IP range to access that. Okay. So EKSCTL also creates the internet gateway for you. Okay. So you
28:32
can see what are the features that EKS can provide and uh what are the use case it can be solved. Okay. So EKS has its
28:40
own internal load balancer as well. So you can also use it for your balancing
28:45
the load and all. Load balancer in Kubernetes is called SVC that is service. Okay. That is created
28:53
by a program which have some limit. Okay. In EKS load balancer is called the
28:58
elastic load balancer. We have other types of load balancer in AWS but EKS internally uses elastic load balancer
29:06
that is ELB. Okay. So load balancers of AWS were like NLB, ALB, NLB could be
29:13
like network load balancer. So if you have a requirement of giving a high speed high performance then you can use
29:20
the NLB that is network load balancer and ALB is for application load
29:26
balancer. So if you have a requirement to set up ingress and something networking related things then you can
29:32
use the application load balancer. Okay. And we have one more that is GB
29:38
gateway load balancer that is for advanced setup that manages traffic and encrypt traffic monitoring. Okay. So to
29:46
expose a service so we uh we use the cubectl get sbc command to get the services. So for exposing the service
29:54
whenever we create a deployment and we want uh our web server to be run so we
29:59
need to expose that service. Okay. So for that we use the command as cubectl
30:05
expose deployment and then deployment name the type uh okay and the port
30:11
number. Okay so you can see that cubectl expose deployment my web and then we
30:17
gave the name uh and then type load balancer and in the port 80. Okay. So
30:22
our service got exposed by the name of my lbsvc. Okay. So you can see that by
30:29
cubectl get get svc we get the service name here and after that we also uh
30:37
checked about the instances running. See you can see that we have cube broker node running in the load balances as
30:45
well. And to test we used uh the IP address there and we checked that our
30:51
web server was running successfully. And if you want to uh like if you want to
30:56
check that it is working like our load balancer is working correctly or not. So if you refresh you can see that your IP
31:03
will change. Okay. So this was uh discussed by sir and u same the same of
31:10
the commands like cubectl get svc to get the svc there and we have one more
31:17
command to get sc that is security group and all. So you can use cubectl get sc
31:23
for that. And um I think all the commands were repeated. So I won't repeat those
31:29
commands again. Okay. So I think um yes.
31:36
So you can see that uh to use the node group to check the how many node groups are running in the cluster you use the
31:42
ektl get node group hyphen cluster cluster name command. Okay. So that this
31:49
was the main uh practical which was done in the previous session. If you have any
31:54
doubts uh you can ask in the chat box. Okay. And so we'll be continuing after this.
32:31
AJ what uh do you want to understand uh what is node group or what things you
32:36
want to understand command or what I'm not clear with your
33:08
Muben ELB works on layer 4. Yes.
34:05
Yes, Rajat. We can
34:39
uh Harshetta I think uh if uh we have provided the recordings then that is
34:44
there in your hash3 portal so please check in that
34:53
uh swapnel please uh could you tell me which uh training are you a part of then
35:00
I'll help you with that. So we'll be joining in 1 to 2 minutes.
35:15
Okay. Uh swapnil uh you would be getting the option of other like you have a
35:21
section for that like EKS and then you would be able to see the recording. So you have a different tab for that. So
35:28
please check in that. If you're still unable to find then you can ping any of our team members.
36:01
Raj Kumar I'm not clear with your question. What is this worked on? Build push
36:39
uh Raj Kumar SVC and Kubernetes is the service uh like whenever we want to
36:44
expose uh like our like we wanted our web server to run so we have to expose
36:51
that so for that we have to use expose that SVC that is always
37:10
how do I update worker nodes and EKS cluster version?
37:16
So you have to first check which version are you working with and you have to use a command I guess you have to use hyphen
37:24
update and then I think you would be able to update
37:30
either you or you can use uh you can also reinstall okay
37:36
Raj Kubar
37:45
okay I think sir join. So over to you sir.
38:16
Hey guys, uh welcome back and uh let's start. So we are going to go more
38:24
deep into uh EKS topic right. So this will be the advanced training. The base
38:30
concept of EKS I explained you guys in my uh last class right what EKS is what
38:38
kind of services it will provide right and some of the cluster we have launched okay and many more things we have done
38:45
in my uh blast classes right so those who are into the EKS advanced training
38:53
or in the serverless training or advanced AWS architecting training uh I
38:59
would like to welcome you again. This is the one of the very important topic in your uh agenda or your course content.
39:09
Okay. So let's continue. We are going go more deep into this particular service
39:16
with the help of tool called ekctl.io.
39:21
We can use this tool to launch a basic cluster or the default parameter
39:27
or we can customize this tool to do many more things. Right? So before we go for
39:32
any customized thing, what I'm going to do, I'm going to launch a cluster very quickly. I'm using kitbash as a
39:41
command line tool here and I'll go to my uh document folder and just creating a
39:49
new folder. Nothing special. I'm going to keep a lot of code here. So, I'm
39:55
going to create one folder here that is let's say uh EKS
40:01
advanc code. Okay, something.
40:08
So, this will be all guys um folder where I'm going to keep lot of uh
40:14
code today. Okay, right now this folder is empty and I have already EKCTL tool
40:21
installed in my system. Let me check in my AWS cloud how many cluster is running. So I have one
40:28
cluster running in my case. Let me delete. I don't want this. I want to launch a new one with some new uh
40:35
setting. Right.
40:40
Okay. Deleting. So the plan would be we are going to go more deep or understand
40:47
the advanced concepts of EKS services. One of the topic that we are going to
40:53
start today is called CSI. Okay, that is more about the storage
40:59
services. So
41:05
what is this topic CSI? I'll explain you in a minute. Okay.
41:11
But let me see the status. So this cluster maybe we have some other issues maybe to delete. So let's forget about
41:17
this. We will clear from the AWS account. Okay. So what I'm going to do
41:22
to start with this topic called CSI. What is this? I will explain you in very detail. But before this let me launch a
41:30
one cluster EKCL. Okay. I'm going to use this version
41:35
latest version and I'm going to create a cluster. You guys know this command. Let
41:41
me see the help. I might need one more option here. And uh I'm going to write
41:46
guys this option. Okay. Okay. Every cluster
41:52
um um has some configuration file, right? That is
41:59
called cube config file. Okay.
42:04
So uh one minute even though this one okay so in my current system I you guys
42:13
know this concept already wherever you have a cluster
42:19
your master node maybe whatever worker node or the compute node as a client or
42:25
better term maybe user of your EKS or your Kubernetes cluster you need
42:33
two things you need cubectl command at your computer that is mostly also
42:39
known as workstation or workbench. Okay. Plus you need one more thing that
42:48
uh you will need one more thing that is one kind of config file at your user end. This config file is known as cube
42:55
config file and this file contain many more things or many multiple things but
43:01
one of the three important thing this file contain one is the IP address username and the password
43:08
okay of your cube cluster so does not matter cluster is managed by you managed
43:16
by AWS EK services does not matter right so if you have this command and this
43:22
cube config file that is a user side file or the client side file. Okay,
43:28
these two things is required. So this command always sorry
43:33
use this cube config file to authenticate and connect to the cluster and do all
43:39
the activities. Okay. And you guys know from last classes cubectl is a command for the
43:46
cubernetes, right? It's not EKS command. Any cubernet cluster you have however you launch we use cubectl command.
43:54
Okay. Then one more alternative name guys for cubectl instead of cubectl
44:01
you can use oc command also.
44:06
Okay. So those who know open sift OC command is actually for open sift but
44:12
open sift is also a tool work on the top of Kubernetes. It means if you have OC
44:19
command also we can use OC instead of cubectl. So whichever
44:24
command you want to use command is same name is different but options and syntax are same.
44:31
Okay. But I'm going to use q command only this standard command. Okay. So
44:38
what I'm going to do because my plan is to launch multiple cluster.
44:43
Every customer have different login name, different password, different IP addresses to store their information. I'm going to
44:51
create multiple cube config files. Okay. And to tell the cube config file,
44:57
this is the option we are using where the cube config file created.
45:03
Okay. So I'm just using this option over here. And by launching the cluster I'm
45:09
using this file the keyword I can okay and here I'm just giving a file
45:16
name let's say cube dot config file or let me let me use the word cube
45:24
cluster one doconfig file just a name you can give any name does not matter
45:30
plus we always try to give a cluster a name and if you want to give a cluster a name you guys know there's a name
45:36
keyword that you can use to uh
45:42
to uh you know to give the cluster a name.
45:50
So let me give a cluster a simple name very simple name cluster one okay that's
45:56
what the name I'm giving and maybe we might need to log to our nodes
46:04
okay the worker node maybe we might need okay so I'm enabling this simple
46:11
facility just go enable SSM okay so I can log to my uh my node
46:21
Okay, work on node whenever I need to login through the SSM procility right
46:27
that's all so this cluster start with the default setting I don't need much more settings
46:33
right now and by default you guys know they create one node group and in that
46:38
node group they will create uh they create this node group
46:44
and this node group guys they're going to launch two instances with M5 some are
46:50
some some name type they launch right so this okay for us because my plan is not to talk about this topic today
46:57
okay this very pretty simple command nothing very tedious okay the main thing
47:03
that we are going to start this very very critical and this concept will help
47:09
you understand many more advanced concept in the for the future topics also so topic that we are going to start guys
47:16
right now is CSI
47:21
So what is CSI? Okay, CSI
47:27
to understand this topic. Okay, let me explain you one simple concept first.
47:32
Okay, whenever you have a app, you always now uh now in the Kubernetes
47:40
world, you always put the app in a images there called container images.
47:48
Okay. And who will create this container images? Those who know a little bit about container technology like Docker,
47:54
Docker file, container file. Those who know who will create these images for
48:00
you. Now from this app you will launch a
48:06
port in the Kubernetes world. What port? code you can think it is like
48:12
a operating system and under this port your app will deploy and run this app it
48:20
will deploy and run okay so this is one thing so technically one
48:25
port equals to one app is running so guys um is it all depend upon guys can
48:34
hold for a second please let me settle myself.
49:25
Okay. So guys, this app might need some storage.
49:32
Okay. Depend on the requirement. Let's say this app may be a database services.
49:39
Let's say example of database may MySQL. So what we want as any client from the
49:46
internet somehow they get the access to the database directly or via some app.
49:52
Whatever data they write in the MySQL okay it will permanent.
49:57
So MySQL database services if you want anything to be permanent so this data to
50:02
be stored in one storage and that storage would be known as persistent
50:08
storage or the permanent storage and those storage mostly not always but mostly come from block storage
50:16
like a hard dis like a pen drive or block storage. Okay. So technically it means not always
50:25
all the app need but if your app need
50:30
or your code need some block storage or storage guys sometime also known as
50:37
volume and this volume block is mostly come under the category of persistent or
50:42
permanded storage okay that also known as PV in short form
50:48
uh form PV persistent volume. Okay. So what we have to do whenever we
50:55
launch a port have to request for the storage.
51:03
Okay. So my point is when you create a port okay the one of the responsibility of
51:10
the port is to launch a app by launching the
51:15
operating system and operating system guys here is most known as container.
51:22
Okay, this is the first responsibility of the port. But port can do many more thing guys in
51:28
the Kubernetes world. Port can do one more thing. Port will say that my app
51:34
needs some storage. My container sorry need some storage or permanent storage
51:40
or the persistent volume. So this is the responsibility of the port to claim for
51:45
it that I'm looking for. for this claim is like a request for it. What the request they I'm looking for
51:52
the persistent volume and this concept guys is known as PVC persistent volume
51:57
claim. Who have to do? P will have to do uh
52:02
this. So I'm looking for this. Okay. And after they
52:09
request then only we will provide them the persistent volume that equates to block storage that goes
52:16
to this hard disk. Okay. So they say I need a persistent
52:22
volume of 10 GB in size.
52:27
Okay. They will decide this because they know that they know what the requirement of the app. So they say I need 10 GB
52:34
storage. So we will give them the hard disk of size 10 GB or PV of size 10 GB.
52:44
Okay, this is how it work. The point is who create this PV.
52:54
Okay, so to create this persistent volume again we are not into Kubernetes
53:00
classes. This is actually topic from Kubernetes. My topic is a little bit different here is called CSI. But I'm
53:06
just giving you a very quick brief by chance if you don't know this concept and this vocabulary. So you can
53:12
understand the context what I'm talking about. So like a quick summary or quick information I'm giving to you. Okay. And
53:17
soon in a minute we will jump to the topic called uh uh CSI.
53:23
So who will create persistent volume that is equals to your storage in simple
53:31
term. So there's two way okay either you can create a personal
53:36
volume manually or dynamically okay nowadays guys we don't create
53:42
manually much we always create dynamically dynamically means as the
53:48
customer or p say I need 10 GB automatic 10 GB store will create
53:55
okay that is the meaning of dynamic so if you want
54:01
personal volume create dynamically then there's one concept called okay called
54:07
that will help you to create this person volume dynamically in the kubernetes world
54:14
okay and that concept is known as storage class so storage class is one concept or one resource type that's also
54:20
known as SC in kubernetes the role of storage class
54:25
in in the kubernetes world is to launch a storage also is provisioning the
54:32
storage means creating the storage called provisioning the storage dynamically
54:38
means as soon as the request come automatically we don't have to go for
54:44
manually automatically they create for you somebody claim we create for you that somebody's most always poor
54:52
automatically create for you for this we need a storage class
54:58
okay so this is one simple concept till Okay. The biggest thing is
55:05
okay let's say we have this keyword this resource available this guys in the cubernetes world okay everything is
55:13
known as resource type okay port is one resource type service
55:20
is one resource type storage class is one resource type is one resource type
55:26
is one resource type whatever you do in the cubernetes world is known as uh resource post type.
55:35
Okay. Now point is when you uh storage class will help you
55:41
to create storage automatically or dynamically. The point is from where
55:47
they create they need some real storage, right?
55:53
Okay. The storage class will create the storage from the uh from the worker
55:59
node. Maybe work has some hard disk they get from there.
56:05
Okay. Or storage class will take the storage from somewhere else.
56:11
Okay. So point is from wherever storage class will create the storage from.
56:18
Okay. that we have to define the storage class that you can create the storage
56:23
from the local storage from the worker node because worker node is also like a computer issue to machines in AWS world
56:31
for example here protect the hard disk take some part of the hard disk and use it that's called local storage
56:39
okay but storage class has a capability you can take this storage from NFS
56:45
there's called your N storage centralized is okay and those who know AWS in AWS we
56:53
have service for NFS called EFS. So EFS service who give you NFS services in
56:59
AWS. So storage class capability they can contact to NFS or EFS service say I need
57:06
10 GB storage or we can do one more thing in AWS. If
57:13
you know we have service called EBS elastic block store. The technical actually is meant for block storage
57:21
real hard this row hard disk. Okay. So EBS is giving a service for block storage.
57:29
Okay. So storage class has a capability they can contact to EBS service also in
57:35
AWS and ask I need 10 GB hard disk.
57:40
Okay. So point is storage class is just a concept they have a capability to contact any kind of
57:48
storage. Those who buy know NFS those are known as file system storage or file
57:54
storage. Those who know block storage or EBS they are known as block storage.
57:59
That will give you like a row hard disk. Okay. storage class has a capability
58:07
to connect any type of hard disk.
58:12
This is one thing. Second thing, they have a capability. Okay, this
58:20
type they can connect to any of the services also. Now this service either
58:25
they run in AWS cloud, Azure cloud, Google cloud you have or you have you
58:31
have your own service or EBS kind of thing or NFS kind of thing in your on premises they have this capability
58:39
okay they can take the stories from anywhere okay
58:44
so let's let me continue this this discussion right let me create this diagram one more time uh to give you
58:51
entire flow then I come to the main conclusion what I'm talking about. So your app is the one who will run
58:59
inside the port or I can say it will run with the help of port. There's a better example.
59:16
Okay. And port is the one who will say I am going to claim
59:23
that I need some persistent volume but in your system personal volume will
59:29
create automatically automatically with the help of storage classes.
59:36
Okay. So if let's say if you claim for 10 GB PV will say I need 10 GB storage class
59:43
say okay I created for you 10 10 GB automatically give this 10 GB to this
59:49
PVC and PVC will attach this 10 GB storage to your container to your app
59:55
that is this okay now from where the storage class
1:00:00
will take the storage from okay for this there's a multiple choices.
1:00:08
They can take from any other public cloud. They take from private cloud. They take
1:00:15
from your own premises, your own kind of setup for storage. Okay. A storage class can take these
1:00:24
stories from public cloud like AWS, private cloud like OpenStack for
1:00:30
example. Okay. On premises, maybe you have your own block storage. there's got sandboxes
1:00:38
devices available like in LKMC and all the things they can take from there
1:00:43
okay but point is okay in AWS taking the
1:00:49
block storage I'm just only talking block storage okay we have different service called
1:00:54
EBS in openstag we have a different service for this so if you guys know openstag we
1:01:01
have service called cinder okay and send storage there the devices away from EMC's devices available for
1:01:09
this thing. So everybody everybody going to give a same thing right they if
1:01:15
they're looking for 10 GB they give 10 GB hard disk 10 GB hard disk 10 GB hard disk but the way they give the hard disk
1:01:23
the API is different their command is different okay the way we ask them is different
1:01:29
technically they give output is same 10 GB hard disk because we're looking for 10GB block storage or hard disk but
1:01:35
their way of of
1:01:40
uh providing this hardest the commands is different. So what we have done in the cubernetes
1:01:46
world we have created one standard interface
1:01:54
interface for the storage in this container world.
1:02:04
Okay, standing means now my storage class has to contact to this
1:02:10
interface only the way they call the command they use API they use is same there's no change
1:02:19
they say I need 10 GB hard because that's what my claim is
1:02:25
and we have to give this 10 GB hardest with the name of PV persistent volume like this called final storage
1:02:33
Okay. So I'm asking to create 10 GB address automatically because with the storage class
1:02:40
okay I'm connecting to you but behind the scene now this is your look out how
1:02:46
to contact AWS EBS service how to contact proc how to contact to some other tools and appliances
1:02:53
that you have to understood that you have to manage behind the scene.
1:02:58
Okay. And guys this standard interface called CSI container storage interface.
1:03:08
Okay. But obviously the this interface does not know how to ABS. So this
1:03:13
container interface behind the scene know and should know how to contact to
1:03:19
AWS EBS service. And for this we have to provide some
1:03:25
program that is also known as driver sometimes known as provisioner
1:03:33
provisioner. So we have a driver available for AWS EBS driver for open section. We driver
1:03:40
for DELMC tools and appliances. Driver like a program technically here
1:03:46
it is known as provisioner and full name is called CSI provisioners
1:03:51
for different different tools. Okay. So point is
1:03:58
okay if you talk about cubernetes perspective
1:04:03
okay cubernetes only understand port container PVC PV SC that's all
1:04:11
they does not understand what is able cloud and open stack but if you want
1:04:19
kubernetes resource type will take the story from some third party world like
1:04:25
as cloud is the third party for the cubernetes tool. Okay. So they don't
1:04:31
have to again change some there in the they don't have to change something inside them. Okay. For them we have
1:04:38
included CSI interface.
1:04:43
Okay. Interface where behind the scene whatever add and remove plug and play
1:04:49
into it. So when you feel no I want a story from open sender attach this
1:04:56
provisioner no next time you you want no I want a a story from AWG EBS services take attach
1:05:04
this provisional driver here or remove it if you don't want if you want both add both you want all you can add all
1:05:13
it is something like this okay so point this is the guys one point
1:05:19
so this is just concept of kubernetes again guys. Okay. Now, interesting thing
1:05:24
is okay. Interesting thing is this guys is a concept of CSI just a general concept
1:05:30
from the Kubernetes world. Okay. Kubernetes world. If you just search Kubernetes
1:05:38
CSI drivers. So that's what you can see from the
1:05:43
Kubernetes website has this is not the actually from EKS. It's a pure Cuban
1:05:48
website and that's what I was trying to explain you and they you will see lots
1:05:55
of you know PVC PV storage classes
1:06:02
let's go direct provisioning that's come from storage classes and storage class is one
1:06:09
that use driver behind the scene okay driver from the external
1:06:15
provisioners Okay. External provisioners.
1:06:22
Okay. And this external provisioner can be
1:06:28
a lot. Okay. So some example maybe you can find
1:06:34
so if you guys go through my cubernetes training CKA or CK so this topic from
1:06:41
more basics or more advanc set up everything there. Okay. Uh but I'm just
1:06:47
trying to show you some name here of the uh of the external provisional.
1:06:59
Okay. And external provision guys you can see maybe some vendors and some name
1:07:05
you will find somewhere. So just go and find just search finally.
1:07:10
Do you know what you will get? some some they keep keep on changing but uh
1:07:16
what this there's a source code here actually but what you find by searching as external provider you can get the
1:07:22
name of EBS or sender or Google storage or blob storage and Azure storage and
1:07:29
something like this that's what you get it okay
1:07:35
this is the guys entire concept challenge is challenge is if If you install vanilla
1:07:42
Kubernetes, okay, what I mean by this? If you
1:07:48
install vanilla Kubernetes, okay, the biggest challenge is what you
1:07:54
will have in the vanilla means there's no cubes from AWS something like this.
1:08:00
So you have the storage classes available
1:08:05
okay available as a because it's a part of Kubernetes
1:08:10
and whenever somebody say I need a storage they say okay I'll take the storage I have to contact to my CSI
1:08:18
kind of interface but in CSSA
1:08:23
that your plan is to take the storage from AWS EBS is
1:08:31
is service in AWS that give a block storage but I don't know how to connect to this
1:08:38
okay I can't connect to this I can't take this from EBS volume
1:08:44
okay why because right now this is a Kubernetes
1:08:51
okay vanilla cubernet you may be running your own premises system
1:08:56
okay and if you guys know a little bit about AWS if anything running outside
1:09:01
the world of AWS okay you can't access the EBS service
1:09:09
this called storage service to the outside EBS you can't use integrate to any thing
1:09:19
running outside the a maybe some trick you can use there's a different point but
1:09:24
there's a standard or support perspective Okay, you can't use eBay service outside
1:09:31
the AWS. So if you run the Kubernetes outside the AWS manage by yourself or
1:09:38
maybe another cloud maybe they won't allow you to take the store from EBS.
1:09:45
Okay, it means you have to run the Kubernetes service inside the AWS. How?
1:09:51
Again there are two choices. One choice launch issue instance
1:09:56
manually and manage yourself and other choice that we all want here is called EKS services fully managed services
1:10:05
fully managed services. Okay. Now which one to use but yeah if
1:10:12
you use any of the method either you launch your own cubernetes on the top of E2 instances that is inside the AWS
1:10:19
okay or EKS you can able to connect with the EBS service with the help of
1:10:25
provisioners provision means this driver I'm talking about these drivers I'll show you guys
1:10:32
this demonstration today so you understand what I'm talking about in detail okay but again we don't want to use EC2
1:10:39
services or EC2 instances to manage by ourself because otherwise lot of management and configuration we have to
1:10:45
follow that's what I started training with EKS so we will go for EKS
1:10:51
okay and if you go for EKS so interesting thing is AWS created EKS
1:10:58
service in such a way such a way that most of the component
1:11:04
they need to integrate with any other services they given to us. One of the
1:11:10
example I show you in my last class you know the load balance services ELB services
1:11:17
it's pretty integrated with EKS services
1:11:22
okay similarly EBS is also many more other service we
1:11:27
might have do something here but most of things they pre-given integrated
1:11:32
so as your operational work you don't have to do much and they give you mature integration ID
1:11:41
test integration with the services. So my entire say the conclusion guys is
1:11:48
okay if you run your cluster
1:11:54
of Kubernetes with EKS service Kubernetes service. It
1:12:01
will launch a cubernetes for you and whenever Kubernetes need any
1:12:07
persistent volume they will always contact a storage class.
1:12:14
Okay. And this storage class guys they give you pre-integrated
1:12:20
with with all the
1:12:25
AWS storage services. It can be AWS EBS storage. It
1:12:33
can be AWS EFS storage or maybe some other maybe
1:12:38
they give pre-integrated and how they give pre-integrated they have given a provisioner to us
1:12:46
that means driver or program to us. Okay. To check this
1:12:54
to check this right now my cluster has been launched in this folder. You can see this file has been copied.
1:13:01
This is what I created. What this file contain the detail of my cluster.
1:13:07
Okay. If you want to confirm this. So this file contain.
1:13:14
Okay. Where your cluster located. So the URL of the cluster. This is your
1:13:19
Kubernetes master or the API server cluster. Plus they given you the username
1:13:28
of uh this cluster plus they also give you the uh the password of this cluster.
1:13:37
Instead guys here they give the password they're using some kind of certificate. So they're using some certific
1:13:43
certificate based authentication. So they giving this certificate to you. But finally this is the IP address. This is
1:13:52
the kind of username and that is the kind of password in store password they have the certificate. Again this is not
1:13:58
the pure cubernetes class but this is the file look like how file look like
1:14:04
it means now onward if you want to uh connect to this cluster.
1:14:14
Okay, this cluster the information of this cluster plus the credential you can
1:14:20
find in this file. So it means now onward if you try to
1:14:25
create a connect to Kubernetes cluster obviously you guys you use this command cubectl
1:14:32
let's say get ports okay so if you run this uh file so they
1:14:39
will read the default file that I have in my windows
1:14:45
okay and my windows the default file I have that cluster is not up actually if
1:14:50
you see here my default file is located to my local system and my local system there's no cubernetes running.
1:14:58
Okay. So now onward guys when I run any cubernetes command I will always write this keyword even though it's in the
1:15:04
help also there's one keyword that you can use called cube config file keyword
1:15:10
to tell which cubernetes cluster you want to connect with.
1:15:15
So this option is not there but let me use hyphen cube
1:15:23
config keyword and then I can give my config name cube config or there's no
1:15:29
space whatever the keyword will be there's a space okay so this line means
1:15:36
we are connecting to cluster which cluster
1:15:42
this cluster because this cluster information is there in this file. IP address and the credentials.
1:15:49
It means second cluster when I launch I will store their information other
1:15:55
file. So it means I'm setting one workstation
1:16:01
and at one point in time I can connect to any of the cluster maybe one cluster maybe test cluster one cluster maybe my
1:16:07
development cluster one cluster may be my production cluster or whatever way way you want to arrange you can arrange
1:16:13
also okay I think this makes sense so now onward
1:16:19
any cubernetes command we going to run I'm going to type this in the last
1:16:25
or you can set in the default conf file also You don't have type but I am going to write because I'm going to launch
1:16:31
multiple cluster today. So sometime to connect here and there. So this keyword
1:16:38
will help me to shift the cluster here and there.
1:16:43
So now guys in this cluster there's a command for the cubernetes client or the
1:16:48
user I have no port is a new cluster all together. But my intention is to show you something else. If you see here in
1:16:55
my system, I don't have any PVC because nobody claim yet. Okay, because nobody
1:17:01
claim. So there's no storage available. But if you see we have a storage class
1:17:08
available. Okay. And in this storage class
1:17:18
that is available right now, okay, is using a provisioner called AWS
1:17:26
EBS. Provisioner is a driver. Actually, this is a driver they're using behind
1:17:31
the scene. Okay. And who give you this provisioner
1:17:37
preset of this class preset? Okay. EKS
1:17:44
U EKS uh services because they know this is very
1:17:51
commonly used driver we always always use they
1:17:57
use they they give you this pre-created storage class with this driver.
1:18:02
Okay. But the what the storage class means means anybody looking for the person volume this will
1:18:11
automatically create the PV for you automatically this called dynamic provisioning but where in the EBS
1:18:17
service so it means what you will see if I go to my AWS cloud
1:18:23
let me go here let me stop sharing also screen for a minute so if I go to my AWS cloud
1:18:33
Okay. So one interesting thing you will see. Okay. As soon as I launch a port in my
1:18:40
EKS service. So if you go to EK service, as soon as I launch a new port in EK
1:18:47
service, if a port need a storage running in this
1:18:54
cluster, a port need a storage internally
1:19:00
is a different service but this server contact to this service. This is called
1:19:07
EBS service and launch a new volume for you.
1:19:12
Right now if you notice guys I have only eight volume but you'll see automatic one more volume will be created in my
1:19:17
system. Okay. Or who will connect to EBS
1:19:23
service? My EKS. But how?
1:19:29
Because storage class asked them to call but how they connect they use this driver actually
1:19:37
this driver they use. Okay. So this is how guys. So my point
1:19:42
is guys same storage class you can create you know
1:19:48
vanilla cubernetes also running on premises but it won't work maybe you can run the driver but they won't connect
1:19:55
why the ebase is one service in AWS that does not allow you to give the storage the outside world sorry AWS they can
1:20:03
give to inside AWS only and mostly to EC2 service EC2 instances
1:20:10
okay And we know our worker node.
1:20:17
Okay. Even though we does not create by oursel but we know our worker node.
1:20:22
Worker node is one where port run right. So this worker node run EC2 only. This
1:20:27
is a worker node right to worker node launch. Okay. So EBS
1:20:35
is a service block storage will connect to the EC2 only and worker node running
1:20:40
EC2. So there's no harm in correct. So technically what I'm talking about as soon as you launch the port will launch
1:20:46
somewhere here maybe and when the port need a storage that time this will auto
1:20:51
create the storage attach to this instances automatically and right away you see this instance
1:20:58
if you see the storage okay this is the by default storage we have
1:21:03
only one storage connected it's called root volume similarly if you see this storage only we have connected with one
1:21:10
storage called root to volume but you will see automatically
1:21:16
this volume create auto test to this instance inside this set that is to pour on the container everything done
1:21:22
automatically who will do this connection
1:21:28
uh connect this create volume address here is done by this driver
1:21:34
this driver okay this is uh uh one thing okay one
1:21:40
more thing I want to add here If you describe this storage class,
1:21:45
right now we can create many more storage class also. Okay, by default KS service give a
1:21:52
storage class with GPU just a name. It can be any you can change the name also. GPU is just a name.
1:21:58
Okay, if you describe it, okay, what it will tell you? So those
1:22:04
who know again about AWS when you create a volume
1:22:10
okay you can create a different different volume types GP2 storage GP3
1:22:15
storage IO IO2 with some IOPS with some throughut
1:22:22
okay so this also you can set here
1:22:27
if you notice here okay I am using a driver called EBS is
1:22:35
but whenever we use this driver we are using a
1:22:42
uh storage type called GP2 mean this hard they're going to launch
1:22:49
but you think no your port is very mission critical you need a hard with a high speed
1:22:56
then you can change IO2 not from here in this storage class you can change Here
1:23:04
either can change in this storage class is already given to you or you can create your own storage class also
1:23:10
I show you how to create your own storage class where you can change. So what happen whenever storage class will
1:23:16
go and create a storage automatically by kind of ABS so they'll say no I don't I don't want GP2
1:23:23
general purpose hard I need provision IOPS or IO hard disk.
1:23:28
So that hardest will create it depend upon size what we write in the PVC claim
1:23:34
and that will be provided. Okay. And guys this is the use of anodes
1:23:42
and concepts. So in the open sift or in the kubernetes
1:23:49
okay SC is a storage type or resource type I can say but every
1:23:56
resource type has a concept called annotations where we can define some extra
1:24:03
capabilities what we want to provide.
1:24:08
So here I can say I my name is GPU it can be any other name also but my main
1:24:14
thing is I'm using this driver okay but when this driver run
1:24:21
obviously this driver got to EBS service but I have some extra settings to tell to EBS some information some meta
1:24:28
information that I don't need this hard at GP GB3 hard I need
1:24:34
fourth you write in the annotation Okay. And in the annotation guys there's
1:24:40
a keywords here. One of the keyword is called parameter
1:24:46
and parameter would be I need GPT hardness or GP3 hardness. And whatever you write here same thing by they
1:24:52
present here in the describe command just to show you the clear output.
1:25:00
Okay. So annotation is used in all the resource type in kubernetes or in the
1:25:07
open sift to tell some extra information about that particular resource type.
1:25:15
Okay, I'll change also something here. Okay, so this is uh one information uh
1:25:22
to be to be discussed here. Okay.
1:25:27
Now uh uh
1:25:32
what is the next point right so let's see this demonstration because when I start doing this demonstration lot many
1:25:38
thing we have to uh perform here okay so what I mean by this let me show
1:25:46
you with the uh demo part here okay
1:25:51
so uh the one thing that we have to understand here is
1:25:58
um as a quick conclusion again then I can able to show you the demonstration
1:26:03
okay why we are using EKS service because they're managing the
1:26:08
cluster for us second thing is they give you lots of integration one of the integration I show in my last class also
1:26:14
with with the external load balancer of AWS they they help us so when we launch a services in AWS sorry in the
1:26:21
kubernetes they autoconnect through the load balancer Plus EBS is one thing and many more you
1:26:28
will see in some time. Okay, this is one of the reason why we using EKS they give you high level
1:26:35
integration to other services of AWS. Okay, now point here is okay point here
1:26:41
is right now are
1:26:48
a cuminous cluster running where we have multiple master node but we can't see it. It is internal serverless but we can
1:26:55
see two worker node worker node one and worker node two it
1:27:00
become your entire cluster. Okay. And when user
1:27:07
of the uh of the Kubernetes if they use a command called cubectl
1:27:14
okay and say to your final cluster
1:27:21
technically they always say to the master API server or Q API that I need
1:27:30
uh PV precision volume. Then finally what happen? Same thing guys, they will
1:27:36
claim that I need this one and for creating this we will contact the
1:27:42
storage class and storage class we need some driver
1:27:49
called CSI driver. Okay, which driver?
1:27:57
This driver. But driver is what is a program.
1:28:04
Okay. And programmable guys in the cubic world we always run inside the code.
1:28:11
Okay. So point is does this driver is available right now? That is one point.
1:28:19
Does this driver available? Okay. Because driver is a program and
1:28:25
program on the port. So that all the internal driver of Kubernetes is managed
1:28:31
in one area that area is called name space.
1:28:37
Okay. So if you run the cubectl again this command
1:28:44
if you see right now which wherever you right now are if you see how many ports are running in current area that's
1:28:51
called name space there called default name space okay when you log in first time landed
1:28:58
first time you are always in the default name space name space like a room area or a project
1:29:05
there's no food but there's many more name space is precreated in the cubernetes and a lot
1:29:11
of cubernetes thing is available in some of the name spaces. One of the name space that is very important is called
1:29:16
cube system name space.
1:29:22
Okay, in this name space if you notice
1:29:28
okay in n is a name space we have a lot of ports are running or ports are running these are the inter port of your
1:29:37
kubernetes okay because of this two port we are
1:29:43
running two worker node actually because of this two proxy program both
1:29:49
the worker node able to launch a port that has a outside world connectivity
1:29:57
port DNS a port through which okay my port and application and we can give a port a host name that is pingable
1:30:07
right so again we are not in the class but I'm just trying to give you so there
1:30:13
are lot of pores is internal port or application system level port who doing
1:30:18
some working for us in the Kubernetes world the same name space where you can see
1:30:26
your CSI driver but it's not there. So my point is what I'm trying to tell
1:30:32
you storage class say I will use this driver I'm done but when you contact to
1:30:40
storage class and say launch launch
1:30:46
volume in EBS they say I know how to launch but as soon they go and start launching they try to contact to this
1:30:52
driver but driver is not running here so finally it will fail
1:30:59
okay so everything is uh setup but if the driver is not there
1:31:04
it will fail. Okay. How can you see driver is not there or not? This is the location we
1:31:11
can check. Okay. So point guys in simple term is whenever you want.
1:31:18
Okay. Whenever you want any provisioners like a driver here
1:31:25
cubernetes that is the one who through which they integrate with other services outside or maybe inside the as cloud
1:31:31
those driver you can find mostly here okay so setting may be done here but the
1:31:40
setting will work when we start using it it will fail this part you have to do by chance here
1:31:46
okay so you have to install the driver here. How to install? I will tell you.
1:31:54
But before install the driver, one more thing you have to do. What is this?
1:32:02
And again demo is very simple here. Nothing much complex. But I'm trying to
1:32:08
give you a lot of information here because this information is give you high base concept not for EBS for other
1:32:17
integrations also. Okay. Every every time we to think in the same way almost same way.
1:32:25
Okay. Now one more thing uh you understand here EKS is a different service guys
1:32:32
and EBS is a different service mostly come under EC2.
1:32:38
Let me use the word EC2. Okay. Now point is
1:32:44
if you if you want EKS will go and contact to EC2 and
1:32:52
ask to do something it won't allow guys. So if you guys know in AWS two service
1:32:58
in AWS try to communicate they won't allow to communicate. If you want
1:33:04
service one contact to service two in AWS world, we have to give some permission. This is called IM permission
1:33:11
mostly known as IM policy and the rules we have to create.
1:33:18
Okay. So point is EK service if they try to contact to EC2
1:33:27
for EBS it won't allow even though installed the provision provision will fail
1:33:34
finally pro mean driver will fail finally after you launch here you might
1:33:39
see they fail or they might not run okay why because EKS has no power by
1:33:48
default to contact to EPS PS. So we have to allow them. How? By
1:33:55
setting up the rules. Okay. And that may be one of the reason
1:34:01
if you go to EKS service here.
1:34:07
Okay. And in this service what you launch you might see some this line
1:34:14
the current user role D access to be clustered to something something something
1:34:20
okay means what they're trying to tell you here is okay that you don't have a complete
1:34:26
proper role setup so some of the resources will not work
1:34:33
some working you might have some by default or role created
1:34:38
So I'm sorry I'm not saying role is not created. So when you launch EKS automatically
1:34:47
they create a role where in IM service of AWS
1:34:53
they create one role for you. Okay, they create one role for you.
1:35:00
But the point is this rule does not have entire power.
1:35:07
Okay, this role does not have entire power. Okay, automatically one role created and
1:35:13
this role is attached to EKS. And what is role? So you guys know about AWS. The
1:35:18
role means um u
1:35:23
it it it it normally means for example I want to give EKS a power to contact to
1:35:30
networking to contact to VPC to contact to load balances. So what permissions
1:35:35
they have that can he cast into but this role whatever has been created
1:35:42
okay that role does not have a power to contact EBS
1:35:49
how I know okay we can check this
1:35:54
okay so how we can uh check this so technically what happened
1:36:00
whenever ease launch Maybe in the output somewhere you might see while launching the crater role
1:36:12
maybe somewhere uh in this output they might mention maybe so while launching they get a role
1:36:21
and that role that is to EKS cluster.
1:36:28
Okay maybe they mention here otherwise we have some way also to check. Okay. So
1:36:33
guys, if you want to check which role they created attached. So again in this
1:36:39
name space. Okay. They maintain this information
1:36:46
in a concept called config map. Okay. Config
1:36:52
map is a one again resource type in AWS. Sorry in the cubernetes. This config map is like a document. If
1:36:58
you want to manage some document or some configuration file or some setup in the kubernetes. So this is what where we
1:37:05
manage this. So in the same name space
1:37:11
they create one document or known as config map called aws oath.
1:37:17
Who created this EK service created inside the Kubernetes
1:37:24
and what this guys contain to see this we can say AWS O is a config map
1:37:33
okay same line come up but I want to see in detail so you see anything in detail you can use a describe command
1:37:43
okay so this document or known as config map they Say I am a Kubernetes service
1:37:50
for by EKS but in me one role has been
1:37:55
attached
1:38:01
and name of the role that attached with me is this one is a role name. It means
1:38:07
while launching the EK services this role created and this role has been
1:38:12
attached. for what this role contain.
1:38:18
So for this I can go to my as cloud and say in IM we can see that the role is
1:38:25
created or not or not automatically. Okay.
1:38:33
So in IM service there's a line here roles and if you copy this role and paste you
1:38:41
can guys see this role is available here right it was not there it is created or
1:38:48
used or maybe you can start to see history it created right now only today only see here today's
1:38:56
at this time when I launch the cluster this role created and guys a role we always attach to some
1:39:04
something right. So we create a role attached to EC2 instances. So EC2 will do something like this. Okay. So this
1:39:10
role created and attached to EKS cluster where in this particular config map
1:39:17
or this role can do as a permission. So this role can do only these things four things.
1:39:26
Okay. They can do something on the worker node. they contact to some registry, manage some instances and do
1:39:32
some CNI you know CNI is what your VPC thing so in last I show you guys some
1:39:37
networking thing is is happening in the in the Kubernetes why because they have
1:39:44
that power EK is different service VPC is different service but they can connect to VPC because they have this
1:39:51
power attached but there's no power for EBS
1:39:56
it means even though I have I launch a PVPVC
1:40:02
I launch the provisional driver. Okay. Still
1:40:08
still when you try to contact to EBS server it will fail. EKS
1:40:17
can't connect to EBS because we have no power attached.
1:40:23
Okay. For this you add more permissions here. Either
1:40:30
you can create a new role update the rule here or better would be the role already
1:40:36
created updated. So let me update this role from this page.
1:40:42
So what I'm going to add I'm going to add new power
1:40:47
on new permission. Now what permission I to give that will be your choice.
1:40:54
You have to give a permission to load balancer. You want to give a permission to cloud. You want to give a permission
1:40:59
to S3. You want to give a permission EKS. You want to give permission to EC2 full access.
1:41:06
Okay. And EBS is a part of EC2 only. If I give EBS EC2 full access, it means
1:41:13
it means it also have full access of EBS also. Again, giving full access is not a
1:41:18
good practice. So those who know IM in detail
1:41:24
or those who are learning uh AWS advanced training under me. So we are going to learn AM service in detail
1:41:31
where we are going to create our custom fine grain ner
1:41:37
permissions to allow specific thing only that we can attach but I to make it
1:41:43
simple and focus more on EKS only I'm allowing this means I'm allowing EC2
1:41:51
full access okay so technically for the
1:41:59
EKS cluster or cubic cluster. Okay, we have attached with this role
1:42:08
and according to this rule, okay, they have these power.
1:42:14
One of the power they have is called AWS full access where we allow everything
1:42:20
about EC2 load balancing. Okay. and many more things.
1:42:29
I think they also allow about EBS also. It should allow EBS.
1:42:34
Okay. Or let me do one thing. Let me check. Does they have extra policy also?
1:42:40
So EBS. No, that's what they had already. So we
1:42:47
don't need. So that is EC2 contain EBS, right? Otherwise we can customize.
1:42:53
Okay. So this but guys so just make sure if means whenever you try to integrate
1:42:59
EKS cluster with any other service AWS first you to allow
1:43:06
okay how by this first find out the role name
1:43:12
okay and go to this role and add the permission otherwise
1:43:18
everything you will do right but but the but the permission is not right. So it
1:43:25
will it will not work. This is the first requirement
1:43:31
but obvious is a not a new thing. If you know a little bit AWS this is what we always do but here this is a right
1:43:37
process to perform it. This part is done completely. The next
1:43:43
process is okay. Now we have power
1:43:48
but this provision driver is not running right now. How I know in my
1:43:58
uh cube system and name space there is no port for this storage class.
1:44:06
Okay. So what I'm going to do I'm going to launch a
1:44:12
driver or the provisioner. How for this? If you search for AWS EKS
1:44:19
CSI driver or driver install maybe
1:44:26
you'll get this link of AWS where they give you how to install
1:44:32
driver they can you can install driver EFS also you know NFS one
1:44:40
okay or a driver also so actually BS I
1:44:45
have to We looking for EBS driver. From here we can.
1:44:52
Now there's two way to install the driver.
1:44:58
One newer way they added to install the driver is a concept called add-ons.
1:45:05
Okay. So they have a concept called add-ons.
1:45:10
Okay. There were there why I show you in my last class also one quick command.
1:45:16
So if you want to install the driver okay so either you can install the
1:45:23
driver with add-ons mostly most not all but most of driver
1:45:28
we commonly used driver they giving you as add-ons and we have add-ons command for this to
1:45:34
install and see or other will be self-managed add-ons
1:45:40
means they give you some kind of script this kind of cubernet script you
1:45:45
can run it. Okay. So add-ons is not a part of cube
1:45:52
command is my part of EKS service and EK is made by EKCTL.
1:45:57
So in EKS guys if you search get right and get you can see add-ons here
1:46:07
and again in the add-ons if you see they're asking the add-ons for which
1:46:12
cluster because they might have multiple clusters right okay so we know our cluster name is a cluster one so I'm
1:46:21
asking just can you show me the add-ons for cluster one okay so there's no add-ons found right
1:46:28
in this cluster. We haven't installed any add-ons. Okay.
1:46:35
So to install the add-ons, we have a EKCTL
1:46:42
create command. So what is add-ons? Addons just a name. But technically addons is like a for
1:46:48
users. It's a EBS driver is EB driver. So we have a add-ons or
1:46:55
create add-ons. Okay. Add-ons. Then we give you give a
1:47:01
cluster name. Which cluster you want to add? Add-ons means your new uh provisioner or new
1:47:09
driver. Every driver something for you and name of the add-ons.
1:47:17
Okay. Name of add-ons and maybe some version also add-ons like a drive program. So which version you want to
1:47:24
store. So this is one of the new or fancy way standard way is
1:47:31
okay because this is available in EKS world but standard world because a
1:47:36
common kubernetes they have a driver concepts or provision concept in other kubernetes also.
1:47:43
So standard ways to use this approach. Okay. When I click this link,
1:47:52
okay, they give you drivers. See here AWS EBS CSI driver. They give
1:47:59
examples also some example for test purpose. Okay. And here they give you
1:48:04
link. Okay. Maybe in Java instruction
1:48:10
somewhere. driver installation they give you a link and they say this is the location where
1:48:16
you can find the driver this is the URL of the GitHub.
1:48:22
So if you want to install the driver either you can use typical cubin apply
1:48:29
command or those who buy know helm chart you can use helm also and you can use
1:48:34
eks add-ons also multiple way you can install it but standard way is qc pi
1:48:40
command this is a code they give you to install the driver
1:48:47
okay so if If I
1:48:52
run this command, it will install the driver. Guys, by chance there's some thing is there. If you try to run this
1:48:59
add-on or this driver from Windows CMD, there's some special character they
1:49:06
might not supporting. So, it might feel might not be might feel in Windows
1:49:12
command prompt. Okay. So there's the reason guys, one of the reason why I'm using this get bash
1:49:19
CLI tools look like Linux. Okay. So that won't have this issue
1:49:28
and paste. That's all. So finally they will install this uh
1:49:38
d for view. Again you guys know why this reason come up because this is cube still command and cube still command
1:49:43
should know where my cubernetes is and my kubernetes is located
1:49:49
in this file. Okay
1:49:54
so the contact to my actual kubernetes where they're running that is there in this file and they install this driver
1:50:00
for you see a lot of things they have done. Okay, so those who know Kubernetes
1:50:06
understand what is service account and arbback and deployment and demon set and
1:50:11
all the things. But finally conclusion is they installed the driver.
1:50:18
How I know just very quickly check last time we seen the port
1:50:24
it was not there but now this port is there and they're creating
1:50:30
okay so they're running and they're creating and if you notice here now they're
1:50:35
running right again I'm repeating guys if you see this number is not last time
1:50:41
is zero right and still if you see zero for longer
1:50:46
name it means your driver is not installed. One of the reason can be role.
1:50:55
Okay, your role is not properly set. But I have given EKS a proper role for
1:51:02
EBS services. That is one of the reason why my driver has been stored successfully.
1:51:09
So in my system this driver has been installed successfully. This driver has
1:51:14
been installed successfully. This this is the main driver actually. Okay. From the server and they run the
1:51:21
driver in all the node because we have two nodes they launch the driver in two nodes. We have three nodes. They launch the driver in all three nodes because
1:51:26
any of the worker node can use the port and their port will connect to EBS services. So they need
1:51:33
driver in all the worker node.
1:51:38
So finally the driver has been installed successfully. Technically finally
1:51:45
what I'm trying to say you here is uh I want to show you here is
1:51:53
that your u EKS cubernetes cluster now has
1:51:59
integrated with okay with EBS services.
1:52:06
It means whenever you contact for the
1:52:13
the way I explained to you for PV storage class will auto create for you.
1:52:19
How I know I will show you a quick demo for this. Okay. But one more thing
1:52:26
I want to add here is if you see the storage class.
1:52:32
Okay. a storage class if you try to describe
1:52:40
describe the storage class and that's why it's called GPT GP2
1:52:46
by first storage class that is given to us is using a driver
1:52:54
AWS EBS there provisioner but my driver name I have is a EBSC
1:53:03
CSI driver, EBS CSI driver. Okay.
1:53:10
So technically they feel this is the driver name but we don't have this driver. My name is different. My port name is different. Driver name is
1:53:16
different. Okay. So either you update this by
1:53:21
default settings. We can update if you know the edit command. If you know edit command you
1:53:26
can update or we can create a new storage class. I think create new store
1:53:31
makes some sense. Why? Because we also learn new things also.
1:53:36
Okay. So I'm going to create a new storage class here. Okay. Again creating a storage class a
1:53:42
pure concept of Kubernetes. But let me do very quickly for this guys. Anything you want to do in the Kubernetes world,
1:53:48
we have to create a YL file. So I don't want to go and creating completely either you can
1:53:55
find somewhere here as a quick example.
1:54:00
Okay. So guys, this is also one of the command they give you to check driver installed or not.
1:54:09
So in my cube she seat system again the last way to I forget to write always
1:54:14
this.
1:54:21
So this is actually the driver name actually we are searching this driver
1:54:27
name and this driver installed successfully but who will use this driver actually
1:54:33
this is the driver name. Okay who will use this driver
1:54:40
my storage class. So create the storage class maybe they give some example here
1:54:45
how to create the storage classes by using this driver or creating storage class is very common thing uh you can
1:54:51
find lot of code in the market for creating the storage classes I have this
1:54:57
code I'll share I have in my GitHub I'll share this link to you can get the
1:55:04
code from there okay so if you want to create a storage
1:55:09
class storage
1:55:14
class. This is the code we have.
1:55:19
It's a pretty simple code. Those who know Kubernetes, they might know this. But technically, if you try to
1:55:24
understand the main thing about this uh file is we are going to get a storage
1:55:30
class. Name of class is this one. You can give any name. In my case, I already have a name
1:55:36
name GPT2. But we're going to create a new name.
1:55:43
Main thing is this storage class using this provisional or this driver. And I show you already
1:55:52
this driver. I have AWS. This actually the the full domain name.
1:55:58
But if you go inside also, you can find this name there. Okay. Probably as a.com.
1:56:07
This is the driver I'm using here. Okay.
1:56:12
So, let me use this file. And guys, this is like code of Kubernetes. Any code of
1:56:18
Kubernetes you have, you can directly run it. So, just take this URL.
1:56:24
Okay. And to run, you can run with cubectl apply command. And because it's
1:56:29
a file, I can give file and the URL this URL.
1:56:36
and are running in this cubernetes cluster. So your your new storage class created
1:56:45
how I know this new storage class created
1:56:52
okay where they're using this provisioner.
1:56:58
Okay, this new storage class is created here. Now it is your choice.
1:57:05
Okay, you want to use this storage class for this but if you this the you need
1:57:12
this driver running in your uh somewhere in system and if you use this driver
1:57:18
should run in my case it is running okay and it is not only about EBS
1:57:24
similarly you can install a driver for EFS also
1:57:30
so if you want to take the storage from NFS services like EFS elastic file system AWS is same concept you can
1:57:37
install the driver. Okay. But he do again allow the rule also or so roll also. Exactly same
1:57:44
approach. Okay. Now after storage class created now we have no challenges. This again
1:57:51
one time setup guys. So is AKS guys or AWS cubernetes guys have to do this
1:57:56
setup once. Now after this after this the life of the cubernetes
1:58:03
will guys will very simple. Now what they do they launch the port
1:58:09
okay and while launching the port they'll tell only one thing I need storage that's all they will explain to
1:58:16
you. So what happen what they will do? Okay, they will launch the port and say
1:58:23
while launching the port I need PVC claim let's say I need 4 GB space
1:58:32
okay and automatically this request go to storage class and storage class will go
1:58:40
somewhere where somewhere in my somewhere here is
1:58:46
my EBA services. Okay. And go to eBay service and launch
1:58:52
4 GB hard disk here in eBay worker. You know it is a
1:58:58
it is a uh volume. So automatically this 4G volume created here right now only
1:59:05
eight. See in a minute automatically it become 9 create and this volume
1:59:12
is class create and provided to PV
1:59:19
and PV is the one who actually give to PVC. So right now if you notice in our system
1:59:25
I don't have any PV PVC created neither PV
1:59:31
neither PVC another PC another PV but nobody has asked them.
1:59:38
So let me show you guys how the command for PVC okay again is a pure cubernetes command. So in this doc I'll share this
1:59:45
doc otherwise this pretty simple nothing very complex.
1:59:51
Here we have a way to create PVC.
1:59:58
Okay. So those who know about AWS or maybe open sift sorry given open sift this is how we create what we write I am
2:00:06
going to get PVC claiming and you can every PVC you can give a
2:00:11
name this is a name we are giving you can any name but main thing is I'm requesting for 4 GB hard disk.
2:00:20
Okay. But I'm requesting to whom? There's two storage classes. I'm requesting to this storage class
2:00:28
and the storage class. No, they take from EBS or take from EFS or maybe from
2:00:34
EBS if you're trying to take. Okay. So, if you just to see the describe of it
2:00:39
EBS SC, let me describe this name. Okay.
2:00:44
Okay, if you're taking from EBS then what is the U storage class type?
2:00:53
Okay, it's not it's not mentioned here guys. There's no parameter here. So what
2:00:59
what are by default value in the as world they take it maybe GP2 or GP3 they will launch
2:01:06
other can some parameter also in this annotation file. Okay, the parameter that you see here.
2:01:12
For example, if you see the GPT2, so GP2 is just a name here storage class. And
2:01:19
if you see this parameter here, this one we can set also or we can edit. How to
2:01:25
edit? You might know we can use edit command to edit this.
2:01:32
So we can go here and change this. What? We can change this parameter.
2:01:39
Okay. Okay. Or we can change here also this parameters
2:01:46
in the top in the annotation. So multiple way we have we can go and uh
2:01:51
change. Okay. Or let me take from here
2:01:57
copy and cancel this and I'll go to my this
2:02:04
one different storage class. Edit and let me paste here. So they
2:02:11
don't have any parameter. Let me add
2:02:18
save. Close. So
2:02:25
update to parameter forbidden maybe guys while launching we have to set up right actually. So when I launch this storage
2:02:32
class that time we have to. So we after parameter forbidden update through
2:02:39
parameter are forbidden. So maybe guys there's a possibility we can't update the parameter while launching after we
2:02:48
launch something we something you can't change after you launch but during
2:02:53
launching we have to do this. Okay but let me check the syntax here um syntax
2:02:59
here. So storage class format uh cubernetes
2:03:09
storage class parameter
2:03:17
type GPT2 I'm just taking some example but while
2:03:23
launching that we can change in the code we can change in the food
2:03:30
and then we can apply it. So the storage class we have this is how it look like. So this is what exactly I've put here.
2:03:38
Okay. And then after we change we can apply it.
2:03:45
Okay. Or something we can change
2:03:50
this is class default but not everything right. So what I'm going to do let me
2:03:55
copy this code. Okay. And uh let me close this
2:04:02
and let me do one more small thing. This is storage class I have.
2:04:08
Let me delete this. We can delete also with delete. So I have no storage class. D we have
2:04:14
but storage class deleted. Okay. And what I'm going to do I'll copy my code from here
2:04:22
and do some changes. Okay. to give some little bit.
2:04:29
This is a storage class.
2:04:35
I'm going to edit this code and what I'm going to write,
2:04:42
I'm going to write a parameter.
2:04:47
Okay. And here my plan is to give GPT3 hard
2:04:53
disk type. And as soon as file system is ext4 means uh what um because we are
2:05:00
going to provide this storage to our port application and you guys know BSV
2:05:06
cube row hard disk. So in this row hard disk they will format it
2:05:12
with ext4 xfs whatever format you want you can they will do automatically for you.
2:05:18
Okay. So that is the meaning of this format type here.
2:05:24
Okay, let me click row.
2:05:29
Come on. Where is save? Right.
2:05:39
W.
2:05:47
So I committed already. Right. After I commit, click on the row
2:05:56
comp
2:06:04
class. This is what I saved.
2:06:13
What is happening? Let me copy from here. will come up
2:06:19
right I don't know why okay so let me copy this code let's store in locally my storage class yimml we can also take
2:06:27
from the local system also okay and we can apply from here so
2:06:33
there's a code we have cubectl apply
2:06:40
this code okay again same thing
2:06:47
you have to tell which cluster.
2:06:53
Yeah. So now this storage classes is been created and we little bit customize
2:06:58
also the way we want to uh uh use.
2:07:04
Okay. So this storage class is customized and now if you see we have a parameter and
2:07:10
automatically the the annotation also been set okay that I
2:07:17
want ext4 format and I need GP3 hard disk
2:07:22
okay so that kind of customiz many more keyword parameter you can write you can find a lot of in the documents or
2:07:31
storage class documents okay this parameter many more things
2:07:37
allow volume expansion or not. Okay. And many more things you can apply. Yeah,
2:07:43
this is the list I was talking about, right? So these are the provisional list.
2:07:48
You can connect Kubernetes through EBS, Azure file, Azure disk, open sender, GP,
2:07:56
GC, cloud, NFS, SAF, storage, many more.
2:08:01
There's a list they are talking about. Okay. But here we are using EBS.
2:08:09
Okay. So this was the thing. Now let's let me launch uh
2:08:17
PVC. So guys I'm not focusing on the code
2:08:22
expression. This is a pure Kubernetes code. Okay. But quick information I'm just
2:08:28
giving to you. So we are taking this storage of 4 GB. So let me take
2:08:36
so again cubectl we going to apply or maybe you can use create command also apply little better
2:08:44
command okay applying this code on this cluster
2:08:51
so what it will do it will create a pvc claim they are doing
2:09:00
okay and if you See in this cluster can claim created.
2:09:07
Yes, they're using the storage class. This is what they use.
2:09:13
Okay. But state is pending because PV guys is the one who is just
2:09:20
claiming we want this like a request and they will pend will be always in the
2:09:28
pending state till the time PV created. The PV is storage created.
2:09:35
Why is it not created? Because when we use a PVC,
2:09:41
we have given this storage class. And in this storage class, this what you
2:09:47
can see here. There's one special keyword we have mentioned over here is called volume binding mode coverage for
2:09:54
first consumer. Okay, this is a one of the keyword in
2:10:00
storage class like there are many more keyword it's called volume bind mode keywords but this keyword means in
2:10:08
storage class if somebody come to me who will come PBC then I want 4GB space I
2:10:18
won't give them okay I will make them in the pending state
2:10:25
Okay. Why I won't give till the time first consumer come and use it. Consumer
2:10:31
may be application. Application is food. As soon as some port start using this
2:10:39
PBC and asking I want to use this PBC in my port in my application.
2:10:45
So as soon as the first consumer come up, first port come up and they need this
2:10:52
PVC then only I will go to GP33 on EBS and create a 4GB hard
2:11:00
disk because they ask for 4 GB hard disk and then only after I will give them PV
2:11:09
and after PV come then only PVC will be in the use state binding state or bound
2:11:16
state status again guys concern from cubernetes only
2:11:21
but it's a con this is the keyword Y look like so there's no error here it's good facility actually a lot of guys
2:11:28
start claiming but they don't need it the code does not need it okay so there's no meaning right now
2:11:35
there's no if you go to my AWS world okay still I have eight volume
2:11:44
There's no nano volume new created, right? Why? Because
2:11:51
the PVC in pending state. Okay. And PV is not created. PV is the
2:11:57
one who actually create a volume here. PV is not created because of this
2:12:04
concept of storage class keyword called wait for first binding.
2:12:10
Okay. So this one so now the point is
2:12:18
okay PVC has been created but it's pending state so who is going
2:12:26
to use PVC my p that we explained to you the diagram that I show you today or
2:12:32
this is the was the diagram I was talking about okay is the one who is going to ask I
2:12:40
want to use you I want to test you in my application
2:12:46
that this application Apache web server or MySQL wherever they want to use that would be their choice. So let me launch
2:12:54
the port for this. Again we have a YL code for
2:12:59
this. So I have YL code for port. So I'm going
2:13:04
to launch a MySQL.
2:13:10
Okay. So, I'm going to launch a port.
2:13:15
Okay. Pode. And this port is going to you launch a MySQL.
2:13:23
Okay. My MySQL. And um that's all.
2:13:30
But if you guys know if you launch a MySQL services, MySQL store entire data in a folder called where WHTML. So where
2:13:38
li where li MySQL. So if you want to make your MySQL
2:13:45
permanent, okay, your data permanent,
2:13:50
then you have to mount the storage into MySQL container or the
2:13:58
code into this folder. Your volume mount would be this folder.
2:14:06
But where you take the storage from? You take the storage from PVC. Which PVC?
2:14:11
this PVC what I created already this PVC here
2:14:18
I say we already have the PVC I will ask this PVC
2:14:25
okay wherever you have the storage you're taking okay PVC 4G by chance so wherever this
2:14:32
storage you're taking I want this storage I know you're getting from EBS volume you have to mount to this folder
2:14:43
Okay, mount to this folder. It means whatever you put into this folder, everything is permanent. Why?
2:14:51
Because port may be deleted again created
2:14:58
but but your data will be permanent
2:15:04
because what I'm putting inside this folder because MySQL is is is the this is data director for MySQL. MyQ is
2:15:10
putting all the data databases indexes file here tables here they are technically storing into this folder
2:15:18
is center storage come from EBS. Okay.
2:15:24
And those who know a little bit about again about Kubernetes MySQL when you use a MySQL image they need to create
2:15:31
some accounts root account user accounts.
2:15:37
So this account guys they take value from the environment variable and here I'm using secret.
2:15:45
So secret is again one kind of database from where I'm giving this information
2:15:51
to my SQL. So first of all I have to create a secret. So I have this file with me again. So I'm going to create a
2:15:59
secret here. secret is like a one one kind of vault
2:16:05
where g I'm giving a secret a name and I'm giving two passwords
2:16:12
is store different variables and this variable I'm going to use somewhere so I'm I'm creating the secret first
2:16:28
the secret has been created okay very quickly I want to show you secret is like a database or kind of world
2:16:37
having this name. This is the name I given. Okay. And the secret we have two
2:16:44
variables that contain some password and some base encode 64 encode. But this
2:16:50
variable you root root pass and user pass. This verby I'm using in my my my
2:16:58
in my myql
2:17:04
this one. Okay that I want my root password from
2:17:10
this variable from this secret. I want my uh user password
2:17:17
username is vl in my case password from this same secret by from
2:17:22
this variable. So my school guys will automatically create this root account with this
2:17:28
password. We use a whiml with this password and the databas that again not so much important for us
2:17:34
right now our topic is storage but in this from this myql image
2:17:41
from this myql image um we going to launch a mysql database
2:17:49
inside this container this folder will take the space from here entire data of
2:17:55
this folder permanent that's what we want to make it permanent Okay.
2:18:02
So this is a port. Now what you will see now this is the final guys entire integration. Right. So when we apply
2:18:09
this port.
2:18:15
So this port will create and this port become our consumer of this PVC
2:18:24
and this storage class from where this PV space the store say as soon as the first consumer come up I will give the
2:18:31
storage to you I'll give the PV to you
2:18:38
and from where I give the PV to you I know from where to give I know I have to give from the EBS Yes
2:18:46
volume still we have a eight but you will see entire integration we have
2:18:51
write is right or not. If yes now you can see very quickly
2:18:58
your PVC is been bound to to
2:19:05
PV and if you go here and refresh last time
2:19:10
eight volume we have I say fantastic right? without coming to AWS,
2:19:17
without coming to EBS services. Okay, we are managing entire storage of
2:19:24
EBS. Similarly with EFS also and interesting thing is we are managing everything from the Kubernetes command.
2:19:31
That's native Kubernetes command. This not not command at all belong to AWS.
2:19:36
Kubernetes command pure Kubernetes command is able to retrieve in the last
2:19:42
class I show you the load balancer now today we able to retrieve the storage
2:19:47
and they launch storage so PV storage so we give 4 GB storage because that's what
2:19:54
PV ask for PBC ask for 4 GB
2:19:59
so 4 GB asked for so we create a 4 GB PV
2:20:05
okay PV PV with this name and same name we are given to my PVC as
2:20:13
a volume. Okay. And if you
2:20:18
search here the last I think this may be last one. I see a GPD3 also this is what they have given to us.
2:20:25
Okay. has been uh attested and uh
2:20:32
and we are created actually
2:20:39
at the time. Let me set the time today is this one. This is
2:20:45
what I created actually last one not this one last one. So this is a volume I created and if you
2:20:51
click on this volume this is used right.
2:20:56
So this volume automatically attached to some of the instance which is say this one right this is one
2:21:02
of my my uh one of the what I can say the worker
2:21:10
node right because port is the one who always run the worker node right that's what you can see here
2:21:18
okay so this entire process okay and u uh but if you notice
2:21:26
If you run the port,
2:21:32
new port has been launched. And if you know the process guys, if you
2:21:39
attest any port as volume, port will always in the pending state till the
2:21:46
time volume does not create because my volume created already. So this is they launch the container and run it. running
2:21:52
means this storage has successfully connected this port. How I know? We can
2:21:58
describe the port also. Describe the port
2:22:04
u uh port name is called DB port one.
2:22:10
And in this port if you notice my port is scheduled in one of the
2:22:16
worker node this one.
2:22:21
Okay, it means the same system where my
2:22:27
PVC has been or PV has been attached. Not PVC, PV has been attached.
2:22:32
It means this this volume attached to this worker node. If you see here, this work node will be same. This work node
2:22:40
name. If you click here, the name of the worker node is say 143.
2:22:47
1 43 same, right? And this worker node if you notice one
2:22:53
is storage attached here last one is not there right I'll show you but this work node auto 4 GB test
2:23:03
but if you go inside this node this work this 4 GB in this work node what the
2:23:09
account would be okay if you can able to log in I don't know
2:23:15
so this 4 GB is not attached to instant actually directly this 4GB internally
2:23:22
attach to the that this is not connected because of firewall maybe. So if you enable the firewall then they connect
2:23:28
but this 4GB and this worker node is actually connected to the port mount of the port.
2:23:37
How I know? So we go up and in this port
2:23:44
some volume mounted in this folder. Which volume? DB wall one and what is DB
2:23:49
wall one? D1 one is my PBC. Okay.
2:23:57
It means inside this board anything that I do in this board okay
2:24:04
will store data here and everything where I store here is permanent
2:24:10
is permanent. That's what uh I would like to tell you
2:24:15
here. Okay. So I think you understand the entire process guys right most of things
2:24:21
is it belongs to kubernetes even though I try to explain you in a way that you can relate the and connect the dots but
2:24:28
main thing is about the integration csi drivers how we can use and connect these
2:24:34
pieces together okay and everything working great and fine and um
2:24:41
u that's all if you delete the port even though before delete the port let me do one thing the port is running right now.
2:24:49
Okay. And let me go inside the port. So for this we can use execute command
2:24:56
T. I can use bash if the support or
2:25:05
have to give the port name also. Right? Which port I have to go? DB port one
2:25:12
of an SS
2:25:22
wit. I think this double half might be getting issue.
2:25:33
Okay.
2:25:41
So we can create from IP address also. I'm just trying to
2:25:47
connect this board.
2:25:56
So this command is a simp execute command right we use
2:26:03
execute command it and then we give a port name DB port
2:26:10
one and let me connect with SSL I don't know if they have SS or not
2:26:16
they don't have I don't know why this error but my point is if you just go inside this port let me drive this
2:26:23
command run is yeah this running right
2:26:29
tty input is not there why it is saying this
2:26:37
yeah it's working and uh this also working install ss
2:26:43
Actually
2:26:57
this command should work. Maybe this container might not support this. But
2:27:02
point is if you're trying to go inside this container or maybe we can expose
2:27:08
this container with some service. Okay. And then if you try to put some
2:27:13
data okay then uh you will see uh
2:27:19
everything's permanent okay that is a one thing right so
2:27:25
there's a guys whole idea about it otherwise as a storage class perspective there's a lot of keywords right
2:27:33
we can write so if you talk about storage perspective so uh where
2:27:43
So when you create any storage classes like uh like a where it is PVC or
2:27:51
storage classes there a lot of keyword they have volume binding multiply binding lead and many attributes I'm not
2:27:59
discussing this point again this pure part of cubernetes whatever we need to know I just
2:28:04
explained to you in the case class intention is how to connect the
2:28:11
uh drivers. That's what we would like to tell you. Okay. Now point here is okay. Right now
2:28:22
this port is running. Okay.
2:28:28
This port is running. Okay. And you know guys one concept if
2:28:34
you want to create a replica of the pool
2:28:39
okay a replica of the pool multiple copy.
2:28:45
So we have a scale command or replica command here in Kubernetes 10 or 10 20
2:28:51
100 port we can launch but here this port is using
2:28:57
storage behind the scene called EBS and EBS has a capability one EBS they
2:29:05
can connect to only one OS or one container or one port.
2:29:12
Okay. So finally it won't work. If you try to if you try to make a more copy of
2:29:20
this port they using the same storage or same standard storage it won't
2:29:25
support. Why? Because you know about AWS EBS
2:29:30
service can mount only in one OS only to
2:29:36
one container only. Okay. This is not the limitation from the
2:29:42
from the port world or the kubernetes world. This container
2:29:48
okay does not support multiple mount only they using they can't connect more
2:29:54
is one thing. Second thing you should know one more thing in EBS they sometime
2:30:00
back they launch one facility that is not available in GPG they and IO2
2:30:08
and that facility is called multiattest facility this one
2:30:15
if you think your port you are planning to create a replica 5 10 20 port
2:30:23
you want to read and where you want to use same storage centralized storage
2:30:30
then you have to plan properly you have to use a storage class that is pointing to IO2 or IO1
2:30:38
because they are the one who support multiattach even the IO1 does not support also IO2 is the one who support
2:30:46
multi-attached facility okay so again you need to plan it for it
2:30:52
so accordingly you to create a storage class the way I created with with the
2:30:58
way I created uh with this IO2 type okay
2:31:03
that's also plan but again we have a limitation if you know the those who know again AWS they might
2:31:10
know the limitation is if you're if if you are creating a IO
2:31:20
two multiase but they could either 1 A 1
2:31:26
But when you create a replica of the pool, some core pool run in worker node
2:31:31
one, some run in worker node two. But worker node guys we always put a node group and node group we always uh plan
2:31:40
that one they launch in one a one they launch different ag. So multi multi a does not work in EBS.
2:31:51
Okay. So maybe they support multi- attach but they can only connect all the
2:31:57
port in 1 A any worker node run 1 B 1 C does not work they doesn't support they go for different agent again it is a
2:32:05
limitation from EBS it's not again issue of the of the Kubernetes or PBC storage
2:32:12
classes or storage driver so point is if you are trying to integrate with some services
2:32:20
so what are the limit they come up with according you have to plan your strategy and your design
2:32:27
okay if you really think you need a block storage then according your plan what I'm talking about you also plan
2:32:34
that multi how much they support I think they support maximum 16 up to 16 support
2:32:40
they support not more than this
2:32:45
okay but you know you want more you want multi-ag code.
2:32:51
Okay. So for this you can't use EBS. Then you have to go for different storage that's called EFS.
2:32:59
So you can create a storage class. Okay. Not for the EBS. You have to
2:33:05
create a storage class that will use a provisioner and a driver for EFS. This cos services
2:33:15
process will be almost the same what I explained to you today. Okay, they have multi sub facility many
2:33:21
port you can connect with centralized storage and so so
2:33:27
uh what I say uh replicating replicating the the
2:33:32
code won't be the big challenge for you guys. The point is using a services or manage
2:33:41
services on the cloud like EKS you have to understand the the limitations
2:33:49
and the use case of the both the side what cubernetes will provide and what
2:33:54
AWS will provide as a limitation right so you have to plug together think in both the angles then create your design
2:34:01
and plan and study then you can deploy your your applications over here that's
2:34:06
also very very important point to be note we can't blindly launch anything uh
2:34:12
just to sake of launching right so I think that this is a great demo uh
2:34:19
today we launch a port with port directly but you can launch a port with deployment that's a better practice
2:34:25
but I just launch port directly uh but we can launch with the deployment
2:34:30
also I'll share this link to you even though let me share right now in
2:34:36
chat message in this current meeting
2:34:42
over here. So that's all guys uh till here any queries if you have because I would like
2:34:47
to conclude now but you can get the entire approach I highly suggest do by
2:34:54
yourself uh kind of similar demonstration by changing a lot of
2:34:59
keyword in storage class file or do the same demonstration for the service called EFS elastic file system service
2:35:06
NFS service and try to get the storage okay and interesting thing is your code
2:35:12
will exactly Same there's no change in PVC my square everything same because we
2:35:18
have a CSI driver everything same
2:35:23
only okay only we will install a driver of
2:35:31
EFS that's all okay but cube builder perspective the
2:35:39
code will be exist same they does not worry much about it coming from EBS or EFS that's also one cool thing this
2:35:45
version why is called CSI so we have many more thing to be
2:35:50
discussed guys in EKS services in next class we'll talk about it but till now
2:35:56
any query if you have you guys can ask okay
2:36:09
thank you for parameter annotation means thank Amul
2:36:14
even though Amul if you the in the last class
2:36:19
I show you there's example service that they connect to the load balancer they also if you see the annotation of
2:36:26
services you'll get lot of idea what exactly you want because they write
2:36:31
there that in the annotation part that I am a service but I am connected external
2:36:37
services called ELB with this name Right.
2:36:42
Amazing session after a long time. Thank you Himu very much.
2:36:51
Any other things guys? Any query if you have I think Shiva what you asking you guys
2:36:57
maybe I think you got the answer if not you can ask me again.
2:37:03
uh annotation is for machines actually cubernetes will read the annotation.
2:37:11
Okay. So you can think annotation is for humans also. Some of the things we also
2:37:17
write annotation as a as a kind of metadata. So something can be useful for
2:37:23
human human being like who is a maintainer the author
2:37:29
company name and some kind of metadata also we can write that might not be used by kubernetes but some annotation they
2:37:35
use okay to retrieve the information about something for example if you see the
2:37:42
annotation of node okay so if you see here uh oc get nodes
2:37:50
command Okay. and node and if you try to
2:37:55
describe the nodes so kubernetes will get lots of
2:38:03
information from the result here annotations
2:38:09
these levels these are okay
2:38:15
that in this nation there's some CSI volume we added
2:38:21
plus we added to this worker node. This is the ID of AWS node ID. This private
2:38:29
IP of the node. Okay. So,
2:38:36
some information is for us and some information Kubernetes will use behind the scene.
2:38:42
Awesome class. Thank you very much. Thank you Dolly.
2:38:50
Yes, P. uh if you guys have multiple storage classes.
2:38:57
So if you don't tell here which storage class to use.
2:39:04
So when you create a PVC if you don't tell the storage class
2:39:12
where it is okay if you don't tell then by default
2:39:17
storage class they use okay which is by default class. So if
2:39:24
you see the storage class there's one by default class. So there's tag there again that is come from annotation only.
2:39:32
So this is by default see default keyword. So we have a 10 store class but this
2:39:38
will be used by default if somebody does not mention manually here in the PBC.
2:39:44
Okay. But again this default keyword also guys come from
2:39:50
annotation.
2:39:55
Okay. Okay, see in nodes this is where we write is class is true.
2:40:04
So I can edit this file and change is false then there's no default or I can make this as a default. I can go to this
2:40:10
class and add this annotation this annotation as it is true. it become a
2:40:18
default. Even though we have command also available cubectl annotation without
2:40:24
editing this file we can manually add on command line also this also you can use or you can edit command to add. Okay.
2:40:33
So that is the default.
2:40:44
So 4GB will have got until the first column come up. There's no chance to exiting exhaustion ratio before first.
2:40:50
Yes, why not? Winker test. We have a keyword for this. Okay. We have a keyword for this.
2:40:58
Okay. So in here in the storage classes,
2:41:05
okay, volume binding is this one, right? We can we can change the volume binding. So in the cubernetes
2:41:14
storage class volume binding if you search for volume binding there are many more world binding one will be immediate
2:41:24
so as soon PVC demand okay
2:41:30
we will give them let's go immediate so PV we will get a PV
2:41:38
code come up or does not come up does not matter as soon PVC demand
2:41:43
we will imitate give them this called volume binding called imitate here I was using something else but you can also
2:41:51
give and some use case may be useful and one of the use case maybe I know when port come up
2:41:58
providing the volume for will take some minutes a second maybe so why not initially we get it so it's ready to use
2:42:05
this can be one one use I want Yes. Okay. But this also we have so multiple
2:42:11
volume binding mode available in the world of uh storage class but
2:42:18
this is what you are asking you can achieve from here.
2:42:24
Hello sir great s can you have also add ingress alb small demo if possible? Yes
2:42:29
uh vin we will definitely add something of ingress. Okay. But yeah more ingress controller
2:42:36
and all the things if you want to learn. So in my service mass topic so we are going to start soon guys ser service
2:42:42
mass st training there we have a very very detailed
2:42:47
uh discussion on ingress control and many more things. So yes v we are going to start soon rest service me training
2:42:55
we'll update you soon. Uh the we will already launch it but when we going to
2:43:00
start we'll update you soon.
2:43:06
Okay.
2:43:11
So if if I can change the driver running port ABS to EFS. No actually punish uh
2:43:17
driver is independent thing. We can load unload driver whenever you want.
2:43:24
Okay. But if your port is getting restored from EBS you can't change directly.
2:43:30
It is something like this. You have two drives.
2:43:37
It is something like this. You have a drive uh for example uh C drive. You're
2:43:42
putting data here and you want your application running behind the cinder
2:43:48
drive chains. So it won't work in this way. Okay. So technically it will stop
2:43:55
operation on it and then unmount and mount it. So that can be possible
2:44:02
or we can create one more storage in EFS mount the same folder
2:44:08
okay on the fly but all data will be removed
2:44:13
okay so technically we can add it but we have to do some extra operation before this we have to first copy data or
2:44:19
replicate the data then we can mount okay or we start doing some some kind of
2:44:25
small maintenance window you to put and then transfer the mount. Okay. Yeah,
2:44:32
adding the new storage and mounting on the fly is possible but it will you will
2:44:38
stop seeing your older data that we have to properly plan it.
2:44:44
So yeah so I also want to do survey mess training but is financial uh amul actually this training was very highly
2:44:51
price from the red hat. Okay. But we tried our best in our case. However,
2:44:57
financially we can help us. I think we wrote the form also and uh what are the best from Linux world side we can help
2:45:04
us and services too we have provided.
2:45:13
So that's all guys. Uh so see you in the next class. Similarly we have many some
2:45:19
more interesting demonstration on the EKS world. we will do in the next class.
2:45:24
I highly suggest guys do this demonstration practice on the top of EFS also. Okay. By good tech.


ript


1:13
Good evening everyone. Welcome to your AWS solution architect session. Uh Vimla
1:20
would just start and join in the session in next five minutes because he just completed the previous session.
1:27
Just wanted a quick update to you all that I hope you all have got the access
1:32
for your learning portal. There is no one in this group who has not received the access to the learning portal
1:38
because if that is the case you can please let us know. We would be happy to help you with that.
1:44
If that is the case then you have Aloc Rahul in your WhatsApp groups please get in touch with him and he'll be there to
1:51
help you all. Other than this, we have been circulating the AWS CSA practice
1:57
questions as committed from our end. You know that we'll be preparing you for the exam as well. So we have already started
2:04
that journey. We keep circulating the questions and you have to answer an attempt. What we are expecting is okay.
2:12
We all expect 100% participation from you all because when you are learning it's not just about listening to what
2:18
Vimmels is saying. It's also important and crucial that you practice what he says and also answer those questions
2:25
which my team is working really hard at the back end so that you parallelly get prepared for the AWS CSA solution
2:32
architect paper as well the global certification as well. So it's a humble request to everyone that please start
2:40
attempting attempting those question sets on a serious note and please give 100% attempt I mean to say I'm expecting
2:48
every participant out here to attempt those questions for your reference.
2:53
Yeah so that is one thing another thing is we keep hap we keep doing Q&A sessions in between by our team instead
2:59
of women daggers. The purpose is to keep practicing what you are learning and in case if your questions are unanswered in
3:06
the class due to any reason then we still have people to walk along with you in this journey so that you complete the
3:12
journey with sheer dedication and you don't face any other chances correct so
3:17
that is it from my side I just wanted to update I hope you all have that sis second thing is all the session what do
3:22
you call this the screenshots of all the things which have been delivered is there on their AWS thing we expect you
3:30
all to have 100% participation for the question sets which we are sharing with
3:35
you all. It's a very crucial thing. My team is really working hard in behind you know you can see the right answer.
3:40
You can see what is your score. You can attempt it. What else are you expecting? Okay. And this is how you can practice
3:46
parallelly and get prepared for the certification without wasting time later. Currently the topics are very you
3:52
know fresh in your mind. So you can very well attempt the certification as well. It's for your benefit.
3:59
I'm opening the chat and the Q&A for in case if you have any management related queries you can definitely raise it I'll
4:05
be happy to help. So one of them has just mentioned yes ma'am we can understand I was also with him in the m
4:11
that was an amazing session thank you so much manoj for appreciating the session whenever we learn with reml it's always
4:17
a new experience be it any technology I'm sure you would have had a excellent
4:23
session with him which just started today and you know I'm sure everyone knows that those all these good
4:29
companies are using nodejs and you know all of those things it is definitely a plus to learn full stack with vimlaga so
4:36
how to access the other courses omar the other courses are still not open for everyone's access yet uh but we'll be
4:43
soon opening it not right away probably we would need another 15 20 days more time
4:50
uh ma'am please share the practice session group name there's no group name we are sharing that links in your groups
4:56
Aloc Rahul is the one who keeps sharing those questions okay for that kindly
5:01
increase the number of questions for more practice we'll have to go slow by slow we cannot just increase the questions to 50 60 and 80 and then you
5:08
don't do it at least we see the increment in the number of participation is where we will push our questions as
5:14
well but we'll go slow we'll go slow yeah women sir is the hero of my life thank
5:21
you so much Prashant I'm sure he has impacted your life I'm sure ma'am can we
5:26
please have some break between both the sessions for food like we used to have earlier priu will manage today was a day one I'm sure it was tight and the
5:33
content is also too much for more so we'll We'll try to ensure to manage this.
5:40
Anyone else has any question?
5:46
Ma'am, I was a part of Kubernetes and Anible training in 2021. Shall we get the access for that recording? Uh, no.
5:51
Sushil, we are not providing any access for any previous recordings and everything. But yeah, if you were a part of Ansible or if you register for anible
5:58
certification, then we are still giving an access for that.
6:08
Uh ma'am please give us access for more than 30 days because it seems to we not able to cover since we're going to a college also. I accept bat and I don't
6:14
think we have removed the access. It's more than 30 days already. So we know you know where to take it care of the
6:21
same. Don't worry.
6:28
I hope I clarified that there's no practice session group. There are those links which my team is sharing in your
6:34
groups respectively.
6:40
[Music]
6:49
Um is it possible to provide terapform recording also for 2.2 or 2.2 access
6:54
learners who are active till June will definitely be getting that. If you are an active learner then you will
6:59
definitely get that. So Aloc Rahul my you know team member is
7:06
mentioning that only 51 people attempted the test three of AWS that's wrong guys you are expecting us to increase the
7:12
number of questions you're expecting us to do this you're expecting us to do that we are working hard for you all so
7:18
that you all can clear this global certification also without any hurdle is working so hard to give you the right
7:23
content which you won't find it anywhere trust me go and attend AWS CSSA session
7:28
with any organization across the globe I can challenge you. You won't find discontent what meals is delivering
7:34
still you don't go and attempt this thing we can't help you and the more the lesser the number of participation
7:40
obviously it demotivates the team as well that why are we supposed to work so hard but still my team will work hard
7:45
don't worry yeah but I'm I would appreciate if I expect and if I don't do
7:50
that if I don't see that participation happening because it's kind that is kind of a cross check on yourself that how
7:57
much are you learning with women sir that that really means that you don't want to measure yourself. That's
8:03
absolutely wrong. We are supposed to measure oursel. Now, is there any link to apply for the
8:09
certification? No, we don't hold any links for applying for AWS certifications. We just hold it for Red
8:14
Hat certifications and we have been doing and helping people around for that. AWS you need to manage it on your
8:20
own for the certification exam booking.
8:27
Is there anything else which anyone would like to put it across? if I have missed it.
8:41
It's a humble request to each one of you all. Please don't rely on the recordings and you know let's do it later and all
8:48
those things. Please stop doing that guys. Please stop doing that. It's for your benefit that Vimlur is delivering
8:53
it live. It's your fortune that you're attending it live with him. So then why do you want to go and rely on your
8:58
recordings and everything? Why don't you shell out your time and do that rather than giving excuses that we don't have
9:03
time? Yeah, it's a humble request.
9:09
Last two minutes I'll be there in case if you have any further queries you can please raise
9:28
uh Alo Rahul it will be my request to please share all the three links again with all the learners I'm sure now they
9:34
all will be attempting and they'll take it more on a serious front and go and attempt those questions. sets which our
9:40
team is really working hard towards it. So please do that.
9:55
Ashish, will this training be completed by July 5th as we have EHV5? But yes, we are expecting and whatever would be left
10:00
in case if something is left, we'll be covering it over the weekends. That's what we we are expressing. we like we're
10:05
expecting them also to do because we have one of the one of the
10:11
most popular training certification by red hat starting on 5th of July which is again live by women daasur so definitely
10:19
I'm sure you all are excited for this RCA track how many more topics are left over and
10:25
how many more sessions sort of no one knows that whimsa never follows anything in terms of content in terms of anything
10:32
it's his wish that till where he wants to take this knowledge to you all. So we never restrict him on that that what
10:37
topics are left how many more sessions are left no one knows that
10:45
till the time we are learning till the time we getting something I'm sure you all would love to attend the sessions
10:54
ma'am only Linux basics if we have will it be okay for RCA definitely you can start your journey definitely that
11:00
should not be an issue you can start your journey with that rest will guide you during the session
11:05
If you have enrolled yourself for 358, don't worry. Is there any plan for Ansible and Kubernetes? No, we just
11:11
completed anible in the last month. In the month of February, we completed you know anible. So I'm sure we don't have
11:17
any more plans for anible and kubernetes also. We just completed in container batches. So yeah, when will the 2.0
11:24
journey be completed? Our 2.0 journey will be completed by August 10th or September first week.
11:35
2.0 learners are fortunate enough to get so much of content with these you know
11:40
professionals and at this level be it AWS or beat any technology be terraform
11:45
be genkins be DSA beat containerization or you know anything even mo to the
11:52
level wimsur is delivering this time you're blessed
12:01
ma'am please arrange a class on how to make efficient notes during live classes I'm sorry but I myself don't know how to
12:07
do that. How will I be able to guide you all till when we have to pay us? It's almost
12:12
10 months. You don't have to pay now. We we asked you to pay only for 10 months and I don't think we're asking you for the next month.
12:23
Any plans for Azure as of now? No. In case if we have anything, we'll let you know.
12:42
That's it from my side. Over to Vimlur and thank you so much each one of y'all for being here and attending the session
12:48
live with Dagasaur. Thank you. Thank you.
13:16
So guys uh let's continue with the next part. Welcome back and um so let's see
13:24
what the plan for today. So today guys I would like to start a new topic in AWS
13:29
cloud. Okay uh that is called load balancers.
13:34
Okay. Or I can say the elastic load balances there's one one some small
13:39
topic is there in the VPC that we'll discuss after in some classes because uh
13:45
after having load balance and some more topics then that that knowing that particular topic of VPC makes more sense
13:50
right so right now what I'm going to do like I'm going to start a new topic
13:56
in today's class that is the load balancer right so first let me explain
14:02
you the use case what challenge challenges we are facing or what challenge we might face if you don't
14:08
have the load balancers and then you automatically understand the power of the load balancer right
14:15
so there's a multiple different challenges we guys can have if you don't have the load balancer
14:22
and guys after this load balancer even even though we have multiple different type of load balancer that's what we
14:28
going to discuss okay classical load balancer um
14:34
and network load balancers um you know application load balancers
14:40
then you know gateway kind of load balancers we have so multiple load balancer we have we will discuss all the
14:46
load balancers obviously not in today's class but by by till tomorrow I think
14:51
almost all the load balancer will be complete and one more topic that is more
14:58
connected to load balances auto scaling group okay after having this topic Okay,
15:04
understand this topic of autoscaling group also been completed. Okay, sorry.
15:11
So there is the further plan guys for this two or three classes from today on
15:16
onwards, right? So let's discuss one by one the use or the challenges or the use
15:24
case where we need load balancers. Okay. So one case where we can use a
15:33
load balancer is something like this. Uh you guys know we have multiple AGs. So
15:40
let's say my one of the AG in Mumbai region is 1A.
15:47
Okay. And we launch our resources. Let's say one of the resources called EC2 in
15:53
this particular A. Okay. And my client is connecting to
15:58
this particular uh instance obviously maybe from some network or maybe over the internet they connected.
16:05
Okay. Now it's all depend guys upon your uh requirement and the use case. Maybe
16:12
this instance is running with some kind of web app let's say website. Okay. And
16:18
this website may be your entire company business e-commerce site. And a business is
16:25
running on the top of uh your web app that is hosted in this instance.
16:32
It means it means uh there's two challenge
16:38
you will have you will have here because it is not the small thing is the entire web running and your business depend on
16:44
this. So for us it is a mission critical application I can say or I can say this
16:50
is the website is running in my production and I don't want in any of the cases my applications go goes down
16:57
because it is for us is a mission critical kind of application okay it may be your
17:04
banking application your e-commerce business financial or anyway anything
17:11
okay so my point here is if your application running in the instance in one a data
17:17
center. Okay, then there's two big challenges you will face. One challenge
17:23
may be okay due to any of the reason if your entire data center goes down.
17:33
Okay, Amazon is not giving you 100% guarantee. Maybe they give 99.9%
17:38
guarantee something like this the data center don't go don't goes down but there's a possibility it might goes
17:43
down. Okay. And in this case, Amazon is not taking any responsibility of of having
17:52
any downtime in this region because they already have the SLA, they already have their service level agreement with you.
17:58
They say 99% they are always up. But for us
18:05
that many hours or minute your instance goes down. Okay. spend that many time or
18:11
that much time your client won't have a connectivity. It means you will lose
18:16
your reputation because having your website goes down maybe on working hour
18:22
it will highly impact the reputation of the company. Okay. Like let's for example Facebook goes down for some
18:27
minute it will impact the reperson. Okay. Plus it will also you also lose the business
18:34
because some lot of uh banking transaction is going on customer processing your data also your products
18:41
they can't do the business with you. So huge loss in the business. Okay. So it
18:46
is up to us to properly plan the strategy there something disaster
18:52
happen. Okay. Disaster happen.
18:58
Then how we can plan for DR this for disaster
19:03
recovery. This plan we have to do. Okay. And one of the plan in this in
19:09
this example may be what can we do? we can we can launch one more instance of
19:16
EC2 with the same web server running or website running in the other data center
19:22
let's say in 1 B in Mumbai and that is guys one of the reason why Amazon has
19:28
multiple AS in one region so that we can plan our disaster recovery properly
19:34
anything happen so if one AS goes down second a they normally keep in very long
19:42
distance almost 100 miles and some kilometers. So due to maybe
19:48
earthquake or some tsunami or some kind natural calamities if something goes
19:53
down power failure other data center won't be or AG won't be affected.
19:59
So this facility Amazon gives to you to have one more AG but how you going to leverage this facility that will be up
20:06
to you. So if you think your application is very important, so what can you do? You can have one more copy of the
20:13
instance running here. Okay. So one challenge what I'm talking about guys is
20:19
use case is or challenge is disaster or I can say use case is disaster recovery.
20:24
It will impact these two things or maybe any more things for you. Okay. So how we can uh solve this use case here? We will
20:33
use the load balancers. how and how they will solve in a minute I will explain.
20:40
Okay. So this is one place where we can have the use of load balancer we can
20:46
use. Okay. One more challenge guys I will let me
20:51
tell you first then I'll explain what is the load balancer and how we going to use this. Right. One other challenge may
20:58
be your application is running in one data center here in EC2 and there's a
21:04
new website you launch your new product you launch as maybe startup company and you start doing the marketing
21:10
you start doing the marketing and uh maybe your product goes viral a lot of
21:16
guys and a lot of customers start liking your product your product goes viral so there's a possibility okay as per your
21:23
plan what are the plan you have planned for that maybe you plan that that till
21:28
tomorrow I will have around,000 customer come or maybe plan let's say in a in a
21:34
second the way we are doing a marketing in a marketing campaign almost 10 client
21:40
per second going to hit my website okay according to plan that you launch
21:46
website instance with instance type that have this much RAM this much CPU this much network bandwidth and this is the
21:53
application products you add some development code like multi- threading, tons of things you plan according
22:01
that if around 10 clients hit to your site, they will have a proper response
22:07
uh goes to the client. So there will be no as such uh slowness in the application. Maybe you might have
22:13
planned for for 100 clients that in a second if till 100 clients come and hit
22:19
my website that is the maximum bottleneck we can handle. Okay. in terms
22:26
of network bandwidth RAM and my applications internal code application whatever the developer write the code
22:31
and the way they write the code but there's possibility there's a possibility that you might
22:39
have might have more than 100 clients hit to the server okay so maybe suddenly
22:48
let's say in a second your marketing campaign goes viral and now what you start seeing that now every second more
22:55
than 10,000 client or thousands client but your your server can handle more
23:02
than not more than 100 requests. So what happened remaining
23:07
um 900 requests guys u the client remaining 900 clients will see you
23:14
either website is slow or website is down they're not getting the proper response so it is again a big issue in
23:19
the repetition and the business and point is simple if the client hit to your site for something if they're not
23:26
getting the response mostly they won't come back because of this bad experience
23:31
and is a huge waste of money and the client base for your future business
23:37
also. It means if a lot of load is coming
23:42
as a network traffic from the obviously from the customer the
23:49
client how you going to manage this is again one of the second challenge. So one is the disaster recovery, one is a
23:55
load of the traffic. How we going to plan and manage that's what we have to do. Okay. Even though in this use case
24:03
only load balancer might not be enough. We have to use autoscaling group also.
24:08
What are these? Uh I might give some idea today but this is exclusive topic. We will discuss tomorrow day after
24:14
tomorrow this topic. But based on this two pointer now it makes sense to to understand what
24:22
is load balancers. Okay. So what is load balancers? So idea very simple. Okay. If
24:30
you think there's a possibility one of the computer goes down. So it is always
24:35
good practice at least you have two computers running together or maybe more than two computers running
24:42
together or instance running together. together means they're running uh same time. That is your choice how and where
24:49
you want to place that was a different point but you can have more than two or
24:54
three computers maybe why because wherever you putting the computers the entire data center goes down there's a
25:00
possibility your instance also fail again because this is managed by us is
25:06
not managed by AWS if the instance fail AWS is not taking any responsibility for
25:12
this you have to and we have to take care of this so in any of the cases you can I have multiple
25:19
EC2 instances running over here. So let me give all the instances IP address.
25:24
Let's say this IP address is one, IP 2 and IP3. It will use and launch
25:29
multiple. How many depend upon your proactive plan by respective
25:37
operations team. They can plan proactively by some uh different method
25:43
how many clients can hit again based over on the marketing plan how much they
25:48
are doing the marketing is a different whole different different topic about the uh the infrastructure planning all
25:56
right or the resource planning and something like this that is not the important point to be discussed here
26:01
topic is very important but it's not the main point to be discussed here but let's say I launch three instance uh
26:08
over here. Okay. Now what we will do? Okay. Now
26:14
because we are running three instances with the same exact web applications here exact same copy I'm running all the
26:19
three instances. Now what I can do one of the facility I can do is I have a
26:25
client somewhere and I ask my client right I
26:31
ask my client that is one website is running. Okay. And I'm giving you all
26:36
the three IP address one, IP 2, IP 3, all the IP address public. So do one
26:42
thing. Okay, do one thing try with IP 1. If you think IP 1 is response will give
26:49
the response to you that's nice. But but if if you feel IP one is down or
26:56
they're not getting the response, then change your UR in your browser and type two. If two is not responding change the
27:03
you are in the browser and type three. So in this case this problem can be
27:08
solved. Which one disaster recovery or maybe goes down can be solved. But for the user perspective is not a good user
27:15
experience. Okay. Facebook say I'm giving 100 different IP type every IP one by one
27:22
one by one over Facebook one.com Facebook2.com. None of the you can going to do this. they will type one name, one
27:29
domain name. Okay, if they hit they will use it otherwise they will move to next.
27:35
Okay, so this is not again the better solution. The better solution would be something like this. Rather we give
27:41
multiple IP to the client. Okay, we can launch multiple instances having some IP
27:46
address. So between client and the sorry
27:52
between the client and the instances we can run one we can put one computer or
27:58
one system here one instance here. Okay the beautiful thing about the
28:03
instance is now this instance will have the own IP address let's00
28:10
and this IP address we can give to the client. Let's Can you hold for a second, please?
28:33
So this IP guys we can give to the client. Now what happened? Now we have
28:39
one instance and one IP if give to the client. So for the client side it has a
28:44
good user experience that client has to only type one IP and one URL I can say here. So this problem of user experience
28:52
will be solved by having one single computer. But what this computer contain does this computer contain any web
28:58
application? No. This computer doesn't contain any of your web application. But what happen? What happen whenever client
29:06
hit to this URL? client feel this is the website they treat this IP00 as a website this
29:13
is what they type in the URL http col less ipund00 or something like this okay
29:19
the path maybe they treat they feel this is the website
29:26
okay and when this client request come to IP00
29:32
the beauty of this system is this computer is or this device is what they do They will hold this request of the
29:40
client behind the scene. Client have no idea everything happening behind the scene. And this system, okay, this
29:47
system on the client behalf, okay, on the client behalf create a new
29:53
request and send to one of the components where actual web application
29:59
running with their own web pages and web data. Okay. So according to this system,
30:06
this system feel the request is coming from the client but in this case they feel the client is IP00
30:13
but doesn't matter whoever sent the request to IP1 they will reply. So IP will request to the system
30:20
and this system will reply to IP00 only or respond to IP00 only. And as soon as
30:27
IP will get the request will get the request this data whatever
30:33
the request get it they get they again uh send this data back to the client. So
30:39
whatever client request they hold in the same session or the same request they
30:46
send this data back to the client as a reply. So in this entire context okay the
30:54
entire context right what client feel that they send the request to 100 and 100 is a reply. So they treat 100 as a
31:01
final web server or web application server but internally we know we are the one
31:06
who going to create this and set up this. We know this is not the web server. Okay. This system is only okay
31:14
work as a intermediate in between client and to the my final server as
31:21
intermediate between and on the client behalf they're sending request and getting the data from the real server.
31:27
So in this sorry in this context this intermediate server is working as a proxy
31:34
typically known as reverse proxy. by proxy. Okay, because anybody who will
31:41
doing something on your behalf are known as proxy. So this computer is working as a proxy. It means actual request of
31:49
client never hit to server. Never hit to server. So my real server
31:56
real server won't see any request coming directly from the client.
32:04
they only see request is coming only from IP.
32:09
Okay. So what is the benefit of your request proxy? After you have this setup ready, lots of powerful setup you can
32:15
build on the top of this. One of the powerful setup you can build on the top of this. Now onward you don't
32:22
need to give any public IP to your instances.
32:28
It means sorry you can run your instances in your private subnet
32:36
and private subnet will give you extra security you guys. So automatically you'll get a extra security for this.
32:41
Now onward you don't have to put your instances web server and where you want web server
32:47
to be accessed by public world. Now web server will be access world without putting in the public submit
32:54
just by having private IP address. Okay we can access why why because if client
33:01
is coming from internet that is a reason we need public IP. But now client is not directly hitting two instances. So why
33:08
we have to give public IP? Why we have to put in the public world? We can put in the public subnet or private subnet
33:13
sorry in the okay but because this proxy program IP
33:20
belongs to your company only. Okay. It's not a public one. So any company running in your company means is
33:27
running in your VPC. You guys know anything running in the VPC they will have a private connectivity. So IP 100
33:34
will have private connectivity to the IP let's say whatever let's say they have private IP maybe let's say in this case
33:39
is 100 to one they can connect to 1001 very uh simply with the private and you
33:46
guys know when any private computer can get any private computer so sending and transition any data is very secure very
33:53
fast in the network perspective and plus they're free so anything any network
33:59
traffic is going inside the VPC from one system to other system with one private computer other private assistance
34:05
computer devices they won't charge you so you will save the cost also
34:11
so after having this proxy setup in between lots of benefit you will have
34:17
and one more benefit you will have here is now we can make this instance more secure by adding a security groups
34:24
firewalls till now guys we are setting the firewall at anybody from anywhere in the world on port number 80 allowed it's not
34:31
good rule rule in terms of security. Now what can we do? We can create a security
34:37
rule. Anybody who come from IP 100 only now IP 100 will come to you client will
34:42
be anybody. Client can be any IP in the world. Can have billions of different IPs but every client will come via proxy
34:50
as IP and 100 IP always connect to this actual instances here. So request will
34:57
always come from IP. So what can we write here? We can add here any computer come from any request come from IP on
35:03
port number 80 is allowed. So the security group perspective we
35:09
have better security in firewall. We have no private public IP. So I public IP will save plus my instance is not
35:17
actually available to the public world. So it's called expose. So we are not exposing any computers into the public
35:24
world. There's also max extra security layers and ton more further uh benefit
35:29
of management you will achieve after having you having this kind of setup.
35:35
But why we are creating this setup? Okay, we are creating the setup is not only for security. We can do the
35:41
security in another way also. We created this setup for one purpose. The purpose is now because my client is hitting only
35:48
IP behind the scene. What is the IP address of my real instances where my real
35:55
application running? These come are known as backend servers. So what is the my real backend server?
36:02
Which IP they are running? They are d they are down or not. Client has no visibility.
36:09
Okay. And where they connecting which instance they connecting client has no visibility. Client has to know only one
36:15
single IP for IP00. So it up to you up to you this system.
36:20
Let's me use the word D up to the computer number D or system number D. They know where they connected.
36:27
Okay. So in this case what can we do? We can launch multiple backend servers.
36:32
Okay. And we connect all the backend servers to your B computer.
36:38
Now here this D computer also known as front end computer. Why front end? Because this is the computer that is actually connected to the real client.
36:46
So any computer that is connected to the internet client or the outside clients they are normally known as front end
36:52
system. So P is a front end system here. Okay. And all the real computers where
36:58
my application is running they are the back end. Okay. Front end guys have no
37:03
application. Application running only on the back end. Front end is working as a
37:08
proxy program for some extra security. I explained to you already. And one more thing guys front end is working for you.
37:14
Now from front end guys here because they know there's a multiple computer working behind the scene. So in this
37:20
case front end is also work for you as a load balancer
37:27
means when the first client come and send the request okay this front end has
37:33
a capability they see this first tren come up they send this first client request let's say client number one to my my let's say instance number A second
37:42
client come up my front end will send this request to system number two let's
37:47
say B third client come up from outside world my front end or that's called load
37:53
balancer send the request to third client to the computer number C so what is known as this is load
37:59
balancing the balance in the load how let's say initially one computer can
38:06
only connect 100 clients together in one second now we have three computers so
38:12
first request go here second will go here third go here fourth will go here fifth will go here six will go here so
38:18
totality around in this case 300 connections we can do per second. Again
38:24
guys 100 200 300 I'm giving a rough number more or less but this many
38:30
connection per second we can do means these many clients we can serve. We feel
38:36
you feel there's a possibility there will more clients going to come up. We can add more computers. One more computer, fourth, fifth, sixth. We can
38:43
add more and more computer and adding more and more computer to
38:49
serve one thing that is this concept is called scaling. We scaling the thing we
38:54
are scaling the computer we are scaling the resources and because we adding individual computers that is known as horizontal
39:02
scaling. So here we are doing the horizontal scaling and alo also known as scale out.
39:09
So we are doing scale out here right now we we are doing manually but
39:15
this scale out can be do can be done automatically by taking the live decision with the help of autoscaling
39:21
group that's what we'll discuss in the next classes okay right now we will do it manually so 3 10 we do manually for
39:30
this manually this scale out so so adding more and more resources
39:37
scale out but if Now in the future or after maybe the next day you feel that this these many client doesn't come up
39:43
can remove the computer behind the scene. Okay, for example, let me we can remove
39:49
three. But if you remove three, we have no issue in the client. Okay, because
39:55
client is not directly connected. If they remove client won't see it. Client have don't have to update the IP
40:01
address. Client will only connect to IP 100 only. They we don't have to update the client because asking the client to
40:06
change the IP address is almost important. For example, Google say the IP change. How you guys come to know IP change? Google said the name change
40:12
google.com to google one.com. How you guys come to? So we have to give one
40:18
single IP, one single name to client. But behind the scene any computer you run, create, remove, they have no
40:24
visibility because everything is running in the back end or behind the scene. In this case, if you remove okay your back
40:31
end will know. So your so your front end will know or load balancer will know it removed. So any next request come up of
40:39
the client they won't send here. They send to remain compress.
40:44
Okay. So either you remote manually because none of the because you're not getting any
40:49
connection from the clients to save your money because if you launch more more
40:54
amount you have to give or maybe this instance maybe launch maybe launch by
41:00
somehow it fail. In any of the cases your load balancer
41:06
come to know that instance number C is failed and because they know they
41:13
have failed. So in the future any new requests come up they won't send to this guy.
41:19
Okay. So they will check that you will fail or not. Okay. And how they check?
41:25
There's a concept called health checking. So my load balancer has a capability. Okay. Any computer you
41:32
connect behind the scene the scope back end they keep on checking the health. Health means they keep on checking you.
41:38
How the D is a different computer B is a different computer and two computer if you want to check the health. Health
41:44
means A want to check does B is connected. So in the networking world the only way
41:49
to check the health is keep on sending the packet. If they reply means they are live. Keep checking the packet. If the
41:55
they are they are running there's no other networking issue no wire loose there's no physical error there's no
42:02
firewall issues they will reply and if they reply it means A will feel
42:07
that B is running right now. We can use it. That is not B is healthy.
42:13
And checking this health is called health check. So there that's a health check. So load balancer has a capability
42:20
to keep on checking the health and health checking is a continuous continuity thing. It is not like this.
42:26
For example, right? If I call your mobile number and your mobile number is ringing right now, it doesn't means you will have a connected after 5 minute. I
42:34
will check does you are connected not with me. It is a continuous process. I keep on checking and by calling you
42:39
after 1 second, 1 minute, 2 minute depend how frequently I have to check are you healthy or not you are connected
42:45
or not okay same thing in the load balancers we can use this setting here
42:51
I'll show you how that they can keep on checking they are healthy or not healthy or not if they're healthy they will keep
42:58
on using this for the next client request if they feel they are not healthy so
43:04
they declare load B declare they are not healthy means they they will say this is out of service
43:12
means their next client request they won't send send to this okay because if
43:18
they send the request they are not healthy they're not connecting so my they won't reply they don't apply how my
43:24
load balancer will or my proxy program will send back to the client so these
43:29
are the few capabilities of the load balancer by default they will provide to you
43:36
Okay. So in this by this example what you achieve okay this part you achieve if you have a
43:43
huge traffic come up load we have more and more computer we can run
43:50
behind the load balancers. Okay. Plus this also you guys achieve which one
43:58
where I got disaster recovery. If one of the computer goes down in any of the data center doesn't matter my
44:04
instance will be anywhere. Okay. So my other instance we will launch. So in this case we can do a
44:10
plan. Plan would be I can launch two instances. This instance I can launch in one A center. This I can run in 1 B. If
44:16
my this 1B data center goes down instance goes down doesn't matter. My load balancer come to know this is out
44:22
of service in this case remaining client request they keep on sending to 1 A data
44:27
center or A components or 1 C data center or C component. So disaster
44:33
recovery strategy can be planned in this in this way. So let me recreate this
44:39
diagram very quickly to add some more point. So now finally guys okay whenever
44:44
client now it's good practices always good practice even though you might have to use only
44:52
one single instances to run your web app or any applications
44:58
okay but it is always good practice okay always run this instance behind
45:04
your load balancer okay and guys when I say load balancer
45:10
almost every load balancer has a inbuilt capability called reverse proxy is a inbuilt capability of all the load
45:16
balancer even though we have different separate proxy server come in the market the different point but if I say load
45:22
balancer proxy reverse proxy concept is always come with them so it's not separate okay so now onward I'm going to
45:28
use the word only load balancer so even though you have one single instance always run behind the load balancer okay
45:35
and always give client IP of your load balancer for example this IP 300.
45:42
So always give kind this IP address or I can say always give the IP address of the front end.
45:49
Okay. Why? Due to a lot of reason if you go why in this way so client has no
45:54
visibility about your backend system. So they don't have any connectivity. So
46:00
management of security and having lot of powerful access security we can put in
46:05
place here. Okay. So these are backend systems and one of the big reason why I want to do this setup by chance okay by
46:13
chance in the future if you want to scale so scaling would be so much easy. So if
46:21
you have this kind of proactive plan okay in the future you want to add more computers with to handle more traffic
46:30
okay you can launch one more instance very quickly and as after launch you can
46:35
add a new instance to this load balancer adding the new instance load balancer is
46:40
mostly known as register so we can register this new instance very quickly let's say my this is the A and this is
46:47
the B very quickly we can add Okay, let's say my back end computer A
46:52
or what IP would be to my load balancers. Okay, or maybe if this goes
46:57
down to some region. Okay, so client itself connect to load balancers and
47:04
load balancer guys we have some kind of rules we can create. I'll show you how if something is not available. So we can
47:09
send the client to some other pages that can be managed in load balancers and say
47:15
just wait for some minute we are coming live or my your resources is not available but can you can connect to my
47:21
customer support. So this can also be possible if something fail we can add some extra rules here in the load
47:28
balancers to send to somewhere else that can be handled. Plus load balancer can also create a logs. So in the future at
47:34
least we can see that point in time how much guys is goes down means how much guys is not able to connect from this
47:40
particular client. So some more thing we can do. So having this proper planning even though you have more one computer
47:47
running always run behind the load balancers.
47:52
This a good practice to have and one of the reason is we can have scale it very
47:57
quickly because I don't want to change my IP address uh every time with the client. I just want to keep it once.
48:04
Okay, this is one thing. Now in in this plan, you can launch this instance in 1
48:10
A data center or you can launch this instance 1 B a. So that is the you know
48:15
disaster recovery plan automator. So if this instance fail okay you your
48:22
load B will automatically connect to this instance behind this. It more look like a failover. So if something fail is
48:28
not exactly meaning of failover rather rather than I can use the word called high aability. So there's a concept of
48:34
high aility. So my instances or my application is always available and this
48:40
is called high aability and high ability guys you can achieve if you have the load balancer in the front of it.
48:48
Okay. Then only you can achieve uh this capability. Okay. Otherwise lots more plants we can
48:55
do. Okay. But at least let me start this practical first. One last term I want to
49:00
tell you here is tell you here is is uh that if one
49:06
computer want to connect to other computers okay we always connect with the IP address
49:13
but after IP address okay in this computer we are running multiple program
49:18
which program you want to connect so every program has a port number so with the IP address you have to give the port number also otherwise thing won't work
49:24
that's what I told in my last classes also okay same thing if my client is IP
49:29
100 we'll never connect to the IP right to get access data we always connect the
49:35
port number so the front end you have to give a port number also this port number
49:40
is mostly known as front end port number okay now because in this IP00 there's no
49:46
application running technically internally right so you can give any port number whatever feel like maybe 80
49:55
81 whatever you feel like or maybe 80 also Okay. But in the back end this web
50:01
application mostly they run on port number 80 or let's say this IP address is IP1.
50:10
Okay. So this back end URL is I know IP1 at port number 18 my
50:16
application is running. Why is important? Because my load balancer will come to this particular URL.
50:23
According to load balancer this URL where actually application is running this let's go back end system this URL
50:29
is known as end point. So they will come to this final end point to get this detail. Either you can use the end IP or
50:36
URL or the endpoint is known as okay this is what you have and in this case
50:43
okay this IP one is known as end point or backend IP address or IP port 80 is
50:48
the back end port number. IP 100 is a front end IP or IP 80 or port number 880 or 80 whatever you will give it your
50:55
choice. Okay. Whatever you give that will be written by the client. So client will write IP 100 and port number 8080
51:02
in the URL to connect. Okay. So this is the client for the client that is known
51:08
as front end port. Okay. So this is the idea. Now
51:13
interesting thing here is your instances of VC2 is managed by us. There's the user managed, customer managed. Okay.
51:21
Load balancers is managed by AWS. So AWS has their own service. Okay. A name of
51:29
service called elastic load balancers. The service name and this service purely
51:36
managed by AWS. So AWS is giving a taking the 100% ownership and the
51:42
responsibility of this load balancers. So where were they running this load balancer? How are the conflict? They
51:49
they giving you a guarantee and they're saying if more traffic come up we increase the benefit of this behind the
51:55
scene for you. This instance will always up. If one of the data center goes down they still running in the other data
52:01
center. Right? So they give you lots of taking lot of responsibility. You don't have to handle anything. You just have
52:07
to use it configure it the way you want to use. Otherwise the entire responsibility is taken care by AWS. So
52:14
this is the AWS managed services that is a good thing. Okay. The only bad thing is because it's been completely
52:22
configured and created by AWS. So as a technical guys we don't have to learn much or we can't see anything what is
52:28
happening behind the scene. We can only use it as a cloud services. There's a bad thing for the technological learner.
52:36
But yeah obviously for real world perspective that's what the real world want. they have the service they want
52:42
blackly use it then they should know what is happening behind the scene but anybody here who is really technical
52:50
enthusiast who want to learn how we can create this kind of load balancer by ourself in our own Linux servers so I
52:57
think I already announced guys and we are launching soon one red official training is called RS358
53:05
okay is again one of part of RSCA track also okay in this training we have a very
53:10
detailed uh topic where we are going to learn how to create our own proxy server
53:17
or load balancer, how to register, how to do the settings, everything we going deep and we are going to create and
53:24
configure ourself. So I'm just giving extra knowledge if you want to learn then you can be part
53:29
of this program right is one of the topic otherwise like this we have 100 more topic like this kind of you know
53:37
kind of things but this is one of the topics we have there in this training of um
53:44
Red Hat RS358 we are going to do and configure everything from oursel in our own Linux
53:50
operating system. So you can use your way you can you can use your way and you can you
53:57
know this is the one of the topic we have uh what is the hroxies
54:03
this is one of the topic through which we can set up this right but yeah based
54:09
on as cloud we don't need to do they have given you precreated so we can directly use it
54:15
so I think this is guys some vocabulary I want to give you let's start configuring then we can do some more
54:22
thing here. So based on this plan what I explained to you what I'm going to do
54:28
right now I'm going to launch two instances
54:33
okay in our 1 A data center and 1 B data center
54:40
okay so let me write a proper plan so I'm going to launch one instance EC2
54:48
okay with in 1 A data center and one more EC2
54:54
instance in one B data center and according to plan because my client is
55:01
not actually going to hit the system so I'm going to launch this instances in a private subsets this also in the private
55:10
and this is also in the private or I can say I don't going to give a public IP to those guys
55:16
okay so you can think in this way also so both will run in the private submit
55:24
for extra security. This is one thing I'm going to do. So, let me start from here.
55:30
Okay. And for this I can you can use your your VPC whatever you created or you can use the VPC already we had. But
55:37
I'm going to use RV VPC because the default VPC what we had already they don't have any private subnet. They all
55:43
every subnet is public there. So I'm going to use RV VPC what we created in the last class. Okay. This is I think my
55:51
LWV VPC. In this VPC guys, we had created two subnets.
55:56
Okay, this is the subnet B and this is subnet A private. Both the subnet is
56:03
private. Okay, how I know? Let's check one by one. So this subnet if you see
56:09
the route table and this route tableable the subnet number A private having a
56:14
route table and this route tableable has no internal connectivity. So this is different rule is I think for VPC
56:21
endpoint I created my last class but technically okay this has no even though let me edit
56:26
this so there no confusing so have to edit for to go that place let
56:33
let me let don't go there I don't want to tell there's a time I want to just want to remove this last line because
56:39
the last line doesn't impact anything but technically there's no route to internet
56:44
okay and there's no also net gateway also connected or intergate nothing is
56:50
there a pure private okay similarly
56:55
similarly if you go to B private routing table it is guys again there's no uh
57:03
default route to gateway or routers so they're pure
57:09
pure private submit okay in RB so uh let's use this
57:17
let's use this even though you don't have to do the P in this way you can use
57:23
if you don't have the setup ready simple you can create an instance and put behind the load balancer to test if you
57:29
want but I'm I'm trying to make this battle more sophisticated more realistic that's what I'm doing here so
57:37
I'm going to launch this instance okay and I'm going to use my AMI because
57:43
this has already web server configured so it will save our Or in your case you can launch your web
57:49
server or set up by yourself. And this I'm launching behind our VPC in a
57:55
private A world there's running in one A data center. Okay, private A. There's no
58:02
public IP we have. We don't require tag. This is my web
58:09
private in open A. Okay. Security group guys intentionally I'm
58:16
giving right now all traffic. Okay.
58:22
Why all traffic? I'll show you in the I will do some changes in some time. All traffic. And I'm giving the security
58:28
group a name all not all web OS private security
58:36
group right that's what I'm giving right now so this group this will be a
58:42
security group created launch and attaching some private key maybe I might have to do some login with
58:48
SSS so it will launch let me launch one more very quickly I'm launching one more and
58:56
uh all Right now I'm doing it manually but those who know automation like Terraform they can create automation
59:01
script for this that will do very quickly but I'm launching one more in a
59:06
same VPC but in a 1B data center a subnet that is running in 1B different
59:12
data center they're launching no public IP and let me give this web OS
59:19
private one okay security group guys I have already
59:25
created in fast. So I'm going to use the same one if they have
59:33
so web OS one same I'm using and all traffic allowed
59:38
review and launch. So two instance launch according to our plan
59:45
okay one is running in 1 B 1 A one is running in 1 B both is p private IP
59:51
address so obviously from outside world we won't able to connect but if you want to test this if working
59:57
fine or not okay fine or not so only way is with help of
1:00:05
bassin host we can use the bin to check the connectivity let me do very quickly we have one bassin host already
1:00:12
Okay. So what I'm doing I'm using and connect and
1:00:19
connected to my bassin host bin is they have a public connectivity from this and this guy will have a private
1:00:26
connectivity. So from this host I can check the connectivity of these
1:00:33
instances. This instant running guys already with with uh web server. I use the AMI.
1:00:43
So, welcome to Linux is working fine. And let me check this also.
1:00:51
Outside we can't connect. We don't have we don't have public IP even though the public IP. If you give the public IP it
1:00:57
will won't connect because we don't have any intern gateway uh attached to this subnet. So, it is working fine.
1:01:04
due to some reason guys. Okay, because this is a different computer, this is a different computer. I will put behind
1:01:10
the load balancer and to check load balancer is balancing the load. First time my client will connect to this
1:01:16
system. Second time my client will come to this system to check they will do the load balancing. Okay, I'm changing the
1:01:22
data of this. Okay, if because both the guys showing you the same data how you can check the
1:01:28
locality in the real world obviously you will have to give the same data
1:01:34
but uh right now for testing I'm changing the data here and for changing
1:01:40
uh the data I'm using SSH with my key I already copied here my last classes if we have here let me log
1:01:48
to my EC2 user for this we have a key here and SSH IP
1:01:54
IP my key okay my username is same
1:02:01
I'm using this IP address let me copy from here
1:02:10
and yes I'm changing this
1:02:19
data on this file the data is this one so I'm changing this data
1:02:24
Look at this instance right now is running in 1B. So I'm changing as a 1B. So eco.
1:02:33
Okay. I'm changing I am from 1B. Okay. And updating in this file.
1:02:41
It won't work because we are logging normal user. We can use sudo. Okay. And sudo also don't work. I think
1:02:47
I give you the way because sudo will run this as a pseudo command but this not run as a pseudo command.
1:02:53
But this file we need a permission. So there's one simple basic L setup we can do. This command we can run. So any this
1:03:01
kind of symbol come up and we want to apply the sudo. This is the way we can do it. So P Linux commands opens up work
1:03:08
fine. And this file has been updated. Sorry it's not updated. Sorry I hadn't
1:03:16
wanted single quote here. Why? There's no requirement for this.
1:03:24
Sorry. Spion denied. One minute denied.
1:03:31
So I think single code double code inside double code doesn't work mostly most of the languages. This might be the
1:03:37
reason yeah double quot double code doesn't work. So I put single code in this. So update it. So this system
1:03:46
has one B and other system will tell you welcome to the next. So let me log out from here
1:03:52
again from a base computer. I'm doing the curl again. This system is giving a
1:03:59
different message and this other system is giving a different message to us. The
1:04:06
computer is is uh what this one
1:04:11
I mean change the content. So I can see the load balancing happening fine or not. So if load balancing happening
1:04:17
fine. So first when I first connect they will see this message other connect they will see this message. So it means load
1:04:24
balancing is happening fine. Okay. So now we have this system running with the different content mostly in the
1:04:30
real world obviously we are the same website we should have. Now it's time to have our load balancers. Okay. So we are
1:04:38
going to put the load balancer here. This is known as elastic load balancers.
1:04:44
So how we configure this? So based on this concept we explained to you setting up the elastic load bas.
1:04:52
Okay. So one. So how we can do this? So ELB is a
1:05:00
subservice of EC2. So in this EC2 page only if you see the left side if you go
1:05:05
down there we have a concept called load balancers. Okay. and the target groups.
1:05:12
Okay, right now if you see the target groups, nothing is there.
1:05:18
Okay, my target group and and I'm going to explain you and if you talk about load balancers,
1:05:25
nothing is there. Okay, now if you want to create a load balancer know in the
1:05:31
Mumbai region, just click here. And now guys, there's three different kind of load balancers we have. Okay, one is
1:05:39
ALB, NLB and G LB or GWLB I can say.
1:05:45
So what are the use case of this? Uh wait for just tomorrow class. I will
1:05:51
first explain you more use cases and develop a use cases of L benser. We will pick one. But the use case that I
1:05:58
explain you right now typical use case of load balancer or device proxy. Right?
1:06:03
This use case can be solved with the fourth one or against the older one.
1:06:08
This is called classical load balancer CLB. CLB is a older one load balancer and
1:06:15
then the soon uh sorry and soon they are going to expiring it in August 15 this
1:06:21
year only this load balancer but till before this we can use this one to for
1:06:26
doing something. Okay. So right now our practical what I'm going to show you can be shown by this load balancer as a
1:06:32
previous one. But after having this practical completed I will explain you some more use cases
1:06:38
that can't be solved by this then we have to move these guys but the core concept I explain you is same in all
1:06:45
okay so let me start with the clustic load balancer okay so I am going to
1:06:51
create a new load balancers click create
1:06:56
okay and here guys they're asking you the load balancer name let's say my web load balancers
1:07:03
And this load balancer you want to run in one so in which VPC. So idea very
1:07:08
simple. Okay. If your load balancer whatever IP
1:07:14
would be right want to connect to this IP1 if they're not running in the same
1:07:19
VPC how they connect because this IP1 is a private IP. Okay. And private IP can be only
1:07:25
connected with the any other computer in the same VPC. So there's one of the reason your robot would run inside your
1:07:33
VPC. So I'm just using RVPC name. This is a
1:07:38
VPC. Okay. So this is what uh we have set
1:07:43
here. Next point is do you want to create your load balancer internal? So I will take
1:07:49
guys tell you some more use case why you want to create your load balancer internal. Internal means you don't want
1:07:55
to give public IP to the load balancers. And there's a lot of interesting use case for this. But right now in our
1:08:00
case, I want to give my load load balance a public IP. So my client can connect to this public IP. Okay, that is
1:08:07
a reason I'm not selecting this. But I will tell you in my upcoming maybe tomorrow class what is use of this.
1:08:14
Okay. Now here they're talking about load balancer protocol means when the
1:08:20
client come to the load balancer which protocol they going to use mostly HTTP
1:08:25
and which port number they going to connect. So which protocol they want to use? HTTP also support but I let me use
1:08:33
HTTP right now. Which port number they want to connect? Let's say 88
1:08:38
in according to our example. Okay. And when this load balancer connect to your
1:08:43
backend systems instances which port number they will connect and which
1:08:48
protocol they use. Okay. So again they use S3 protocol and
1:08:54
the port number of the instability. This port number you can use anything but whatever you use that will you have
1:09:00
to given to client. But this port number you can't use anything. Okay. Based upon your application. For example, right now
1:09:06
my application is running on port 80. You can't give a TD here. It won't work.
1:09:14
So whatever application work on which port number that what you have to give here instance port or backend port.
1:09:20
Okay. Again this concept is known as it is known as when it means my client will
1:09:26
connect on this load balancer and load balancer will will listen to client at this IP and port number or this
1:09:32
protocol. This is not a listeners. So it is set the listener
1:09:37
on the load balancer. So listener configuration if we have
1:09:43
and if you have more application you have maybe sometime it's possible one system have multiple
1:09:49
u application running or port running or features running so more and more listener we can connect with different
1:09:56
different ports on okay that's what we can add more.
1:10:01
Now the setup is done. Now we have to select the subnets because right now I would like to
1:10:08
connect my load balancer to different different instances. Now you to pick your instances running in 1 A or 1B or
1:10:14
both or one. So in this VPC you have to select your
1:10:20
you have to select your subnets. Okay. Okay. And even though they also suggest to have the provide high
1:10:28
availability for your load balancers different a you select means two at
1:10:34
least subnet you have to select then only you will have set up actually
1:10:39
actual setup of high availability and these are the different subnets we
1:10:45
have. So which subnet want to select? We know our instance is running in 1 A and
1:10:51
1 B private. So this is the private. Oh, this is the private I am going to
1:10:56
select. So I'm going to add this. Okay. And this also I'm going to add.
1:11:02
Okay. So in this VPC this two submit I am going to add.
1:11:07
Okay. So it means it means your internet facing ELB. Why is internet facing?
1:11:15
Because right now my ELB this is called elastic load balancer. The ELB is one
1:11:20
service name. Inside ELB there's four different uh load load balancer we have classic or other other guys we using CLB
1:11:28
here. So let me write here ELB is a
1:11:33
is a name of your service and inside this there's four different types today
1:11:39
we are discussing CB classic older one okay that's what they're talking about
1:11:44
and here they say is internet facing internet because we are attaching not selecting as a internal means public
1:11:51
facing anybody it means they will give a public IP to business okay and they also guys give warning
1:11:58
there's No interative address to submit. we just select it.
1:12:03
Okay, it means they're talking about okay, you are using internetf facing
1:12:09
ELB. Okay, but there's no internet gateway attached to the subnet.
1:12:16
It means what a challenge you'll face. I'll show you in a minute what challenge you face. Okay, for this
1:12:24
even though Okay, let me go for next. I will explain what challenge you face.
1:12:30
Okay. Next they ask you security group. Now
1:12:35
here this is security group for your for your load balancers means load balancer also have guys
1:12:42
security group. So this is the client you have from the internet and before the load balancer you have a
1:12:49
one firewall security group. Okay security group. So obviously guys
1:12:56
because of our load balancer what IP would be my my load balancer working on the front end port 80. So I want any
1:13:03
client from anywhere can access this port. Okay. So this is security group we have
1:13:09
to add. So I'm going to create a new security group. This is a load balancer
1:13:15
security group for port number. Okay. And I say this because this is a
1:13:22
kind of TC protocol. I would have to allow this port number from anywhere in the world.
1:13:28
So this is a security group for the ELB load balancers.
1:13:34
Okay. Click next. This is giving a warning. You are running load balancer publicly.
1:13:41
You have to use some HTTPS. That's what we'll discuss in the future classes. Okay. For extra security means
1:13:47
encryption. But right now I'm not doing this. So let me go for next. Next is health checking.
1:13:54
Okay, health checking means what I explained you already.
1:13:59
Okay, whenever you lo when you launch your instances behind
1:14:05
the scene, your instant will keep on checking the health. Okay, so it is like this. Let's say A is
1:14:11
your load balancer and B is your backend instances.
1:14:17
So load balancer is keep on checking your health.
1:14:22
Okay. So that any client come up load balancer will send that request or
1:14:28
process request to you only if your health is okay means you have a connectivity. Now for checking the
1:14:34
connectivity load balances keep on pinging you as ping is a protocol you guys might
1:14:40
know if you do normal ping as a ping command. Sorry if you do a normal ping as a ping
1:14:47
command. Okay, this spring come work on protocol called ICMP.
1:14:53
ICM and most of the case guys in the server ICMP is blocked.
1:14:59
Okay, so if you try to ping B the server side is running but it look like it's blocked. So that easy reason the good
1:15:05
way to ping is okay rather than ping on the ISM protocol ping directly on the server because server is working on the
1:15:13
protocol HTTP okay and server has a web server running on port and server has a web page most
1:15:21
of the web page is index HTML and because this is your server you know which page number page name you have
1:15:27
so I can ask my a try to do this kind of server this protocol this port number
1:15:33
and this page if you can access this page it mean they're pingable and this is called ST ping or TC ping so
1:15:40
this what we normally do so pinging by HTTP or port number 80 and accessing this
1:15:47
page or whatever page you have in the server you can access this or this page if it's
1:15:52
bigger you can make this one smaller page just for hand checking the only
1:15:58
motor of this page is okay if this page is accessible or downloadable. It means your server is
1:16:05
running and there's no issue of connectivity or downtime or any kind of load or any kind of uh you know page or
1:16:14
any kind of security issues. Okay. So whatever page you have in my case by I have this page with us. Let me
1:16:22
refresh this page again. In our case this page is there
1:16:29
what IP would be? So in our case uh you guys know what is
1:16:36
IP let me open a new page because you might require
1:16:43
EC2. So in our case
1:16:49
this is the page by default we have
1:17:02
so check this this IP address by default our page name is
1:17:09
if if you don't write the page by default page name is always this page we get so you can ping this IP address So
1:17:15
this bas on the slash both are same. You can use slash also there. Both the things are right. So you can write this
1:17:22
or you can write slash. Both things are right. Now let me write this one to make more clear what we have.
1:17:30
Okay. Now interval between pings.
1:17:37
I told you guys ping is a continuous process. Maybe after some time they're down. So I a will keep on pinging to b.
1:17:45
How frequent it depend right so how
1:17:50
let's say if you're pinging right now is ping but after two second is down
1:17:55
but if you if your interval of pinging is 30 second mean after 28 millisecond you come to know that up mean load
1:18:02
balancer have no clarity till 28 second they're down and still they're sending request to B again and again to client
1:18:07
and B is not responding so client is not facing getting the proper reply what I
1:18:12
mean by this Okay, if let's say A is your load balancer and B is your
1:18:18
instance behind the scene, this is load balancer. And if your interval of pinging is 30
1:18:26
seconds, okay, it means A ping to B
1:18:31
let's say right now, right now let's say 00 second and B say I am okay, I'm live.
1:18:39
Okay, after 30 second they will again ping. This is called interval here this
1:18:45
interval. Okay. But there's a possibility maybe after 2 or 3 second let's after 2 second
1:18:51
2 second after your instance B goes down
1:18:57
means till 2 second to 30 second around 28th second your lowers have no idea goes
1:19:04
down because they start they will do next spring after 30 second. It means till 20 in from 2 to 30 second your B is
1:19:13
down but A feel they live. So any client come to A they keep on sending request to B and B is not replying. So it's a is
1:19:21
not a good um you know um
1:19:26
service or you experience for the client they will see this disconnected next
1:19:32
time because client disconnected client normally resend the request. Next time A might send to other guys there's a B for
1:19:38
nature because they do load load balancing but initial they won't correct that's a different point
1:19:45
okay so in this case you can decrease the time maybe let's say 5 second again lesser time is not good because if
1:19:52
you give you lesser time there's a 5 seconds 00 after zero 5 second 10 second 15 seconds so they keep on pinging so it
1:19:59
will unwanted west impacting the extra load on the back end server
1:20:05
so depend You have to choose this parameter depend upon your requirement. If you think your application is very
1:20:12
critical okay maybe 2 second down time is not you you think is right then you can decrease
1:20:19
the interval. Okay. But you think your application is very reliable you can increase the time but you got to save
1:20:24
the unwanted head from the load balances for checking the load or also checking
1:20:30
the head health. Okay, that's one thing. But one more
1:20:35
small thing here is what load balancers do. Let's say my time interval is five.
1:20:40
So 0 0 till 05 1 5 second they hit. Then 10 second the hit. Then 15 second they
1:20:46
check the health. Okay. We go right 5 second here. Okay. But let's say at this point in
1:20:53
time till here let's say server is okay. But at this point in time server is down. Means a hit to b is down.
1:21:02
Okay. But in the first B is down for and healthy. They don't declare B as
1:21:09
unhealthy. Okay. They still
1:21:14
keep B with them. That's called registry. They keep register B with them. And
1:21:20
there's a possibility thing there might be some network errors. There might be some system rebooting that point in time
1:21:28
that they might be down. So again they try after five 5 second. Okay. Again if they're down again try
1:21:35
after 5 second. Okay. After two or three tries this called unhealthy try two by default
1:21:42
here. After two try this first try they did their second try they did. Okay
1:21:48
after this they will declare B is down. Then they they make the B as out of the service. Then they drestri this
1:21:54
something like this. Now future in the future they won't send the request we can do it again connect there that's
1:22:01
different point but now onwards they won't start sending the ping to the
1:22:07
they declare as a this out of service so before you make it unhealthy how much
1:22:13
how many requests you send that's what we can check here depend upon your requirement if you think in the company
1:22:20
mostly you do a lot of patches in the server you have to restart your backend servers restarting might take maybe two
1:22:26
minutes sometime. Okay. And you don't want that point in time server
1:22:33
not as a out of service then you can increase the time and and the intervals
1:22:38
also and same thing with healthy okay the first time
1:22:44
when any new computer connect to the to the uh load balancers
1:22:51
some ping 0 second again 5 second they ping again 5 second they ping again 5 second they ping before they restore
1:22:58
this Okay, before they assure this guy and start sending the client u traffic they
1:23:07
check multiple time the hell and after set multiple time the hell then they mark this guy as a healthy and then only
1:23:14
they send the traffic that is called healthy time. So 10 means 10 means total
1:23:21
10 times. So every 5 second they send the request to total 10 requests they
1:23:26
send after 50 second they mark this guy as a healthy let me
1:23:32
change to four right now I want to make make this instance become very healthy
1:23:38
very quickly. Okay. And response timeout means if your
1:23:44
uh if your instance is sending uh request to B,
1:23:50
okay, as a health check on page score index.html, okay, B will reply. B might reply in 1
1:23:58
second because page may heavy page is busy. Page have some thing that will load from the database. I we don't know.
1:24:05
Okay. So if B is responding and processing this page and replying in 1
1:24:11
second 2 seconds okay but this page is taking more than 5 sec this time out
1:24:17
okay this time out so maximum time the system can wait is 5 seconds we can increase or decrease also
1:24:24
okay response time so I think guys every keyword I explained logically because I've seen
1:24:30
lot of places uh having the right knowledge of this keyword is not proper
1:24:36
or it look like very confusing but I believe by having this example you have a clarity about every particular
1:24:43
component and it is not a standard not standard means to fix any number it's
1:24:49
all depend upon what kind of application you're running behind the scene so multiple example use case I will explain
1:24:54
to you so this parameter you can change according to your requirement sorry
1:25:01
then add the instances now Um
1:25:07
u now guys in our uh this particular what sorry
1:25:13
this particular Mumbai all the instance that we running here it would be visible
1:25:18
okay so these are the different instances we are running right now they're showing you all the
1:25:26
uh instances even though they're showing you public also public
1:25:33
okay now what is important What I'm trying to tell you here is okay. So one more interesting point guys I want to
1:25:39
tell you is there sometimes confusing you are running
1:25:47
your instances one A and one B in parameter
1:25:52
load balancer is also like a one instance running behind the scene managed by AWS managed but you want your
1:25:58
load balancer has a public IP and public IP guys of the load balancer
1:26:05
is only available able. If your load balancer is running in the public subnet, your public subnet is one who
1:26:12
can who can give the uh public accessibility your
1:26:18
public instance. So public subnet public submit is the one who normally
1:26:24
give public IP or nor public IP actually means public submit has a internet gateway connectivity.
1:26:32
It means if you don't put your load balance in public subnet your load also won't have a public internet
1:26:38
connectivity because they don't we have the inter only public submit and if you have inter connectivity or inter gateway
1:26:46
don't then only guys client can come you can write in this way then only client
1:26:51
can come to internet gateway through which they can go inside your role and through the role they will go to your
1:26:58
respective instances. Okay. So point is if you think if you
1:27:04
want a load balancer to be kind of outside world if this is the case then you have to put your load balancer in
1:27:10
the public sublet and that was the guy guys warning coming up. Okay behind the
1:27:17
scene right after load balances load balancer configured
1:27:22
you want to put which instances that is a different point these instances may be
1:27:28
coming public or private doesn't matter. So they will list you all the public and private the public in the port give you
1:27:33
private they give you in the Mumbai region you can select anybody
1:27:39
okay but if you don't put your load balancer in public thing won't work that
1:27:46
was the guys warning that's what the screen I want to show you here but that was a warning guys coming initially so let me go to my initial page
1:27:54
okay this is the warning coming here Okay. And this page guys is the
1:28:02
page for load balancer. Okay. Right. Load balancer is also a kind of
1:28:08
instance. Okay. And if your use case was this one, let me show you one one more time. Use
1:28:14
case. If your use case was if 1 A is a data center
1:28:20
and 1 B is a data center. Okay. And if you feel this data center
1:28:27
might goes down then client
1:28:32
from the internet can connect this. This is called disaster recovery means you want high aability. Actually
1:28:40
in this kind of use case your plan will be something like this in your load
1:28:46
balances like instances only behind the scene. So you what you have to plan you
1:28:51
have to plan in this way even though uh let me
1:28:56
give a little bit better plan. Okay. So guys this is what again this diagram
1:29:02
will become from a VPC class only. This is what we have created in the VPC and that is the reason why I created this
1:29:07
diagram in VPC classes. Okay. So how you have to do it? Okay. It
1:29:13
will be something like this. You have one subnet.
1:29:19
You have one subnet um running here. One more subnet we
1:29:25
have. One more subnet we have. And one more subnet we have.
1:29:32
Okay. And let's say this subnet is running in 1 A center running 1 A. This
1:29:39
is running 1 B. This is running 1 B. But this subnet is a public. This a
1:29:45
private this update is public. and this private.
1:29:51
Okay, in our case right now my instances is running here AC2 in private and one
1:29:59
more running in private but one is running 1 A one is running 1
1:30:04
B means 1 A goes down 1 B instance is still running
1:30:10
but load balancer also you have to plan in this way because you want load balancer to be public accessible so you
1:30:16
to put your load balancer in public subnet And actually you have to create two load
1:30:23
balancers because a plan is disaster recovery or high availability.
1:30:30
Okay. In this case, okay, in this case because load balancer is public submit,
1:30:35
it means we have a internet gateway that is already connected to your public and
1:30:41
through which your client can come in.
1:30:46
Okay, client can come in. Okay. So client either connect to this
1:30:51
guy, either connect to this guy. It means we have one more load balancer
1:30:56
on the top of this. And this one more load balancer guys is been created by AWS for you. You don't have to worry
1:31:02
about. And this load balancer guys they created with the help of DNS. So DNS also one
1:31:07
service that has can also be used as load balancer also. How? So when I talk
1:31:13
the topic called route 53 in upcoming classes I'll explain you there how
1:31:18
okay so so initially what happen your client we will give a IP address instead of IP
1:31:25
address we give a domain name IDS so let's say my domain name will be ren.com
1:31:31
or www.com so when the client hit to this name this
1:31:38
name always go to DNS Okay. And DNS behind the scene give the
1:31:43
IP address. And in this case, DNS will give the IP address either of this load balancer or this load balancer. Let's
1:31:50
say this B IP will be 100 and 200.
1:31:55
Okay. So client will have the IP address of let's say 100. So client will connect
1:32:01
to IP 100. Next time next client come up. Okay.
1:32:07
Next client come up then my they always go to DS. Why? Because we are using name, name will always first convert
1:32:13
into IP by DNS only. More about DNS guys, we'll see in upcoming classes. And DNS will give the
1:32:20
IP address. And this time DNS will give IP 200 because DNS can be useful or it
1:32:26
can be used as a load balance only. Okay. So this time my client will
1:32:32
connect to IP 200. But same time guys DNS can also work as
1:32:37
a fail or also fail or means DNS capability.
1:32:45
So any client come to DNS and say this is thew
1:32:51
give the IP before they give the IP they check they check the health of your load
1:32:56
bes okay and maybe at this point in time entire 1A data center goes down. So this
1:33:03
entire setup goes down. Your load base also goes down. A instance also goes
1:33:08
down because they're running in the A1A. In this case your DNS
1:33:14
okay DNS come to know your 1A goes down because
1:33:20
means your load goes down I 100. In this case when the client come up they will only give the IP address of 200. So they
1:33:28
will give the IP address of 200 and they connect to 200 and load balancer will connect two remaining internal back end
1:33:34
systems whatever they connected okay they they connect this technically
1:33:40
every load balancer connect all the instances this load balancer connected to this also and this also both the guys
1:33:48
are connected okay but this is the remaining part of load balancer now load balancer know
1:33:53
this instance goes down because they check the health so they want to connect to this
1:33:59
Okay guys, this is the typical setup everywhere. If you go to google.com, facebook.com, DNS is always your first
1:34:06
load balancer. Okay, so when you type google.com, every time you will get the
1:34:11
different different IP address. See even though see here if I go
1:34:17
my DNS will give a this IP address. Next time it might give different. Okay, in
1:34:23
this case they're giving IP6 both the sides, both the cases, right? Mostly you
1:34:28
will see in most of the cases they give a different IP address. Even though if you ping you might get different even
1:34:34
though IP6 is coming but they give you different different IP address all the
1:34:40
times. Okay. And most of them I can see. So point here is this is the setup we have.
1:34:46
But why DNS? Okay. I have one more detail discussion in upcoming class or route 53. But this
1:34:53
is the setup we have. So finally the setup would be the client
1:34:58
for internet is always connect to DNS. And guys if you have any doubt in this
1:35:04
case what happen if the DNS goes down the DNS never goes down. Whenever DNS
1:35:09
goes down it means your entire internet of the world goes down. So DNS is a like
1:35:15
internet it will be splitted everywhere in the world. So DNS never goes down. You can think this. Okay. And behind the
1:35:22
DNS we have two load balancers running.
1:35:28
Load B number A or B. Okay. And behind the load balancer we
1:35:33
are running multiple instances. Instance one, instance two, instance three,
1:35:39
something like this. So this load balancer connect to this one also. This one also this one also. And this load
1:35:45
balancer connect to to this also, this also and this also.
1:35:52
Okay. So in this case if my this instance goes down
1:36:01
so my client can come maybe to this load balancer this will send to this guy.
1:36:08
Okay. But BB by chance if your roer goes down so client with hyperinance will go
1:36:15
to this road benser and this road benser connect to this instance or this instance.
1:36:21
So everywhere we have the high whatever the way you architect. So this is one of
1:36:26
the architect design right of the load benzor right and that is reason it is
1:36:32
good practice to have a a high aability on the road benser because load bener launch per ages
1:36:39
okay and if your plan is if ag goes down I don't want my service goes down then
1:36:46
in this case you have to uh launch your uh load balancer in multiple ages
1:36:55
if you want to have uh high heavy abilities for this. Okay. But your load
1:37:02
balancer to be launched in public
1:37:08
uh public uh subnet if you want your load balancer will have a public
1:37:13
connectivity. Okay, that easy reason guys I'm changing here.
1:37:19
This is the page for load balancer the first page and here I'm selecting
1:37:24
and what sub will submit my my load balancer to be deployed. So I'm putting in the public only public and public.
1:37:33
Okay guys this is very comp otherwise ro confused with this line and the last page of this configuration. So this is
1:37:40
what I explained to you the use and now in this case
1:37:46
now there's no warning we have because I want my load balancer to be
1:37:52
public this line is not selected public so for this you have to put the load
1:37:57
balancer in the public submit that has entered connected plus I want a
1:38:03
high a setup one of the a goes down second a will
1:38:08
will have the robots running. So that is when I select two
1:38:13
uh subnets. So in both the subnet my load balancer will run behind the scene.
1:38:19
Okay. See the same concept. This is a port number for the load balancer. This is a
1:38:27
different warning because right now we use HTTP not HTTPS. H check is same.
1:38:33
Okay. Now two instance I want to run. One is my this instance and this instance one
1:38:40
is running in one year a one is running in one this has no relation with your load
1:38:45
balancer where they're running okay running my in my case if the load
1:38:51
balancer running here they can connect to this guy they can this guy
1:38:57
both all the guys running in VPC so they have prioritiz okay so this is what this is how we
1:39:03
register with your back instance. So these two instances will be
1:39:09
registered to our load balancers. Right? Now there's two concept called cross zone load balancing and connection
1:39:15
draining. We will discuss that at this point in my coming class. So again I'm just giving I'm going for
1:39:20
by default settings. But what are use of this cross zone and connection training? We'll discuss add tag. I don't want
1:39:29
setting you want to change you can change. I don't want to change. Okay.
1:39:35
So here for a small warning check out time must be less than the interval. Okay. So let me review and resolve this
1:39:42
is what they're talking about. They say this time should be less than that. Obviously logically
1:39:50
okay if you are if you're pinging every 5 seconds and some application will take
1:39:55
more than five 4 second. So they're same right? So it be little bit less lesser always logical.
1:40:02
Okay. So first thing you're doing right now is you then you're doing 5 second then the then the first response will be
1:40:09
come within 4 second otherwise they will be confusing right so that's what they're talking about so it will be less
1:40:15
always
1:40:21
that's so guys your load balancer has created successfully is a purely managed by what we have done we just ask them
1:40:28
and use them right now we see instances they're out of service. Why? Because we
1:40:36
have set the health time and say we will do after every 5 second check and we do
1:40:42
four checks for health checking and after four check mean around after 20 second if your your
1:40:50
instance is pingable there's no firewalls issue okay pingable and service running then
1:40:57
we'll make this service both the instances one and two running 1 A 1 B
1:41:02
status to be healthy. So let me refresh one more time now in service.
1:41:09
So they check these instances and they say they have connectivity. They try four try. Okay, because this is what we
1:41:16
have checked the set the health checks four try the check maybe 5 second around
1:41:21
and they make this guy as a instance in service. Okay. And right now what this
1:41:28
line says okay we are running with the load balancer one load balancer running
1:41:34
in 1 A that is connected to one instance count and second is 1 A that has
1:41:42
I can say it's not like this this is what in one A data center one instance running and one B data center one
1:41:49
instance it's not load by they are just talking about that we have one one
1:41:54
instance running in one one data center it's about instances. This is what we're talking about. you find instances
1:42:01
okay this page this is the listener if anybody want to connect they can comment
1:42:07
on this port they're talking about right and finally if you see the describe
1:42:13
okay because this is a interfacing load balancer and the way I explain to you
1:42:19
okay because you are using interfacing and because you're using two load
1:42:24
balancer because you have two different um public sub use for disaster recovery.
1:42:33
So this load balancer guys has been further load balanc by DNS and that is
1:42:38
the reason guys they don't give any public IP public IP you can't use for for load balances
1:42:45
okay in the DNS so DNS will do only load balancing with the public host name and
1:42:50
the domain name so client will have the host name of the domain name of your
1:42:57
load balancer that's what they give you here
1:43:03
your DNS you don't get any public ID you can get this public DS and
1:43:11
what status is in this VPC two is still running and two are up no is nothing is down is interface okay this with the
1:43:18
deals and some more settings we have security global okay now let's see
1:43:25
everything working fine or not so let me copy this DNS name.
1:43:30
Right now, if I hit my DNS name, it won't work. Why? Because the
1:43:36
port number of my load balancer what we planned
1:43:43
already is 880. So, let me show you where it is.
1:43:48
The port number we planned is 488. Okay. So,
1:43:55
so what we'll do it's not working obviously we connect to port automatically
1:44:01
and let's see output come right working fantastic and one thing guys if you see
1:44:08
this particular page okay so IML client from my system
1:44:17
uh hit to this IP address or to the port number. We have a front
1:44:24
end IP as a port number. But behind the scene guys, they hold my request, go
1:44:29
back, get the data and send to me. See here they are not redacting me. If they
1:44:36
redirected then I will connect to my final server to the server IP address.
1:44:41
I'm still there in this page and behind the scene they get the red and throw to me. So for client it look like coming
1:44:47
from load balancer but internet is coming from a different website. So that is the reason I'm using word reverse
1:44:54
proxy. Okay. And second thing is your instances
1:45:00
where I is running in the private world right even though no public IP address
1:45:06
even though I can get my data how I already show you the concept they we we
1:45:11
reach here and they will connect and get the return and this load balancer has public IP that the reason I can get the
1:45:18
return and because they also using uh reverse proxy
1:45:24
so so it doesn't matter they have public or private IP address. So we can get from private IP also.
1:45:30
Okay. And if I refresh this page last one when I refresh this page, let me refresh this page. You can see there
1:45:38
that means my load balance is also happening. Fine. Okay. So first time the connect here, second the connect here,
1:45:45
then the connect here, the connect here. So you are getting a proper load
1:45:50
balancer. Sometime when you refresh you won't see it. a change
1:45:56
if you don't change that changing because that is one of the reason is you normally browser create a caches
1:46:03
so that is not the issue from the load balancer sometime your local browser get a caches so they won't show you okay so
1:46:09
if you don't change they're not changing because that is the reason the caches right one last thing guys for today
1:46:16
today one thing I I haven't said properly here
1:46:23
is is your instances right now even though they're
1:46:30
running private this means nobody can outwork can connect that's a good thing but instances has running with a
1:46:38
security group okay and this security group guys is a
1:46:43
public accessible everybody can commit commit okay it means my instances
1:46:50
that is running right now Okay. Has a security group and security
1:46:56
group says, okay, anybody
1:47:02
can connect all traffic. Okay, it's not good rule. The good rule is
1:47:09
because instances right now is running with web server that is running on a port number 80
1:47:16
80 or ST protocol. So you have to only allow HTTP
1:47:26
or port but this part you know but the main point is we allow from where are load
1:47:33
balancers but do you know the load balancer IP
1:47:38
address because there's two IP address guys of load B public and you guys know public IP is not never belong to
1:47:44
instance it belong to inter gator but do you know the IP address or the
1:47:49
private private IP address to the load balancer your private facing IP of the load balancer do you know let me check
1:47:56
okay so in the load balancers page
1:48:01
okay if you see here do you know the private IP of load ber I don't so they
1:48:07
will post here there's no private IP they show you because it is running
1:48:12
behind the scene they should have but they are running behind the scene okay so in this is which IP allow
1:48:21
there's no good reason to allow all it's not good reason to allow all the network events by we know the network name
1:48:27
because load balancer is running in one network or subate we can allow all network but it's not good practice okay
1:48:33
there's a good security if you want only load balancer will connect so only allow
1:48:40
load balancer uh IP address okay this is one point and second point
1:48:47
by we don't know the IP as a rob second point. Okay, there's a possibility my
1:48:53
public IP will say same it won't change but a private IP might keep on changing.
1:48:59
Okay, but in this context there's one more interesting feature of security group. Okay, the feature is if A is a
1:49:07
computer, B is a computer and this is the security group of B
1:49:16
and let's say this is a security group of A. Okay, if you want A can come in B
1:49:26
to do something. Let's say access port 80 and you don't know the IP address of A
1:49:34
or private IP of A. You don't know and maybe private ID is keep on changing.
1:49:40
This may be one of the case keep on changing. Okay. In this case let's say this
1:49:47
dynamic IP address in this case how can you create the rule in security group.
1:49:53
So you want to create a rule that anyone who want to do HTTP or port 80 only from this instance can come but I don't know
1:49:59
IP address or IP address changing how can we do four is there is one more concept of security group guys and that
1:50:06
is the only concept we left in my initial classes so I told you guys you know I told you in my security classes
1:50:12
security group there's one concept left that is the concept I'm explaining you right now okay the way we can do is in
1:50:20
this case okay we can take the help of security groups and the one unique identity of security
1:50:27
of A is this security group A has their own personal security group it's fixed it's not going to change so what can we
1:50:35
say we'll tell my B that anybody from the source system the IP will change or
1:50:41
might we don't know IP address but they have the own security group let's say security group A
1:50:48
so we can create a rule anybody from belongs to security group A come to you
1:50:54
come to me B and try to access this allow this.
1:51:00
So what I'm trying to do here is my firewall also not firewall my load balancer is attached to this security
1:51:07
group this security group is called LB security group AD okay I don't know the IP is my load
1:51:14
balancer I don't know maybe I IP also might change the future let's say A is
1:51:20
my load balancer here okay so what I can do I can go to my
1:51:26
computers and say the source IP I don't know. So I want to use custom and custom
1:51:32
would be I would like to use the security groups names. Here there's a lot of name come up here. So instead of
1:51:39
IP address and the port IP range you can give a secure group name also. In this
1:51:44
case the group name is called LBS. LB SC this one. This one.
1:51:53
Okay. So any computer where the security group has been attached
1:51:59
in this case the security group has been attached to my load balancer. So load balancer is a source
1:52:05
if load balancer try to connect.
1:52:11
So you may not so little let's go over this. So
1:52:17
if any computer from the system belongs to this security group come
1:52:23
to access this port number v1 that is the meaning of this line. Okay. So this
1:52:31
is one very common thing in the secret group will do mostly the case where the
1:52:37
IP addresses keep on changing. Okay. So if source ips keep on changing
1:52:44
then we can create this kind of rule. I don't know why this warning is coming up. Let me do one more time. So this is
1:52:50
the LB security group we add. You may
1:52:55
not specify a reference group ID of existing
1:53:01
M4. Let me save it.
1:53:08
W it you may not reference group ID.
1:53:17
I don't know why this mess is coming. It should work.
1:53:22
Let me check this. So but this is the guys
1:53:27
idea. It should work. Why this warning come up? Let me edit this.
1:53:33
Okay. So what I'm doing all traffic instead of all let me use HTTP
1:53:39
[Music] this custom anywhere we don't require uh
1:53:45
LB security group I just try it I don't know maybe I've
1:53:52
missed some some VPC I don't think so right but it should work right right now
1:53:57
uh this console just keep in mind just check it or I will again try next class it will be very very late Okay. So at
1:54:05
least till now I allow all but this is guys one concept I want to
1:54:12
tell you by this is a good example but I don't know warning we can troubleshoot but we've been late right now so I just
1:54:19
skipping this point. Okay but this can be done to make this thing more powerful
1:54:25
in the terms of uh security. Okay. So that's all guys. Uh this is the
1:54:31
classic load balancer. Okay. We have now this has a lot of
1:54:39
limitations lot more lot of advanced settings we can do even there's some more concept of stickiness and some more
1:54:46
things we will discuss in my tomorrow class then I will move to some advanced load balancer for ALB and MLB other
1:54:52
topics right so that's all guys uh uh in today's class any query if you have till
1:54:58
now you guys can ask me okay any queries in this
1:55:21
a person that is not uh it is not like there's the pretty fixed number to
1:55:27
handle multiple requests is way from server to server. So every server has their own configurations. In the
1:55:33
configuration you can check which fork they're using uh and that will tell you
1:55:39
the connection limits. Even though if you are the part of my three factor training this is one web server topic we
1:55:44
have I show you there how to go and check how can we do that.
1:55:57
So um Susil can you ask me again what actually doubt you have proxy proxy I
1:56:04
will explain to you proxy is not the part of the discussion so a little bit different concept so I'm not going for
1:56:10
that particular partrum tomorrow or we will discuss NLB
1:56:16
okay NLB and LB we will discuss tomorrow
1:56:25
when the DC where the LB is placed goes down because of the do they fail to next
1:56:31
yes will happen automatically because on the top of load balances now we have one
1:56:37
more load about DNS so if the entire 1 A goes down where my
1:56:43
load balance is running automatically DNS will send a next request to load balancer B in my 1B data
1:56:51
center so it will happen automatically we don't have to do anything Okay.
1:57:11
So yes uh right now for load balancer here they using round round robin algorithms
1:57:18
of course. Okay, this particular load balancer what
1:57:23
are you seeing here they are using the algorithm called round robin not the random
1:57:29
that is reason when I refreshing the page you can see first request goes to 1 a e2 second go to 1 b ec2 why round
1:57:38
robin is the one who will send one by one okay it's not random
1:57:48
so that's all guys see you uh And next class tomorrow with some more detail about load balance inspector I guess you
1:57:53
put


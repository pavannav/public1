ript


17:04
Hey guys, uh welcome back and let's continue with the next part of EKS uh
17:09
training. So uh we will go more deep into uh the
17:15
EKS today and my plan is to
17:20
explain you the EKS internal architecture. Okay. Some of the part
17:26
guys we have already discussed about EKS as architecture but it is more respect
17:32
to EKCTL command. Okay. So we use EKCTL command.
17:40
Okay. To set up the EKS cluster. Okay. For example, if I run EKS ETL get
17:47
cluster. So this is a third party tool. Now it's been kind of official tool from
17:54
uh AWS. And through this if you want to do any changes in the cluster
18:00
or you want to configure or set up the cluster for EKS, this is a
18:06
tool we use, right? But this tool has uh normally create a
18:13
cluster in by using lot of resources of AWS.
18:19
Okay. What I mean by this? Okay. For example, right now I don't have as SS any cluster. This is some kind of uh
18:27
cluster I already have. Let me create one cluster. What I'm talking about I will explain in a minute and then you
18:32
also come to know what we are going to discuss today. Right? So I'm going to create a default cluster with a ES
18:39
command. Let's say my cluster is called cluster one. Okay. When I hit enter,
18:47
when I hit enter, let me get a different name. Cluster two.
18:54
Okay. When I hit enter, it creates a cluster, right?
19:00
But I and we does not uh you know ask
19:06
this tool what we looking for. By default, this tool
19:13
okay is creating a cluster of EKS okay in uh Mumbai because this is my
19:20
default setting in my local system in AWS configure file my region is Mumbai
19:26
but apart from this there's many more thing what they're doing over here that
19:31
we does not ask this tool to perform what they're doing okay one thing what
19:37
they're doing is they're launching node node and you guys know they launched two node behind the scene this coworker node
19:46
sorry that you know you can change it you can increase the number but my point
19:51
is here different what I'm trying to tell you here is right now this tool what I running right now is doing lots
19:59
of changes and set up lot of thing in AWS cloud in
20:04
your account okay so in my account in the Mumbai region
20:17
they're doing a lot of changes what I mean by this okay they're creating
20:23
instances in EC2 this is one change they are doing okay some instance they are
20:30
going to create over here plus they also uh creating some storage
20:38
maybe with EBS. Okay. Plus they're also creating some
20:45
VPCs in the VPC network services.
20:51
Okay. And many more things they also doing over here. So point is we are using EKCTL command.
21:00
EKCTL command. But this command is doing a lot of thing for you. But who is
21:06
helping behind the scene this command in AWS world to create VPC, EC2 and many
21:14
more uh resources to be create. Okay. So behind the scene guys in AWS if you guys
21:21
know there's one tool or one service called cloud formation.
21:27
Okay. This is a tool that will help us to create the resources automatically.
21:35
Resources means uh manage AWS services automatically.
21:40
Okay. With the cloud form, what can we do? We can create one script. The script is known as template here.
21:48
And whatever we write in the script, they will perform it for you automatically. Whenever run this
21:54
template or when you run this script, Okay, they will launch and they will set
22:00
up those services. I can write in the script I want S3 bucket. I can write in
22:06
the script or in the template I want EC2 instance to be created with this AMIS.
22:12
Okay. So almost any services whatever available in AWS.
22:19
Okay. While writing the script okay or by writing the code we can
22:26
manage entire infrastructure of AWS. So that is the reason cloud formation is
22:31
known as infrastructure as code uh service right is a very big service even
22:37
though we have entire course only one course in a cloud formation it's so big service okay and obviously this class is
22:44
not about this class is not about cloud form only thing what I'm trying to tell you here is whenever you are running ek
22:51
command whatever ek doing
22:56
okay is actually not done by ectl Okay. Then launching of the node,
23:04
the worker node, setting up the EPS volumes. Okay. Setting the VPCs,
23:10
whatever is requirement for the uh EKS cluster that from this tool. This tool
23:18
internally is contacting to the cloud form.
23:25
Okay. And what they done they create a cloud formation code
23:31
automatically entire setup automatically that also known as cloud formation stack
23:38
and this tool asking the cloud form that can you run your code can you run
23:48
your stack okay that's what you can see here so if you go to Mumbai
23:54
Mumbai you can See this ST right now created
23:59
this that's the name of the ST okay EKCL cluster 2 this because I given
24:05
the cluster name is cluster two so they create the ST name same name of my cluster okay and if you note here they are in
24:14
progress okay that's what you can see also here this command is still in progress
24:21
okay what you can see here the stack with this name is deploying.
24:27
Deploying means they are in progress means they are deploying the
24:35
EKS related resource in AWS. What they're deploying? They're launching nodes, EC2 instances and many more
24:42
things they are uh launching. So my point here is okay it look like EKCl is a command
24:52
who is setting your entire EKS for you. Okay but it is not the actual truth. The
25:00
truth is EKCL command is the one who will create cloud formation stack or the
25:07
code or the template for you whatever language they support
25:15
and submit this template to this AWS. So remaining part
25:21
of setting up the EKS cluster is the whole uh game of this this you see this
25:28
is created by EKSCl but setting up the EKS C EKS cluster is
25:34
actually done by your cloud for it means while launching the EKC cluster
25:41
something fail okay or some trouble come up so the best
25:47
flesh to see why they fail where they facing the issues the best placeh to
25:52
come and troubleshoot is this place mean there isue issue in the cloud
25:58
formation template something either EK command does not
26:03
create properly or maybe something whatever they create that might already exist they're conflicting
26:11
or maybe EK command say I want to create a instance with some T2 hello type
26:17
instance But the res is not available in Mumbai. So EK does not know they submit to cloud
26:23
formation. Will cloudformation launch those that time they fail.
26:29
Okay. Or maybe EKCTL we say I want to launch VPC. Okay. So EKT does not know
26:37
how to launch VPC. Cloud for is the one who launch VPC for you. But maybe in
26:42
your region we have a limit on VPC. For example, your Kota is five. You can't create let's say more than 5 BPC they're
26:49
already done right so EK will be command does not know but when we ask cloud formation when they're launching that
26:54
can be fail okay so what I'm talking about guys
27:01
what I'm talking about uh your setup of EKC so EKS cluster is
27:09
internally completely governed by or deployed by cloud form
27:16
How ease is helping you? You don't have to you guys see also here
27:23
you don't have to create cloud for code but creating the code sometime consuming
27:30
time a lot of extra knowledge you need in the language that cloudformation need you don't have to create this they will
27:36
create for you on the fly and for on your behalf they will also u they will
27:43
also launch the uh the cloud formation template for
27:50
Okay. Uh template for you. So that's one point right.
27:56
Second thing is now we come to know whenever we are using EKCL command
28:04
internally they are used calling cloudformation template or clformation
28:09
stack. From this stag we come to know what is the current status.
28:16
Okay. Or they deleted or they created
28:22
okay they failed. So you know I I run multiple time EKCTL.
28:27
Every time I run in this uh class or the classes you can see this details going to come up here something fail or
28:33
deleted or I can go in depth in this. This is what happening right now at this
28:38
point in time. Okay. So what you can see what is happening at this point in time.
28:46
Okay. So you can see here this ST is just a name. It is in
28:53
progress. Okay. But this ST behind the scene
28:58
launching these resources
29:04
sorry these resources. Okay. What they launching? They're
29:10
launching security group you know firewall right and this part is done.
29:16
So when you run EKC customer EKL command right so internally they
29:23
use create security group with this name what the security will doing for you we
29:29
can check here is a firewall maybe they are allowing some IP addresses they're blocking some
29:36
IP addresses they are doing connection between master and the worker node some some kind of rule they write over here
29:42
so if you see here the name is in E 08 AE
29:48
0 AE this one. So you can see the rule what they're doing, right? They're allowing some
29:54
traffic and something like this. Okay. Plus they launch the cluster and guys
30:00
when I say launch the cluster in EKS normally it means they launch the control pane master node again they
30:06
create more security group. Okay then create a security group for ingress traffic. But in GRE we have a
30:13
detail discussion on this in upcoming class. Take a net net gateway.
30:20
Okay. So if I go here guys net gateway you can find in the VPC
30:27
uh page. Okay. Sorry those who don't know VPC VPC
30:32
is a network service. So if you want to create your own lab entire network with router and switches and firewalls.
30:40
All right. It is given by this file. But here there's a uh service called net
30:46
gateway. Okay. So one net gateway right now is
30:51
being created created name 0.
31:00
Uh where is it's not here still and this
31:06
is the name actually cluster B. So net gateway has been created.
31:12
Okay, this netway gateway has been created. So what is the use of net gateway? If you know about net gateway
31:19
by this, all right, any traffic from internal world can go to outside world.
31:28
Okay. So I'll give very quick information about net gateway one more time in a minute. But just very quick
31:35
information. If you are working in the private world, if you want your uh
31:41
system in your private world can go to internet, right? For example, right now my laptop at this point in time is is
31:49
not connecting to the internet directly.
31:55
Okay. So I can't directly go to internet but but I can use my router at my home
32:01
broadband from my home to go to internet. So boardben is in my case is giving me net gateway facility.
32:10
Okay. So it's something like this. Otherwise those who know about networking in detail netting concept
32:16
SNET DNET they understand more in depth. But very quick information I just want to tell you it's been created here.
32:24
Okay. I'll give you a very quick architecture also in a minute how these pieces connect to each other.
32:30
Okay. Inter gateway. Okay. So this is actually this is net gateway. This is internet gateway actually.
32:38
Okay. Internal gateway means if anybody want to come in for example this is my laptop in running in my home in my
32:44
private world. Nobody from outside world right now connect to my network. I can go out but nobody can come in.
32:53
Okay. Right now this is a current set of my home. Why? Because I don't have an internet gateway.
33:00
But here they launch internal gateway. So anybody from outside world try to come in in your Kubernetes world they
33:07
can come in because we have a internal gateway attached. So if you see here internal gateway has been created here.
33:15
This is the internet gateway has been created. Okay. It's been created here.
33:21
Then you can see some kind of private routes.
33:28
Okay. create sorry private route I'll explain in a minute even though there's no VPC classes those who know AWS they
33:35
know about VPC all the things okay plus they also uh set up cloudatch metrics so
33:43
any information about uh EKS cluster they they are pushing into cloudatch
33:50
service cloud service okay and for this they
33:56
need some policy and rule that was that created So see here my point is my point is when
34:03
you launch this cluster when you launch this cluster
34:10
okay uh with ekl command behind the scene
34:17
many more resources has been created and everything is by cloud from
34:23
lots of thing but these are the service related to AWS only VPC created routing table
34:31
created you can see subnet created subnet.
34:36
So if you see here one subnet created second third fourth fifth sixth lots of
34:44
subnet created and VPC created. So was also created with this name 06 F9. So if you go to VPC
34:53
okay so this is the VPC created
34:59
okay and if you see the VPC also have the network range for the VPC and under this VPC I will
35:07
draw this uh one more time in a diagram then you understand more clearly what is happening so I'm just showing you right
35:13
now very quickly what is happening behind this and this VPC
35:18
okay right I select this VPC from Here the VPC name is is
35:25
0 F9 Z F uh
35:31
this one. So this VPC has some subnets
35:38
and if you see here around six subnets they have created and every subet has their own network range
35:46
okay network range and these are the IPs. So I'm just trying to guys collect the information. Why this information is
35:51
important? I'll tell you in a minute. Okay. This also been created here. Okay.
35:59
Plus VPC get has been done. So these many
36:04
thing has been created. And then finally if you see here the the stack has been
36:09
completed. Again if you go to cloud formation here. Okay. Okay, if you go to again ST this
36:17
ST has been completed. It means from the cloud formation standpoint point of view.
36:24
Okay, you whatever resources need to be created is been created here.
36:33
So created here and here there's a list what all resources
36:39
need to be created is been created here. Okay. Okay. But by by chance sometime when you
36:47
see any kind of issues that events can be good page where they tell you
36:52
okay that according to me okay if you guys notice here in the
36:59
command line they're still waiting right still waiting but ST say I'm complete it
37:07
means my deployment complete. I send the instruction to other services
37:13
that I want to create a EKS cluster, I want to create a VPC, I want to create a network, gateway, route all the things.
37:20
Uh right, but still the setup is not completed. Why? If you notice here in
37:26
the events, okay, not everything is completed.
37:34
Okay, so something is still waiting. Is still in progress. Still in progress. The cloud formation send the
37:40
instructions to their respective services. Okay. And they are creating for us and
37:47
as soon as they create for example control plane create control plane means EKS. So if it means if you go to EKS
37:55
okay EKS master will create that's called control will plane will create.
38:01
So if you go to EKS you can see your control plane is active.
38:07
That's what this events was talking about. Okay. Is created.
38:14
Okay. Your VPC subnets have been created. Okay. Uh some netting uh route is in
38:23
progress. All right. Net gateway come created that I show you already. Okay.
38:29
Something is still in progress because something depend upon each other. Okay. Has been created. So lots of
38:36
things being created and some of things is more to create. The point is if you
38:41
create the the cluster with ekle command lots of
38:48
resource you created if you don't use ekle command
38:54
then there's a possibility you might have to create these many resource by yourself
39:01
and obviously there's no good reason to create this resource by ourself that is can be one of the reason okay we use
39:08
this kind of third party tool EK serial command. So all the best practices, all
39:13
the best kind of setup or real world kind of setup or architect they will do
39:19
for us. And you can see almost 100 different events they launched mean 100
39:24
different things they have done for you. Okay for you uh to provide your final
39:32
EKS cluster. Okay, my point here why I'm explaining this point to you again this is not
39:38
cloud formation class. Okay, but this is a good place to see
39:45
whenever you launch EKS command because right now we launch very very row command lot of customizations thing we
39:52
will do today in this command. Okay. So just just confirm that whatever
39:58
you customize in your cluster is is working the same way or not. This is the
40:03
best place to come and check or if something feel then again this is the best place to
40:09
check why they fail some error or whatever the thing would be the conflicting so they will show you the
40:15
reasons here very clearly. They say feel all the things they will show to you.
40:21
Okay. This is the reason why I give this information to you. Okay. Plus
40:28
maybe not important right now but you can see templates and this is the code they're running behind the scene
40:35
this code. So if you know cloud form guys this you guys might know how to
40:40
write this code. Okay. So this code is created not by us
40:48
and I don't want to create this code. That is the reason I use EK serial command.
40:55
Okay. So this code is been built by or created by EK command.
41:02
Okay. In a format what cloud form that's that this code and they submit this code
41:10
to cloud form. And now this is a duty of cloud form to launch these resources.
41:16
In this code what they say I need internet gateway to be create. I need that gateway to be create. I need
41:24
EKS cluster to be launched, EIP and all the things whatever you seen here. So
41:29
every block is like a one resource to be launched.
41:34
Okay. So this code is being by EKCTL submit to cloud form
41:41
and cloudformation duty is to run this template run this code and what they're
41:47
running. Okay, you can see in the resources these many resources they're
41:53
going to launch and the current status will be this is many been created and
41:58
this many been in progress. Okay, that's what we can see here. Maybe
42:03
sometime output you also see something sometime they give you print also as a message. So what are the print sometime
42:10
help you uh but this part is done this part done. So it's a kind of output
42:16
they're showing you but it's a good place what I'm talking about to
42:21
troubleshoot and some many things right now why I'm giving this information to you
42:27
it means if you want to create EKS cluster
42:34
okay the best helper tool for creating the EKS cluster is a cloud form
42:42
but challenge in the cloud form is I don't want to write these kind of JSON
42:48
code by myself. Okay. So that is the reason we using
42:55
EKCTL. But challenge is okay in this code I
43:00
want to do lot of customization. Customization can be okay can be I want
43:08
to launch I want to use different EBS volume type. I want to use different uh
43:15
worker node uh instance type okay or I want to you create VPC with a
43:23
different IP range okay VPC different IP range and many
43:30
more customers I want to do okay I don't want to allow anybody can come in I
43:35
don't want to give internet gateway okay so those kind of things right so
43:42
point is okay for this either come and change this code again and redeploy
43:48
right or what can we do what can we do we can go to ekl command and say you are
43:54
the one who is building this code for me so through you I will pass some
44:00
instruction and based upon my instruction generate the new code for the cloud form and deploy in my AWS
44:09
okay so here the role of EKCTL this one here the role of
44:18
EKS ctl options come in play.
44:23
So whenever you create
44:29
ekctl let me go for cluster first they give you this option right that we use a lot
44:36
right till date the option that I want to use different instance name different
44:41
node zones or amis or ssm enable or number of nodes
44:48
you know what we're doing we are not we are telling we are the one as a user of ekl command we are telling EKL command
44:54
this is what my cluster look like and based on this information EKCTL
45:00
command generate a code for cloud formation that looks something
45:07
like this and finally clformation will deploy the the cluster based on the input we have given to the EKCL command
45:16
okay that's what they do but the challenge is okay in the final EKS
45:23
cluster or Kubernetes cluster there are lots of changes we might need according to a requirement.
45:30
This command might not help you to give and make your cluster with fully
45:39
fully customized cluster. Okay, they give a lot of options. Modern most options can be very quickly useful
45:48
useful but okay mostly in the environment in production environment
45:54
maybe you want to create a EKS cluster with with lots of customization
45:59
requirement right that command line option does not support
46:05
so here what we have to do in EKS cluster that what you know already actually instead we go for command line
46:12
we can go for EKS ctl yml code that looks like this. That was the demo where
46:17
I show in my initial class also. But this code is very simple. Nothing very
46:23
special here. Okay, very special here. But
46:30
but this code give you lots of keyword that through which you can configure
46:36
your cluster fully customized. Okay, fully customized.
46:42
And that's what guys the detailed discussion I'm going to uh discuss today
46:48
discuss today. So let me summarize then let me again explain to you what we are
46:53
going to do today. Okay we're going to do today we are
47:00
going to create our own customized EKS cluster.
47:07
Okay. But for this the end goal is EKS.
47:13
Sorry the
47:20
end goal goal is EKS.
47:25
Okay. But one more goal we have. I want to
47:30
create a custom EKS cluster. Fully customized cluster.
47:36
Who create this cluster? cloud for but I don't know even though I don't want to know also right now
47:43
how to write the code for this guy okay so to create this code
47:49
automatically let's go build the code automatically we are using eksl
47:55
command okay but in the ek command now your two
48:01
choice cli you you can use but again this won't give you much information
48:07
Okay. But what can we do again? We can create e we can use ek command that give
48:12
very simple language almost look like a yml code.
48:17
Okay. Through which we can again again again write a code not the complex code
48:22
of cloud formation. We again write a code. Through this code we will tell only the
48:28
requirement. Okay. According uh the requirement what
48:33
I need finally in my case cluster. that I need one VPC with two subnet with
48:39
one network gateway or whatever the things would be I can tell here.
48:46
Okay. So what are we going to do? We are going to create a code for EKS ctl
48:52
command not for EKS. Okay. And when run this code, EKCT will
48:58
automatically convert this code into the format what cloudformation support. And cloud form is great tool from AWS no
49:05
doubt to set up the entire infrastructure of AKS.
49:10
It would be something like this. Okay. Now point is cloud for also the
49:16
code. EKC is also code. Okay. The challenge is okay. If you
49:25
create a code in cloud formation, so what you have to do, you have to tell I
49:31
want to create a VPC then I have to get EC2 then attach this to VPC in VPC get a uh
49:39
router for example attach the router VPC.
49:44
Okay. Every small small thing you have to tell by
49:49
yourself. Okay. So even though if you create a
49:56
router also you tell where to test this router which instance going to use this router.
50:02
every small thing you tell in the cloud formation then only they do otherwise they won't do
50:08
but in EKCL you don't have to tell those general thing right is but obviously
50:14
only the hub the higher level thing right I need my cluster look like this
50:19
but but obvious cluster something like this but obvious to create a VPC but you to attach the but you have to attach
50:25
this instances many hundreds more things to be done okay so guys this is what Sometime
50:32
somebody says that here also we have to write a code here also write a code why
50:37
we'll add more tool like to write a code in cloud form you can do so
50:43
okay but here every small steps you have to type as a code
50:49
but ekl to e ek is specialized for eks
50:55
and they know in the eks okay that that we don't have to
51:01
everything about about the EKS right about the the the infrastructure they
51:07
know if they get a security group where to attach the security group if that is the private key where to the private key
51:14
okay and most of things you don't have to tell this but obvious thing that we always need in EKCL
51:20
okay for example that they know obviously that this is the AMI for
51:26
worker node they know obviously this worker node have to register with the master node
51:31
So there's lots of thing that is but obvious we don't have to tell any question there's always we need
51:38
a equist right they will do for you okay so technically with the ekiller
51:44
command by writing the code we can tell the higher things right the sub custom thing what you need a cluster is higher
51:50
level for example I need 10 worker nodes I need work this worker mode this my instance type I need a worker node this
51:57
IP range I want to those kind of things right I think this this also make you quick you know
52:05
difference why we don't want to use formation we use ekl it's still both the
52:10
place we write the code but eksql code will become very simple only the higher level things you need to tell to the
52:17
eksl to we write in the bal language
52:22
okay so I think this cluster might be created not it still waiting. Why are
52:30
they waiting? Maybe sometime you know we are stuck. They maybe they're stuck. So we can quickly go to the the uh cloud
52:38
form and ask uh cloud form in this stack.
52:45
In this stack okay some event is going on. Uh so tell
52:52
me which event. Yeah, these are the events still waiting. they're doing something for you. Okay, a lot of events
52:59
have been completed. Okay, so these are the things, right?
53:05
Uh plus many more things. Uh again, I don't want to go here because they are running in the cloud
53:12
world. Okay, so this event also generated logs. Okay, a cloud watch
53:17
events. We can go there and see more details what is going on, why they stuck or why they take a lot of time.
53:26
I'm sorry. So those thing we can see from the cloud watch also.
53:31
Okay. So but again this is not the AWS training as such. We will focus only eS
53:37
part right now. So let's go
53:43
for this part how we can customize this file in more detail more advanced.
53:54
Okay, let's let's see this. Before this, I want to tell you one
53:59
small thing here. Okay, small thing here. Internally in AWS
54:06
world, your cluster is managing in the personal
54:14
network that is known as VPC.
54:21
VPC is your private network. Okay. So whenever you launch a EKS
54:28
cluster they create a independent VPC
54:36
is you can think is like a one building the on premises building they create
54:41
okay and in this VPC they create multiple different rooms let's say this
54:47
is one building of office and they get multiple rooms these rooms are normally
54:52
known as subnets here they get multiple rooms
54:58
Okay guys, again this classroom of VPC I'm just quickly giving you some small terminology as a as a revision those who
55:04
by chance forget the VPC concept and they might don't know also right so they create multiple subnets
55:13
subnet one subnet 2 sub 3 subnet 4 okay and why they create the subnet
55:19
because this subnet they're going to put your EC2 instances
55:26
Which instances your worker node? So worker node they're going to put
55:31
here. One worker node they put in subnet one. Second worker node they're going to put in subnet two.
55:41
Okay. So let's say if they if you launch a case cluster four
55:51
uh worker node. So one uh E2 instance we put here and they spread to all the
55:57
subnets. Why? Because guys if you remember we we
56:05
launch this cluster on EKS in EKS world mostly we put all the worker node in one
56:14
node group. Okay. So in the node group you say
56:23
okay in this node group I need three worker node or four worker node.
56:30
Yeah and one of the things what your node group will do for you you know desire
56:35
capacity we say here two worker node or one worker node. So we say two worker node or four worker node. So Norgo what
56:41
they do one of the duty of the Nord group is they will go for better
56:46
planning one of the planning or dis disaster recovery planning and according
56:52
to this plan what they do if you say four work on node so they launch one work on in subnet one one in subnet two
56:59
subnet three subnet four why because mostly guys whenever you create a subnet we always get submit different different
57:05
ages so they might be creating Mumbai 1 a
57:12
this may 1 B different data center different aside in Mumbai we don't have 1D but for example if you go to Virginia
57:19
they have multiple DE also they might launch here
57:24
okay that's what they do okay so if you want to have a disaster
57:32
recovery plan at least two
57:37
uh ages you should use okay like a 1 A or 1 B
57:45
but we if you know about little bit of AWS we can't launch the instant back in a we
57:52
to go v subnet okay so this instance launch in a subnet and
58:00
because subnet belong to 1 a so finally your instance will launch in 1 a d center this how it work
58:08
and second thing is submit also give you one facility in submit we give the IP
58:13
range okay so example I give I 190 to 168 1
58:21
till 20 it means sorry
58:28
it means any instance launch they will get IP
58:34
from this range only so this guy might take IP1 from this range
58:40
only. Okay. So B subnet having range 21 to 30. So the
58:49
work node will take the IP address from here.
58:54
Okay. So submit is when key area in AWS world. Okay. You have to launch instance
59:02
in subdate only. Submit is the one who will decide which data center instance will launch.
59:09
Okay. And sub is the one who decide what is IP address we give to your instances. In this case, this instance the worker
59:16
node worker node. Okay. This one thing but one more
59:22
interesting thing is okay if I try to zoom this part only this part.
59:29
Okay. So let's say we have one area, one room, one lab that technically are known
59:37
as subnet and we launch subnet in one a a this
59:43
data center or a zone. Okay. And in subnet we give the range.
59:52
We give range that my IP start from 11 and stop 20. Means total 10 IP address
1:00:01
maximum we can use in subnet maximum. It means total 10 computer we can launch
1:00:07
here. It means if you launch one worker node
1:00:13
your EC2 instance that will work as a worker node or slave or the compute node that will take one of the IP address 10
1:00:20
minus one nine IPs available. One more thing guys here is if you
1:00:26
remember in my first class I was talking about something like this. If you launch a cont because it's a worker node right
1:00:33
and we are talking about the e EKS kubernetes right you're going to launch a pool container
1:00:40
they also need IPL right okay so in AWS and EKS world
1:00:50
okay they are also taking the IP address from the subnet from the VPC subnet
1:00:56
belong to VPC right VPC The IP allocation in the EKS world is
1:01:04
been governed by even by or network is managed by I can say by
1:01:11
subnets and the VPCs we don't use the word subet always we always use the word VPC because we one
1:01:16
VPC can multiple subnets a VPC okay so entire providing the IP address
1:01:24
range providing the connections and the networking is done by VPC only
1:01:29
if you say only it means if you have create a subnet
1:01:34
that has only this range of IP address it means total one IP given to work or
1:01:40
node nine IP has been left it means maximum nine port we can launch okay as
1:01:46
you launch 10th port every port we need IP address IP is not available the port
1:01:51
will fail with the error or the event called we not able to assign network uh
1:01:57
IP or something like this they will feel. So it means it means if you think
1:02:05
in this subnet number 1B or belong to 1B data center as
1:02:11
subnet number B okay everything in this subnet you might
1:02:17
have to launch two or three four worker node and out of this they you want to launch thousands of ports that is a very
1:02:22
common requirement then planning for this network range is very critical
1:02:32
Okay, you have to give thousands of IP address provided to your subnet. So if you
1:02:39
notice here very quickly if I go to my VPC.
1:02:44
Okay, if you notice also here in my events in my cluster in the cloud formation what they're doing they are
1:02:50
creating a VPC and they're creating a subnets.
1:02:55
subnets. Okay. So, and if you go to VPC page.
1:03:03
Okay. So, in this V this VPC is equals to this big area
1:03:13
under VPC this subreddit is equals to 1 56. Let me go to this this VPC.
1:03:21
They might be launch more maybe not more actually. Let me again go and pick
1:03:28
this VPC the filter and these six subnet by chance they create.
1:03:35
Okay, means in this uh VPC I have four subnet creat but they have created six
1:03:42
subnets by chance here. Okay. And in this subnet if you pick
1:03:49
this one first one this just a name of the subnet
1:03:54
subnet private A south 1B this is the name of the subnet but if you talk about
1:03:59
this subnet if you click on this subnet technically think I I'm here
1:04:06
if you talk about this subnet okay in this subnet total IP available
1:04:13
in this one Why? Because in this subnet we have
1:04:19
attached this range. So in the networking world guys we don't give the range in this way the way I explained to
1:04:25
you. In networking world we give the range in a format of C that look something like this. I'm not
1:04:32
going to explain to you what is this. Those who buy does not know about how network range C look like. I asked my
1:04:38
team they'll share some network video basic network video for mine. There you can understand this part. Even though
1:04:44
those who buy does not know subnet VPC creation by yourself also I will ask my
1:04:49
team they will provide you all the basic video subnet VPC where I show you step
1:04:54
by step if you want to create the VPC subnet by yourself also you can create if you want to create otherwise here we
1:05:00
don't need they will create automatically but if you want to know we will provide the video to you as a basic requirement
1:05:07
okay so your subnet we give the range
1:05:13
according to this range this many IPs available it means in this subnet
1:05:19
total worker node let's say 10 plus all the port on the top of worker node
1:05:27
we can allocate maximum these many more IPs it means after this many ports if I
1:05:33
launch one more port it will fail because IP is not available
1:05:39
it means if you think in one subnet. If you want to launch let's say 10,000
1:05:46
board then it won't work. Then what you have to do you have to create a subnet
1:05:52
by yourself where you have to increase your range
1:05:58
of your C and if you know anything about networking so instead of 19
1:06:06
we have to add 18 or 17. So lesser the number would be increase the size of the
1:06:14
IP address. You can think in this way. Second thing the subnet is belong to 1D
1:06:20
ages. Okay, that's why I was talking about it
1:06:25
means all the port run on the worker node and worker node launch in this
1:06:33
subnet. They launch in 1B data center or AG I
1:06:38
can say. Okay. But if you notice, if you go here in the subnet,
1:06:45
we have one more subnet created. If you go to this subnet, this subnet created in one A, they have again here this many
1:06:53
range. Okay. So automatically subnet ced
1:06:58
different aes. Okay.
1:07:03
Why? Because for the planning of disaster recovery. If one of the entire
1:07:09
data center goes down or a goes down, it's still we have other worker node as a port running there.
1:07:16
Okay. And you guys know one more thing about the compute node of AWS. Sorry not as Kubernetes. If cubit find the worker
1:07:23
node goes down, the port goes down. So wherever they find the remaining worker node, they relaunch the port there
1:07:29
automatically. So technically you won't see any issue in the application. launching the application port will be
1:07:35
gone by AW not not AWS cubernetes master the control plane a master node that
1:07:42
will be done by cubernetes you don't have to worry about from the as perspective what as to provide this
1:07:48
planning to to have your worker node in
1:07:54
different different ACS that's planning and who will do this planning for you it
1:07:59
will done by EKS cluster node group
1:08:05
in EKS cluster. We always want to manage our node.
1:08:12
Okay, so we go to compute. We always manage our node in a node group.
1:08:20
Okay, that's what we can see also here. Okay, they create a node group, right?
1:08:26
Same name you can see here. And we're going to go by default because of this command they launched two uh two worker
1:08:36
node that what you see here okay but if you notice here this node
1:08:41
group has launched two worker node okay two worker node
1:08:48
and worker node is your EC2 instances if you notice two worker node they create and they are going to create still they
1:08:54
are maybe in in process because the process is still going on they are ready. So it's coming some time but what
1:09:02
they do that two worker node one they launch in 1 A one they launch in 1 B or maybe 1 C whatever they would be
1:09:10
okay that we can see from EC2 page also
1:09:15
okay EC2 page also I'm showing you the
1:09:20
default setup right why if you know this this default setup then you can customize your next cubernetes cluster
1:09:28
so if you See here guys two worker node has been created or so two worker node yeah is created
1:09:34
but this worker node is launched in 1 C
1:09:40
why because not we can't launch la instance directly in the work uh ages
1:09:46
internally what happen this instance is launch if you go to networking part
1:09:52
of it they launch in
1:09:58
in this subnet. This sub 1
1:10:04
because this subnet belongs to if you if you go to the subnet page even
1:10:12
because this subnet belongs to this subnet
1:10:18
belongs to 1 C. That is the reason
1:10:25
this instance launch in 1C. Okay. Second thing is if you see this
1:10:32
instance has this network range.
1:10:40
Okay. Or I can say this sub has this network range. So all the IP
1:10:46
in this worker node and the worker IP will take the IP from this range only. That's what we can see here. The IP
1:10:52
address of the worker node is this one here.
1:10:58
Okay. And in this work on node when you launch the port will also take the IP
1:11:04
address those IP address of it will pick from here. How I know for example in
1:11:10
this work or node maybe there's some port running as a system port maybe
1:11:15
okay and those IP you can see here secondary IP addresses that we can see here. So these IP address we attach to
1:11:22
this worker node. And this IP in the worker node is providing to their port whatever port
1:11:29
they're running maybe a system port or the port we launch these iPad is allocated in this guy but every IP you
1:11:35
see here they come from this range whatever range we have given here
1:11:41
1916/9 range is given here
1:11:47
okay so this one point right now point here is why I'm giving this information to you
1:11:53
Because creating this VPC
1:12:00
under this VPC who creates VPC cloud formation but who
1:12:05
instructed cloud form EKC to command
1:12:11
okay even though it doesn't instructor but they have some Bible settings according to the setting they they
1:12:18
launch that VPC under the VPC. Okay, they create a subnets
1:12:25
one sub 1 a 1 B with some name some range of the IP address but point is I want to customize
1:12:32
everything I want to create everything according to my requirement because I might don't want to give so
1:12:39
much any IP range or I want to increase my IP range maybe maybe I don't want to deploy any worker
1:12:46
node and port in one C data center
1:12:51
okay and many more thing. Okay. So for this either you can write a
1:12:58
cloud for template or stack. Okay.
1:13:05
You do so or without because writing here is very complex because complex
1:13:10
means only creating is not important here. Connecting the tots is also for
1:13:16
example we get a private key then attach the private keys to in each to instance. So you have to first pick the ID of the
1:13:22
instance then we connect right. So it's a long long process right
1:13:27
but in EKCLE command they know how to get they know where to attest you don't have to travel much
1:13:34
okay so I think you understand the requirement right my requirement is I want to customize almost all the
1:13:42
resources in the EKS world okay
1:13:49
whatever resource that you use by the AWS
1:13:54
Okay. So here the role of this file come in play
1:14:01
and here guys in this website you can see lots of example precreated.
1:14:07
If you click on the left bottom example tab, it will take you to the official
1:14:15
GitHub page of this company V works who is created the EKC command and they give
1:14:21
you lots of precreated viral code tested code and very very interesting codes.
1:14:28
Okay. So one of the simple code can be this
1:14:34
one. Okay. So if you want to create a cluster
1:14:40
okay cluster with one node group with this instance type with one worker node
1:14:47
in this region with this cluster name just run it that's all
1:14:52
okay plus by chance one more thing they have in this cluster whenever they generate
1:14:58
the log okay log
1:15:04
especially the control plane logs Okay, those log will be sent to
1:15:09
cloudatch log. So we enable this type also.
1:15:15
Okay, even though we can also type here which type of log you want to send.
1:15:20
Okay, any who uh log into a system authenticator log
1:15:27
your your you know control plane has some control manager internally in Kubernetes.
1:15:33
Okay, those logs and all the logs also.
1:15:38
So these are the logs supported API. You guys know when any user connect to Kubernetes with EKCL command or EKCL
1:15:45
cubectl command they can API program. Okay. So whenever they say say something
1:15:52
get port uh create port create deployment those send to API. So you have to create that log also.
1:16:00
Okay. So that to be sent to the cloudatch. So
1:16:06
if you guys know cloud watch one server ws cloud watcher service called cloudatch logging. So they send the log
1:16:12
over there. Okay it's a pretty simple comm uh file
1:16:17
you can run and create it. Okay. So, what I'm going to do, I'm
1:16:24
going to take this code. Okay. I'm going to take this code.
1:16:32
Uh
1:16:37
let me take a row and run it. Okay.
1:16:43
Okay. This cluster is running. Okay. But let me run this code also. So,
1:16:50
a kl create cluster and I'm creating cluster
1:16:58
from this file. this file right now they're creating in
1:17:04
a U north one whatever would be they launch the cluster there okay by chance
1:17:11
I believe they does not support file to be accessed in this way so what I'm going to do I'll go to my document if I
1:17:19
have ekctl one minute let me create one folder
1:17:25
eksctl uh config
1:17:32
And let me download this code curl command
1:17:40
or double command the support. Yeah,
1:17:52
right. What happened? Let me call my one O.
1:17:58
This is uh I'm just using same name.
1:18:05
Okay. So this file downloaded.
1:18:10
Okay. Now how to I said by the download here does not
1:18:16
matter. So how to run this? You guys know EKCTL
1:18:21
create cluster file 01 simple.
1:18:28
Now again EKC tells create a cloud for template in this region whatever the region would be and this time they
1:18:35
creating the cluster with one this type but they creating in this region but
1:18:41
here this time they will enable the cloud watch login
1:18:46
it take some time when this cluster up I will go and check this okay so you see here configuring the
1:18:53
converging okay only we get a log for this But we're not creating the rock for API and
1:18:59
the settler. Okay, because we don't have the access
1:19:05
of a master node. But what is happening in the master? We should know, right? And who will tell us
1:19:11
the logs? And for logging in the
1:19:18
config file of ekctl, we are passing this option which kind of
1:19:23
log I want to enable. depend the requirement you can enable those log. So
1:19:29
this one quick example it takes some time obviously we are running this code. Okay similarly
1:19:35
if you go to this examples we have this example
1:19:42
um let me check this. Okay here guys the now that VPC to be
1:19:50
get by your way. Okay.
1:19:56
So by default they create a VPC automatically. But if you want to create a VPC by your network range you can type
1:20:02
here and by default VPC they create they don't support IPv6 but here we can also
1:20:09
enable IP6. We need IP6 you can enable that. Okay that's also right adding the VPC
1:20:16
port. Now we can customize the VPC and then the range of the VPC.
1:20:22
Okay. So this is one more thing we can do or if I go to uh this example let's
1:20:30
can hold for a second please.
1:20:50
Okay. So this example okay this example you know already
1:20:57
nothing very special we're going to get two node group why we want to get two node group because different node group
1:21:04
we have a different instance type but here we're going to get four worker
1:21:11
node it means this node group will auto manage the almost all the disaster
1:21:17
recovery plan so if you have three or four or five ag so they will distribute
1:21:23
automatically your worker node and the ports okay this kind of example we have seen
1:21:28
on the initial classes also okay that's what these guys are doing
1:21:36
uh existing VPC this also good example I believe
1:21:42
okay guys in your AWS world
1:21:47
okay mostly we have lots of uh application already running let's say
1:21:55
my database in other application in one of the VPC
1:22:00
one of VPC for example so this VPC we already have in our account
1:22:07
okay where we have done lot of thing we have application running instance running okay I want my cubernetes also
1:22:16
launch in the same VPC Why? Because if you know something of VPC is
1:22:24
okay by default behavior of the VPC is if you have one VPC
1:22:30
and if you one more VPC this is VPC number one this VPC number two any
1:22:35
instances running in this VPC try to connect to this instances they don't have networking enabled
1:22:44
okay this is a by default behavior of the VPC VPC is like your private world
1:22:50
isolated world okay two different VPC in two different private world this called VPC virtual
1:22:58
private network technically we can connect to VPC there's a concept of VPC peering there's a different point but this is by def
1:23:05
behavior so what I want I want we already have
1:23:10
existing VPC where everything has been preset preconfigured
1:23:16
okay my instance is running my database running my storage available
1:23:21
uh many more things maybe okay my RD service running so I want now in the
1:23:27
future I want to launch EKS cluster but by default behavior they launch in different VPC but I don't want no I want
1:23:34
it should be launch same VPC what is already exist so my port will have a
1:23:40
reachability to these guys these guys are re to my pool directly because they belong to same network
1:23:47
okay so in this use case then this is the keyword we can use
1:23:54
okay we can give the VPC ID every VPC has their own ID we can give the VPC ID
1:24:00
there okay VPC ID there plus we can also tell
1:24:08
because VPC already exists so we can tell VPC has this range otherwise we don't require to tell it's optional
1:24:14
in this VPC we can say this is the subnet we want to Okay. So in this VPC we can say now I
1:24:23
want to create subnet 1 A 1 B 1 C three subnet I want to
1:24:29
create and then I want to create one node group with two worker node.
1:24:36
Okay that's what we can uh tell here but this is for existing so that's what
1:24:43
we write the ID. Okay, with the IP address. Now one more
1:24:49
thing here uh if you don't mention the subnet then they use the previously existing
1:24:55
subnets in this VPC but technique is good practice mostly
1:25:01
different different workload we have to manage in different subnet is a good practice for a lot of reasons
1:25:07
okay so if you know AWS and VPC concept and managing network trafficics okay and
1:25:13
cloud so you guys know in one VPC in one VPC
1:25:20
Okay, we can create a multiple subnets. By default, every subnet has a
1:25:26
connectivity. So do not because if you belong to one VPC, if I launch something here, if you launch something here, you
1:25:32
don't have to do anything. They have a connectivity that done by VPC only.
1:25:39
Okay. But this subnet why we create? So in this subnet we create this to manage
1:25:45
the resources instances having same workload and many more extra setup we can do here.
1:25:53
Okay. So that's what we're doing here. We are using existing VPC but we are creating a subnets.
1:26:00
Okay. So that ease related workload we manage in different subnets
1:26:06
but they belong same other subnet whatever other resource already been launched there we can have a
1:26:11
connectivity that you don't have to worry about but only worker node are managing or port we are managing a
1:26:17
different subnet just to management purpose or many more extra benefit you also get but this is the one point
1:26:24
so if you want to launch the kubernet cluster in uh in
1:26:32
existing VPC. This is the key you can use here. Okay.
1:26:38
Then advance the node groups.
1:26:46
Okay. Now here you will see lots of customization.
1:26:52
Lots of customizer. Okay. Some more thing. Let me try to explain
1:26:57
to you right now. Um we are going to launch a cluster with
1:27:04
this name here. In this cluster we have one node group
1:27:09
with this name. Okay. Where we tell this instance type
1:27:15
minimum maximum this one because I told you guys in my last class about about auto scaling
1:27:22
of the node not the port both auto scale is different right? I
1:27:27
explained you both about the autoscaling in the last class. If you manage the autoscaling the port
1:27:33
then we have HPA concept in the cubernetes. If you're managing the autoscaling in
1:27:38
the in the cubernetes then we have to autoscale node.
1:27:45
Okay. Then we have different concept you know ektl scale command and other commands we have.
1:27:51
Okay. But we can tell the minimum maximum right. If you on autoscaling we can't go less than two worker node we
1:27:57
can't go more than eight worker node this worker node has this hard size the
1:28:04
GP2 this we use we use Amazon Linux as OS
1:28:10
okay and these are the level of the worker node
1:28:16
okay so if you know guys about the worker nodes we always give nodes and levels
1:28:22
okay so if I show you Here this cluster already running. If you run the this command nodes so two nodes running
1:28:32
but every node we mostly give the labels right. So if you see the wide command
1:28:41
so we have some levels. Okay. So here we don't have any levels
1:28:47
given here but if you have any levels given it will be updated here. Okay. Or
1:28:52
maybe we have some command called I think show label. I think this command might give you.
1:29:00
Yeah, actually they have level. This command will show you. So every work on node we have given a level.
1:29:07
Python here there's a predefined level. For example, level is my cubernetes zone is 1 A. This zone is 1 C. There's a
1:29:15
given level given by AWS where the resource running. But mostly guys we give a label to the worker node
1:29:24
something like this. This worker node environment production. This the worker node is test environment. This worker
1:29:30
node belongs to web worker node database worker node team A team B.
1:29:38
Okay. Why? So if you guys know the concept of scheduling.
1:29:44
So when you launch any application okay so I launching the application the
1:29:50
port we can tell only launch this port where the level of the node is production or the test
1:29:58
okay so again this is a cubernetes concept so it's it is known as port
1:30:04
or node uhulings okay so that those who know what
1:30:11
equipment is again we have a level command Okay, in the other command we can give
1:30:18
node and our node name is this one and let's say I want to set my
1:30:24
environment equals to dev we just attach the level lab just label
1:30:31
right now in this worker node what you will see
1:30:37
okay we have a label attached in this one you can see somewhere where
1:30:43
there are lot of level pre given but you will also find our level somewhere I don't know it's messy but you can find
1:30:49
somewhere yeah here it is yeah okay so what is the benefit so let's say
1:30:56
I have one more node this one and I attach the
1:31:03
involvement request to production just a lab key value pair you can give according to your requirement
1:31:11
okay and now what happen. Now till date guys when you launch a
1:31:16
port will launch anywhere we have no control is controlled by
1:31:23
cubernetes scheduleuler program either in node one node two but now we
1:31:28
can control okay we can say now we are launching the port
1:31:34
okay my port to be launched in this worker node only
1:31:41
so we can control for example Example, I'm launching a cubernetes
1:31:47
create deployment my
1:31:54
image let's say httpd image hold on we know we have no control this
1:32:01
port can launch anywhere who decide cubernet has one program called
1:32:07
scheduleuler who decide this so this port launched where the launch
1:32:13
They launch in this worker node 140. They launch here
1:32:19
140. Okay. But we know this worker node is a
1:32:25
dev environment. But my requirement maybe I want to launch in the production environment. So but they have no control. So auto schedule it wherever
1:32:32
they feel like. But what you can do now because we have
1:32:38
attached the levels to the node. So while launching the port we can tell
1:32:44
okay that I want to launch this port or I will launch this deployment only on
1:32:50
those worker node that has a level environment production or team one or
1:32:58
where we have security pairs number two we have this OS base running with Windows or Linux it could be any thing
1:33:07
we can do Okay. So this called node affinity concept
1:33:13
is right. So again if you guys know cubernetes even though otherwise you can go here node affinity
1:33:20
in the cubernetes world and assign the node to some
1:33:25
node by attaching the labels. Right? Again we are not into the pure cubernet class but this is what all kind of
1:33:32
things what I explained to you and the port we can write here.
1:33:40
Okay, where we want to run it. So normally when you run the cubernetes training, you will learn um these
1:33:46
concept. All right, that where you can decide where to launch.
1:33:52
Okay, but I'm just going for this demo because we have changed something in the code of deployment. But I'm just trying
1:33:57
to give you very quick information. Why I'm giving this information to you? Because right now we this worker node is
1:34:03
launched by EKS. After we launch, we attest the level. But what can you do? You can do while
1:34:10
launching also this way. That's what I'm trying to explain.
1:34:18
Okay. Explain. So this worker node that launch all the worker node attached to
1:34:24
the level core node type front end workload or involvement production or or
1:34:30
patch level two security patch level two. Whatever you want to set the level you can set.
1:34:36
So those who the user of the Kubernetes when they launch the port they know this level those level right we extend this
1:34:42
information and by launching the port they say no I want my port to be launched in the environment dev
1:34:50
so port will launch there only where only in these worker nodes only in this
1:34:55
node group only with instance type only those thing we can do.
1:35:01
Okay. And one more thing guys here is okay. If you guys remember my last few
1:35:06
classes, I was talking about add-ons. Okay. So, if you want to launch EBS
1:35:13
volume, we need to install EBS add-ons. This colosso known as provisioner and I
1:35:18
told you that point in time there's two way to install the provisioner by yourself and by the add-ons
1:35:24
or EFS add-ons for example. Okay. And for the add-ons, we also need
1:35:32
to provide IM roles otherwise they won't work right. EKS is
1:35:38
going to contact to EBS loop. You know if you remember guys at the role
1:35:45
in the cubin cluster right we create the role is there. So same thing can also be automated by this keyword.
1:35:52
As soon as this node group launch okay all the worker node will be
1:35:58
attached to this policy and now whatever they're doing does not matter it will be they contact autoscaler program maybe ag
1:36:07
for example or maybe they contact EBS we can write the uh
1:36:14
policy rows automatic create you don't have to do manually okay similarly we have one more node
1:36:21
group created with this level. Okay. And uh many more settings. So
1:36:27
these are kind of uh this also work as something we can do here. It's very
1:36:33
interesting concept. What is worker node
1:36:38
that has the docker engine pretty installed. Okay. If you want to do some change on
1:36:46
the docker engine contain engine then this command you can pass
1:36:53
because you guys know work or node create automatically
1:36:59
okay by the default setting they have but if you want to do some changing on
1:37:04
your worker node or the container engine
1:37:10
okay so either you first uh config worker node manually go with SS
1:37:16
and do some changes or we can do this write some commands also
1:37:22
those who know about docker this is a docker intern config file and said docker if you go to these IP address
1:37:28
this is my registry IP range don't check any login and password is insecure then
1:37:34
we regard the docker services okay the point is not about this command
1:37:40
the point is point is uh
1:37:47
uh after your worker node launch if you want some command to be auto run on your
1:37:52
contain engines you can pass from here or any command you run it will be any command does not matter not only docker
1:37:59
in in your worker node you run any command while setting up the clusters go bootstrap you can run there
1:38:07
that's also Okay, one more thing guys in the one
1:38:13
more node group we launch four worker node with this level and here
1:38:19
we're using this load balancer okay this load balancer so if you want
1:38:26
to use some previously created load balancer I saw you guys know when you expose anything they use the load
1:38:32
balancer right but here you have to use precreated load balancers names you can
1:38:37
write here. Okay. Right here.
1:38:43
Plus, if you want to collect any metrics also, we can collect.
1:38:48
So, if you think some of the special metrics you want to collect and send to the cloud watch.
1:38:54
So, here we connect everyone met these are the metrics we are collecting. We can add many more metric names.
1:39:01
Okay. And again those who know about Kubernetes this concept of Kubernet and tolerance.
1:39:08
Okay. So if you think okay if you think these work on nodes
1:39:16
okay is for special case only
1:39:22
I don't want my scheduleuler will schedule any port here.
1:39:28
Hm. Okay. Till time we exclusive ask them to do it.
1:39:34
So there conse don't schedule any port here
1:39:40
ourselves. So scheduleuler maybe have 100 worker node but my cubernetes does not schedule a port here.
1:39:47
Why? Maybe this work on node 4 I have for special purpose only. So uh so
1:39:55
uh while launching the port we can tell okay I want this port to be launched that's called tolerance concept okay
1:40:02
these are the cubernetes concept it's not at all related to EKS but I'm telling you those things you can set
1:40:09
while launching okay automatically even after launching
1:40:14
also we can use cubernetes command to launch but but while launching of also
1:40:20
cluster you inside this. Okay. And uh we can also write which ag
1:40:26
to launch and some extra command going to pass here to some extra thing. Whatever the command would be that's not important. This can be any command you
1:40:33
can launch. Uh so when we run this worker node okay automatically this
1:40:39
command will be run over there. So it's a good good script actually very
1:40:44
advanced script but according to comment you can do it the setup
1:40:51
otherwise those remaining script won't be so much complex
1:40:56
okay some of the example we'll see in the future classes also but the lots of script depend upon with kubernetes what
1:41:04
you want to use for example very quickly if I talk about this example
1:41:13
Okay, if you remember guys in my last class we use CSI driver for E. So EBS
1:41:18
and EFS by manually launching the provisioners.
1:41:24
But here if you think you need EFS service or EBS service you want
1:41:30
automatically as the cluster launch the add-ons will install automatically or provision will install automatically.
1:41:36
Okay, then we can use this.
1:41:43
Okay, actually you know what they are not doing this way actually they are doing something else actually they are giving the access only
1:41:50
so again let me repeat again what this code is because I haven't seen the code what this code is doing okay while
1:41:55
launching the cluster in this node group they're going to launch one or two worker node whatever
1:42:01
the white setting would be okay because we know we're going to
1:42:07
launch a provisioner in the future you know in EBS storage class and all
1:42:12
the things so but we need IM security or role so they will auto set up for us
1:42:19
you don't have to worry about EBS or EFS or EFS services is for storage service
1:42:26
only okay so when this cluster we already have the role in the future you can
1:42:32
launch the provisioners that's all okay so that can also be done
1:42:40
SS key that I think this demo I will show you somewhere. Okay, in this cluster
1:42:47
we are going to enable SSS with this private key.
1:42:52
Okay, in this node group we're enabling SSS only.
1:43:00
Okay. And by default they pick this private key in all the west guy Linux Windows. This is the by default public
1:43:05
key they use. So you want to go upload the default public key then use this keyword. If you
1:43:12
own you have customized public key somewhere else located you can use there.
1:43:17
If the key is already uploaded in AWS then you can give the key name.
1:43:22
You can also actually pass the key directly here the value of the key. Okay. And one more thing you can do
1:43:29
enable SSM. If you think this worker node you don't want to login via SS command but you
1:43:35
want to login via graphical way of AWS connect you know SM you can enable that.
1:43:42
Okay. So my point this code you can mix and mix you can mix mix and match
1:43:49
and create your own um create your own
1:43:55
code. Okay, take some portion from here, take some from there, some K from here and
1:44:02
create the final code over here. Okay, but if you see here, if you just
1:44:09
only focus this part, just by typing this code, entire
1:44:16
Kubernetes will create. So is a EK case serial command strand point of view we
1:44:22
have to just type this line but behind the scene they will launch a
1:44:27
VPC they will launch a subnets they create a keys
1:44:33
EBS volume maybe if you have requirement enable this facility because this facility need to install some agents in
1:44:40
your instances some agents in your worker nodes launch
1:44:45
the worker node rest the the controller um node manager node. Okay. So just this
1:44:52
code we just submit from EKCTL and the convert this code in in
1:45:02
cloud formation uh in this way.
1:45:07
So I'll pick code and they will do the remaining part of your so there's the
1:45:12
reason guys EKS it will make the things life very very simple for the EKS uh
1:45:19
EK services this is a good very good resources official resource
1:45:25
based on the requirement whatever you want to do you can pick the thing from here and do uh the thing
1:45:33
even though the forget of service I think maybe tomorrow next class we'll talk about target. Okay. And other thing also we maybe we
1:45:40
need in the future we'll see it. Maybe this can be one example
1:45:46
for the subnet. I guess this is how guys you can customize the sub.
1:45:52
Okay. I show you another example but you can say subnet subnet subnet subnet.
1:45:59
We can customize right. So I launch very simple cluster
1:46:06
it will launch it will launch in some uh region. So if
1:46:12
you ekctl get cluster you won't get it you give
1:46:19
the region name because region name it's this one.
1:46:25
Okay. Now this cluster launch with this detail.
1:46:30
Only extra thing what have done in this cluster is this cluster is logging to
1:46:36
the cloudatch. This is what I enabled in my code.
1:46:41
I enabled the logging in the cloudatch. Okay. Cloudatch log. But where you can
1:46:48
find in EU north one. So if you go to cloud watch.
1:46:56
Okay. So let me search for cloudatch service is a monitoring service in AWS.
1:47:04
Now EKS cluster or Q cluster is sending the log to the cloudatch.
1:47:13
Okay. Cloudatch where in EU north one. Where is EU1? Let
1:47:19
me check. EU can be Europe. Okay. EU north one Stockholm
1:47:28
that's this one. Right. So a cluster is created here.
1:47:34
EKS cluster and EKS cluster is sending the log to
1:47:41
the cloud watch to this area only. In the log if you see guys in the log group
1:47:50
in the log group I see this was not there actually this was a new first time
1:47:55
I used this region but you can see here because my cluster name was cluster one
1:48:01
or the name they give you okay that's what the name create a group
1:48:06
okay from EKS this group is more like a folder in this group they get multiple file
1:48:13
known as log frame. Okay. So 23 minute ago they create and
1:48:20
they can see a lot of logist they create and what they're doing every individual
1:48:25
log guys this is a very very important point control plane we don't have any access
1:48:30
right is a fully managed serverless service from AWS manager node but what
1:48:36
manager node is doing behind the scene okay the manager node have multiple
1:48:42
different different uh programs Right? API program, cellular
1:48:49
program, controller program. Okay? Then log is coming to us.
1:48:57
Okay? So for example, if you talk about uh API program,
1:49:04
okay, so their log is coming. Okay. Controller program of Kubernetes,
1:49:09
their log is coming. For example, if I go to uh maybe API audit program.
1:49:17
So there log is coming. Okay. So log is coming and here we can
1:49:23
see a lot of thing what is happening in the system. Entire log is coming to us.
1:49:29
Okay. The somebody log into this account. Okay guys this log is a pure cubernetes
1:49:35
log right. So anything Kubernetes generating behind
1:49:40
the scene, they are sending here. Okay, they're sending here. For example,
1:49:47
if you know about Kubernetes, somebody log into this, somebody log in here
1:49:53
under this group. Okay, from the source IP, what are source IP and the port maybe and with
1:50:00
this in the role power all the things updated. Okay, or
1:50:06
if you go to the other log group for example maybe cubernetes controller manager.
1:50:13
Okay, so this is the log they get come from control manager, right?
1:50:20
So this is a log from the control manager. So those who by chance know
1:50:27
control manager they are the one who manage replication controller and replication controller is the one who
1:50:33
actually manage the replica of your port that's what showing here.
1:50:39
So whenever you use any replication controller many more things they are joining log here they tell you what is going on.
1:50:46
So we can't go inside the worker node. So sorry so not work or not we can go but we can't go inside the the the
1:50:55
compute load but if something is not working so as a administrator of the cubernet we should
1:51:01
know why it's not working why the challenge because in the cubernetes also guys we
1:51:06
have a security we have a roll back access control we have a users in cubernetes
1:51:11
does we have given the user right permission right power in the cubernetes
1:51:17
What does my some issue of u some uh memory issue going to come up garbage
1:51:24
collector is going to come up okay many more things may be there right
1:51:30
so by log is always a great source for troubleshooting right so because now we
1:51:36
have a log without going to the uh control node by looking at the log we
1:51:42
can troubleshoot and accordingly change our plans or settings. So this is a very great
1:51:48
tool or facility we have with us. We
1:51:53
have with us right. So so my point is mostly it is highly recommended
1:52:00
highly recommended while launching the cluster. Okay. uh in e with EKS service
1:52:10
okay enable the logging part logging is different guys metrics are different I'm
1:52:15
talking about logging okay so enable the logging part and
1:52:21
depend what kind of log you want to monitor in the future you can pick this keywords or you can go for all if you
1:52:27
want to collect all but more log you collect more it will might hit the performance
1:52:34
is different point but depend requirement you can take that right
1:52:40
otherwise lots of customiz we can do here but you guys might also understand
1:52:46
if you do the customiz you should know the requirement okay you should know the requirement
1:52:53
okay and plus you also know the basic conservatables then so if you want to use a VPC so VPC only subnet subnet you
1:53:00
need internet gateway and net gateway routes private gateway private subnets,
1:53:06
public subnets. Okay. So if you know this concept then only you can create a plan then only you
1:53:12
can create this code. Don't know the concept of VPCs for example you might not able to create this code.
1:53:19
Okay. So that's also I'm talking about. So I highly recommend for example if you want to use the VPC concept for example.
1:53:25
So if you don't know VPC learn it first understand what is different public subnet private subnet when we need get
1:53:33
internet gateway when we need net gateway after knowing the basic concept
1:53:40
then understand the cubernetes does my port should go out of the kubernetes or
1:53:45
anybody can come in the kubernetes when you expose it because exposing guys we will create a
1:53:53
load balancer right But if you don't have a internet gateway even though
1:53:58
create a load balancer ELP it won't connect.
1:54:04
All right. So my point is from the cubernetes stand point of view we can expose.
1:54:11
Okay I told you maska cubectl exposed command with load balancer
1:54:16
load balancer will launch they give a public IP but in your VPC if you don't have internet gateway attach it won't
1:54:23
work. Nobody can come in. So accordingly we test the net gateway.
1:54:29
Not in this case but in my case we need to connect the internet gateway.
1:54:34
Okay. Like this. So my point is we have to plan
1:54:41
our architecture of the networking and accordingly we will say which component
1:54:47
I need which component I don't need. Okay. So the two or three files connect together we can solve your one use case.
1:54:54
Okay. Then one more small thing about logging here. Okay. So in the logging what I was
1:55:00
talking about. Okay. So this what I explained to you.
1:55:06
Otherwise we can also enable some write some more keywords. Okay. So if you want to look at a log
1:55:13
for some written period how long you want keep your log 60 days for example 2
1:55:18
days for example. M okay this keyword also
1:55:24
you can write in the EKS CDL world the point is whatever dependent service EKS
1:55:34
need you don't have to go to as portal everything can be controlled by EKCTL
1:55:40
command by using this code that's what I'm also I'm trying to tell
1:55:45
you here okay by this two only those is whatever Kubernetes need that's all
1:55:53
okay you can use okay and that is reason guys this tool give you a different tab
1:55:59
here okay for example
1:56:04
in the clustering world if you need cloud login
1:56:12
okay so click here they will open different page for cloud login and here
1:56:18
they will tell you. Okay, here they tell you uh that
1:56:25
by by using this command you can check enable types and audit types and all the
1:56:32
things right okay and these are the options they supported that I was talking about
1:56:39
okay so in the cloud logging these are the options you can pass which kind of log you want to collect
1:56:45
okay and this is the example they give you okay what kind of log you want to
1:56:51
collect, how much retention period you want to take. So there's a good document from this document you can see all the
1:56:57
option what supported and some good examples also. Okay. And by they have a
1:57:05
command line also. Okay. For example, um if you
1:57:13
if you want to enable all the logs, you can update this
1:57:19
Okay. So if you have the cluster running already in the running cluster if you want to
1:57:26
enable all log that was not enabled or particular log type that was not enabled they can enable
1:57:33
or you can disable some logs you can disable it.
1:57:38
Okay so this is the command they give you is again e command right not eq command.
1:57:45
Okay. So I'm updating the uh cluster that means it's running and we enable
1:57:51
feature disabling something or disable all the types.
1:57:56
Okay. So EK util commands also help you. So if you go for ektl
1:58:06
utils command okay they give you a lot of things to be
1:58:11
done. So one of the things they do is update cluster logging.
1:58:16
Many more things we can do with utilis command. Okay. But here I'm talking about the
1:58:24
update logging. And guys don't think in this way that
1:58:30
I'm talking on log. I'm just giving you I'm taking just cloudatch log as general example here. But based on this example
1:58:37
you can perform another resource also. For example in ekctl
1:58:44
we have a cluster and what I'm doing here in this cluster what I'm having right now
1:58:50
okay having right now um in this cluster
1:58:57
okay in this cluster cluster two
1:59:03
okay I am want to disable all the log or maybe I want to enable all the logs
1:59:11
all the logs. So this cluster what I'm running right
1:59:17
now I think is running in Mumbai in Mumbai.
1:59:27
So already running cluster we updating this. So right now if you
1:59:32
see in Mumbai this cluster running and we log group.
1:59:40
So by saying the Mumbai there's no log group right. So the now log we are collecting
1:59:46
in any of the service when I hit enter. Okay. So they will ask you to approve to
1:59:53
change because we're doing some changes. They say we are enabling the cloud log for this cluster in Mumbai.
2:00:01
You say all. So we are enabling for everything but no change applied because
2:00:07
running cluster. So do you want to approve? So guys mostly when you update something they will ask for approval
2:00:14
okay because a lot of changes they doing on the cluster that's what asking for approval and
2:00:20
again they are upgrading this cluster okay so they're enabling the log and now
2:00:26
onward in this Mumbai cluster okay they are collecting all the log and
2:00:32
sending to a cloud watch that we generate here okay and mostly guys for if you update
2:00:41
also uh update also they are uh behind the
2:00:47
scene they run the cloud watch sorry cloud cloud form so if you go for cloud form
2:00:58
not for all but most of the cases okay where they need to reset
2:01:04
reconfigure something they might launch
2:01:09
platformation. So if you go to Mumbai,
2:01:17
so so I think this case they does not need
2:01:22
they might not need to do because they might be changing some of the they're not changing anything in the AWS
2:01:29
infrastructure. Okay, what they will be doing they're
2:01:34
doing inside the Kubernetes world. Okay. So they have done this changes
2:01:42
or maybe sometime you'll see your logs start coming here they come up right.
2:01:48
So uh Intro some cloud word agents maybe if
2:01:54
you guys know agents so they install some agents something okay and they start sending the log to so the cubern
2:02:01
cluster they're sending the log to this okay so in the Mumbai this cluster two
2:02:08
we are connecting the log if I said the more log is coming right because we enable all logs
2:02:14
so all the logs been coming coming to us even the API server logs also and many other logs also coming here.
2:02:22
Okay, is coming to us and those who know API means any
2:02:27
commands you run they will go to API everything you are doing it will be
2:02:33
connecting here in this cluster okay so that's one thing right the point
2:02:38
is right all the analys of cubernetes
2:02:44
ekctl plus AWS mostly connect together you can create this
2:02:49
kind of customized file Okay, some example I show you in my next class also some example I show you today
2:02:57
lot for example explain to you by this some of the important code mix
2:03:03
match and create your things maybe some example we might not in the future classes I will show you more example but
2:03:11
most of the interesting thing I explained to you so that's all guys for today uh today
2:03:18
class is more about EKCT TL and then the configuration file and some extra
2:03:24
information also I given to you. Okay, see you tomorrow and see some more examples in the EKS world.
2:03:33
Okay, so maybe tomorrow guys we'll talk about ingress topic of EKS.
2:03:39
Okay, mostly okay we forget some some topic we'll take tomorrow we'll update you guys when
2:03:45
I start over class. Any query if you have till now you guys can ask.
2:03:54
So uh Munir if you uh miss some classes talk to our team they
2:04:01
will try to provide you a recording you can revise those classes don't worry
2:04:07
okay so how to read the log point of
2:04:14
everything again am this class is not about the log management
2:04:20
Okay. So our intention is to send the log to the cloud watch.
2:04:27
Okay. After log come to the cloud watch. They have lot of utility
2:04:34
that we can run on the top of cloud watch. Okay. Something we can search from here
2:04:41
also. For example, you think some error is coming and you know error is coming because of port or deployment of the
2:04:46
memory. We can search here memory. So they filter out
2:04:53
all the log related to memory I don't have or maybe any log related to error
2:04:59
or warning. Yeah, these are the logs warning. The thing is not working. I know some error
2:05:05
is coming. I can come here filter here and from here we come to read no. Okay.
2:05:13
This is look from coming from HD service. Okay. So this approach you can use but
2:05:21
it's not a log management class. Otherwise you can also create a log. We
2:05:26
can also send the log and ask you for my CSV format and this log my team will load in some kind of graphical portal.
2:05:33
They get a graph and filters and they can know some AI tools. For example, this log I can send to Splunk.
2:05:40
So spank some has some AI in built so they can find out something for you give
2:05:47
you some you know analysis the on the logs. So
2:05:53
log intent tool available that they run on the top of this cloud duty is to collect the log
2:05:59
store here. Now on the top of this log you can filter here and find out by yourself or
2:06:05
you can send this log to other logs tools who give you very powerful utilities that will help you to debug
2:06:12
and find out the root cause analyst what is happening there's a different point so we are not into the particular
2:06:18
training of log management intention here is to tell you that if EK is
2:06:24
running and the control node want to send the log how can we fetch it that's what we
2:06:30
done successfully Okay.
2:06:39
So I think commumar they might have in installed uh cubernetes log agent
2:06:46
over here. Okay. So when I run this command they launch in the worker node.
2:06:54
Okay. Okay. Actually the not in work node in the uh in the manager node or master node the cloudatch log agent.
2:07:02
The log agent is one who send log to cloudatch or maybe they might
2:07:09
launch unified agent. Okay. Some agent they launch there.
2:07:14
Okay.
2:07:22
So technical uh uh Rajes uh Babu here we don't have to do anything in cloud
2:07:27
formation I just explain you something that if you use EK command they use cloud formation that was what I trying
2:07:33
to explain to you otherwise you don't need to know much about cloud formation okay for this part
2:07:47
uh yes uh uh Romesh if initially if you are setting the cluster
2:07:52
If the field setting of the cluster is a field okay then a cloud log won't help you
2:07:59
cloud log will help you after your cubes start running then your cloud uh then your cubernetes be sending the log but
2:08:07
while launching the EKS cluster if they're failing and failing can be multiple reason VPC
2:08:14
IP is conflicting they already exist we have cot limit many more things maybe
2:08:19
then those troubleshooting you have to do from cloud formation That's what I was trying to sell you in the initial part of today.
2:08:26
Okay. So, setting up the cluster any trouble come up go and visit cloud form.
2:08:31
They will tell you in the events why they're failing. Okay. But after cluster launch
2:08:39
and then launching the port deployment and many more thing is not properly working then go to cloudatch log because
2:08:46
they're pushing the log to cloudatch now. Okay. So depend guys which which area you're facing the issue.
2:09:00
Yes Kumar you can use other log management tool also proton Splunk um
2:09:05
data dog new relic a lot of two levels in market only thing is
2:09:12
okay after you pushing the log to cloud this log we can push to splunk or any
2:09:17
tools we can do the the remaining log management there
2:09:23
okay so that's also we can do do even though
2:09:28
as a cubernetes perspective they have a capability to send the log directly to other third party log management tool
2:09:35
but I highly recommend because using EKS or Kubernetes on the AWS world so highly
2:09:41
recommend first push the log to cloudatch because they have very much strong integration internally
2:09:48
after they come in the cloud then from here where you want to push you know export import push to other third party
2:09:55
tool then you can push it and do the remaining log management and troubleshooting over there.
2:10:07
So uh that's all guys from my side. See you tomorrow more deep discussion on
2:10:13
some other topic in EKS we'll see you tomorrow guys. Bye. Good and take care.
2:10:26
Uh Paris you asking getting error in as console that current user does not have access to community object
2:10:32
that is not the error there's a warning you normally get in the in the EKS page
2:10:41
it's just a error not error actually warning
2:10:46
okay what warning talking about if EKS cluster this cluster Here you might find
2:10:53
some warning. Okay. And maybe the warning different color also they're talking about if EKS
2:11:00
cluster want to connect to other services like EBS or EFS or some other
2:11:05
service they might not able to go because role is not attached.
2:11:11
Okay. Even though I don't want to attach the role also that's that's okay. Why? because maybe in the future when I want
2:11:19
to go to EBS then that time I will test the rule right
2:11:24
so this warning is just a warning it does not impact your thing but in the future if you want
2:11:32
your EKS will go to EFS service then you have to attach the role the way I show
2:11:37
you in my last classes okay that's just a error or not the error is just a warning
2:11:43
Okay, so that's all guys. Bye. See you. Good
2:11:48
day. Take care. See you tomorrow. Good day.


ript


17:06
So hello everyone good afternoon. So I have two things to share. Uh first is uh
17:13
our team is sharing you the discord channel link for EKS. So guys please
17:18
join this channel discord channel also for the ones who are new to this
17:24
training and uh usually we revise for 15 to 20 minutes about the previous session
17:31
and then after 15 20 minutes so we'll uh start the session. Okay. So our team has
17:37
been sharing you the link. So please join the discord channel.
17:42
Meanwhile, I'll share my screen and revise.
17:52
Okay, I hope my screen is visible. So yesterday uh sir discussed about EKS
18:00
core EKS. So you know uh sir discussed about the industrial use cases of EKS
18:06
that is various IT companies are using EKS. EKS is elastic cubernetes service
18:12
by AWS. So companies like Goldman Sach, Netflix, Apple, Amazon, e-commerce
18:19
website are using EKS behind the scene. So EKS is a managed service of AWS and
18:25
it is one service of AWS that have a huge potential to perform managed service of Kubernetes. So basically
18:33
entire management of Kubernetes cluster is managed by EKS service of AWS. Okay.
18:40
So after that uh we covered about here EKS uh KS cluster is the uh Kubernetes
18:48
cluster which includes storage, load balancer, active directories, RAM, CPU and many more things. So powerful thing
18:55
about EKS is that it is tightly integrated with AWS other services like EC2 and EBS etc. So sir discussed about
19:05
EKSCTL tool which is a third party tool to manage EKS. Okay. So if we want to
19:11
set up a web app we need a physical hardware like RAM CPU. So also we need a
19:17
an operating system and a runtime to run that web server. So there are three possibilities to set up this. First is
19:24
bare metal which is uh running directly on your laptop and that can be referred as an operating system. Second method is
19:32
virtualization. Uh you can launch a virtual machine or an instance which we
19:38
refer in AWS as a virtual machine and we have to configure the runtime there.
19:44
Okay. So the third method was containerization which uh for that we launch a virtual machine and everything
19:50
will be done install start means booting and run services in less than a sec
19:57
second. So container will launch everything within a second. So these were the three possibilities to set up
20:03
this. Okay. So here we can refer operating system as a virtual machine or
20:08
we can call it as a container in the containerization world. Okay. So you
20:13
know today's requirement is we need agileity and we need a great performance and speed. So if uh in container world
20:21
if something fails then we want everything to be launched within a second. So we don't want any kind kind
20:27
of downtime. Okay. So to launch a container we have ECS service in AWS
20:33
that is elastic container service. Okay. So elastic container service is different and EKS is also different. EKS
20:41
is elastic cubernetes service. So we are doing the training of EKS elastic kubernetes service. Okay. So launching
20:48
container is not we want we want when something fails it launch new container to make the application run. Okay. So uh
20:56
sir discussed about container engine which helps the container to run. So
21:01
some of the examples of container engine are cryo uh containerd etc. And docker
21:07
using uh docker is using containerd and this program is known as a hypervisor.
21:14
Okay. So I'm first discussing about the theoretical part and then I'll move it move to the practical demonstration
21:21
which s discussed yesterday. Okay. So where the container engine runs it is known as a host OS, container OS or you
21:29
can refer as a compute node or a container node. Okay. So why do we call uh it as a compute node? Basically it
21:36
gives us RAM CPU that is why we call it as a compute node. So it is giving a
21:41
computing services that's why we call it as a compute node. Okay. So EKS uses
21:46
container engine called container D. So sir discussed about one challenge that
21:52
is uh if we want to launch thousand containers or nodes then management of these nodes will be harder. So due to
21:59
any reason if one of the container fails uh then our entire setup will fail our
22:05
entire cluster will go down. So we want a program who monitors everything and we
22:10
need automation for that. So duty of that program is to keep on monitoring
22:15
all the containers and as soon as if one container goes down it will up the
22:20
other. This kind of monitoring is called realtime monitoring. Okay. Uh so if you
22:26
want our program to be fall tolerant then we need this program that manages the entire container. So for that we
22:34
have a container management tool called Kubernetes. Okay. So other examples are
22:39
Docker and Swam. And so here uh this uh program who manages container and it's a
22:47
kind of container management tool. This is called Kubernetes. Okay. So in Kubernetes main system is called the
22:54
manager computer or manager node. So any computer that is running everything of
22:59
our application we refer that as a worker node. Okay. So here uh below I'll show you the diagram as well which
23:06
discussed in the session. Okay. So container which is available and we have a requirement uh like we to take a
23:14
decision to launch a clust uh cluster container. So that for that we have a cube scheduleuler. Okay. So and this
23:21
entire setup is known as the container cluster. Okay. So this you can see this
23:26
is the master manager or and we have the nodes worker nodes. Okay. So uh storing
23:33
information of the cluster is also called the state information. So to manage all this information we have ETCD
23:40
which is a kind of database to store our information. Okay. So one of the core
23:46
facility of EKS is it gives the fall tolerance and it it has a seamless
23:51
facility which means that one if one of the system goes down then it will
23:56
automatically connect seamlessly to a different system and there will be no downtime. Okay. So program that gives
24:04
seamless facility is called a cube proxy. Okay. So in master node one
24:09
program is running called cube API. What is the purpose of cube API is that it is
24:15
meant for IT team. You can see uh this is our IT team and it sends the request
24:21
on the basis of a requirement. Say for example sir discussed one use case about Amazon u website and in that we have a
24:29
order. to order in order we have a request. So that was the requirement and it sends to the master or the manager
24:36
node. Okay. So uh yes in k test container is also
24:41
known as pod. Okay. So pod is equals to container or you can say as an operating
24:47
system. So we have a challenge if you want to launch anything we need a physical hardware that is RAM, CPU, hard
24:54
disk. So we have to purchase on demand and it will cost a huge amount every time. So to solve this challenge we have
25:00
a EKS service of AWS. It is a managed service. So everything will be managed
25:07
by AWS. Okay. So EKS is a K service but it is managed by AWS. Okay. I hope you
25:14
are clear with this. So sir discussed about single point of failure. What is single point of failure? So when master
25:21
fails so entire cluster will fail. So to solve this single point of failure challenge so we need more than one
25:29
master. So we instead of having one master we can launch more masters node.
25:35
Okay. And master to have a multiple copies is called a high availability.
25:40
And this facility is provided by AWS of having a high availability setup. Okay.
25:47
So you uh I think uh that EKS can be referred as entire KS that is entire
25:53
Kubernetes plus management and maintenance of Kubernetes means setting
25:59
up with all the best practices like security, reliability, availability and
26:05
many more. Okay. So this was the diagram uh which sir shared that this is the
26:10
master node and we have a worker nodes and we have a it uh okay and uh we send
26:16
the request. So everything will be managed by EKS service of AWS to use
26:23
fully managed service we have EKS fargate which is serless. So anything which can be fully managed so we can
26:30
refer as a serverless. Okay. Any computer running and controlling multiple computers is called a control
26:37
plane. It manages the entire kubernetes and have a full control on entire master
26:43
computer. Okay. So here control plane is the master node and worker node can be referred as a slave node. Okay. So sir
26:51
then discussed about the cost uh pricing of AWS of the service. So for master
26:57
node AWS give the serverless experience. So it has a pricing of 0.10 per hour ra
27:03
and we have to pay for that control plane. Okay. And worker node will be
27:09
everything worker node setup will be on our end. Okay. So now is the main part
27:14
which are started about the practical demonstration that how to launch the EKS cluster and running the basic commands
27:21
of kubernetes there after launching the cluster. So uh sir discussed that there
27:26
are three ways by which we can use AWS EKS service. So we have one as a web UI.
27:33
Second is we have a third party tool through terapform. We can learn uh run this AWS EKS cluster. And the third is
27:41
third party tool that is EKSTL tool which is specifically designed for EKS
27:47
service of AWS. This tool was developed by way works. So uh so to login uh by
27:54
CLI sir uh sir already had AWS configured and u so to uh sir check
28:02
about the AWS and he so checked about AWS version by AWS version command.
28:09
After that we created a user in service of AWS. So to create a user you
28:16
need to go to AM service of AWS and after that you need to add the user.
28:22
Okay. After adding user you will give the name of your user. Then click on next and you can attach a policy. So in
28:31
our case we attach the policy as an administrator access. So click on administrator access and then create the
28:39
user. So you would be able to create a user and after creating the user you go
28:44
down and you will be getting the option of security credentials and in security credential when you click uh you will
28:51
get on this administrator access you will get the uh options like local code command line interface. So we wanted to
28:58
run in command line interface. So we choose command line interface that is CLI. After creating on CLI we create the
29:05
access key. So we need the access key and secret key to configure AWS. That is why we use the service. Okay. So access
29:13
key and secret key will be created. Now you can use this access key and secret key to configure AWS. So here is uh uh
29:21
we use the AWS configure command to configure AWS by using the access key
29:26
and secret key. So we gave the access key, secret key and the region name. Okay. And we uh configured AWS. Okay.
29:35
After configuring AWS, we will start the EKS uh install the EKCTL okay tool. So
29:42
to install EKCTL uh you can search EKCTL go to uh go uh to the first link and
29:50
after that click on wave works ekctl which here in the screenshot uh is
29:55
having tick mark. So choose that option. Now go to releases latest version and
30:01
ekl windows amd64.zip zip you have to download. So here are the screenshot for
30:08
uh showing you the uh how to download. So you click on releases after that you have to go to the latest and then you
30:15
have to select the EKCTL windows AMD 64.zip as the latest version. Okay. So
30:21
after downloading you create a folder. So sir in sir's case sir down uh created
30:27
a folder named AWS EKS tools and then sir extracted and download the data into
30:33
that folder that downloaded data into that folder. Okay. So in AWS uh this sir
30:39
created one folder here and everything was extracted in this folder. Okay. So
30:45
you know how to extract. So now go to the environment variable to set the
30:50
path. So search environmental variable uh and then you will be getting the environmental variable and after
30:57
clicking on environmental variables you can set the path. Uh so we wanted a new
31:02
so we clicked on to the new and we set the same path uh which was in which we
31:08
had that folder. Okay and then click on okay. So after setting the environment
31:13
variable we will create a cluster by using ekl create cluster. So before
31:19
creating the cluster you need to configure everything uh like you have to download EKSCTL tool and then we will
31:25
create the C cluster by EKCTL. So to create the cluster you have the command
31:31
EKSCTL create cluster. Okay. So you can see that cluster
31:37
created successfully. So we had one error of version. I hope
31:42
you saw yesterday's session. So you you might be able to uh recall about uh like
31:47
about what problem we were facing yesterday and how we solved that challenge since sir already had that
31:54
that's what uh that is why both the versions were clashing so that is why we were having that error I didn't mention
32:00
uh in this PDF but uh the entire steps which is to be set up for the cluster is
32:06
shared in this PDF okay so uh now our cluster will be created successfully so
32:12
you can see this uh in the cluster we have this cluster ready and after that
32:19
we can use ekl command to get cluster that how many clusters are running by
32:25
using the ekl.exe get cluster command so uh and we have few more commands which s
32:31
discussed that is ekl.exe exe get node group. So, ng is the node group. Okay.
32:39
So, you need to uh give the cluster name for having the node groups there. Okay.
32:47
So, after that uh we uh the cluster was active. Uh okay. And then we uh moved on
32:54
to the next part. So, by default whenever cluster is created, EKS gives
33:00
two worker nodes with some instance type. Okay. So when uh as soon as our cluster was ready so we were able to see
33:08
two instances there in our EC2 dashboard. Okay. So you can see that we
33:13
have this uh system also we have this uh as a second instance ready. After that
33:22
um our uh this region is also ready. Um you can see when you create the cluster.
33:28
So then sir discussed about cube config file which contains the credentials. It
33:35
contains cubectl command. Okay. So it contains the cubectl command and this is
33:40
the setup which discussed that we had a k test cluster and we have a cube config
33:46
file which contains user as a cubectl and we have these credent credentials as
33:53
IP user password. So we we don't need to give this details. Okay. So we have then
34:00
after uh this setup everything was done our cluster was ready. So we can uh use
34:05
cubectl command that is a cubernetus command to get the nodes. So since we
34:11
have two nodes ready so we uh did cubectl get nodes to see how many nodes
34:17
we have. Okay. Then uh uh how to download cubectl? Uh so we can go to
34:25
this URL cube cubernetes URL after download uh after uh landing into this
34:31
page click on this uh I have shared the command screenshot that is uh you have
34:37
to curl this and then download that cubectl in your windows. So I think it's
34:43
clear to you that how to download. Okay. And uh after downloading so uh during
34:50
the download of that cubectl we uh got one error. So sir ran that by using run
34:56
as administrator in command prompt. So you can see that we run as an administrator and then uh we got this um
35:05
we were able to download this okay cubectl and then you can test uh the
35:10
cubectl get nodes and all your commands related to cubernetes. Okay. So this was
35:17
the thing which was discussed by the commands. After that uh we deleted that
35:22
cluster because sir told us a new uh one of the good method which is recommended to use by using a yml file. So we
35:30
deleted the entire cluster which we set uh seted and then we launched again a
35:36
new cluster by using a yml file. Okay. So sir created one file named my cluster
35:42
setup.iml. In that file uh sir discussed everything about the API version kind
35:47
and everything. So we created this yml file for creating the cluster and to run
35:53
this file we have to do eksctl.exe create cluster - f my cluster setup.l to
36:03
run this file. Okay. So we were able to run this file and at the end we'll get
36:08
our cluster ready and the cluster will be created successfully. So whenever we
36:14
want to do something in EKS we use eksctl command and to do something on
36:20
the cluster we use cubectl command. I hope this is clear and this was uh
36:25
pretty much clear in the last session. uh cleared you everything also uh I shared the do these two screenshots uh
36:33
like so how to think uh what what is the plan so this was the first we downloaded
36:39
AWS CLI then we checked the AWS version then we created the AM user then we uh
36:47
log via CLI okay that is we configured AWS after that we use uh downloaded
36:54
EKSCTL to for creating the EKS cluster and then we checked EKSCTL version and
37:02
then the fourth step was to uh that uh sir shared the link how to download that
37:07
I have already shared in the previous part of this PDF okay I hope everything
37:14
is clear if you have any doubts you can ask in the chat box
37:19
and please join the discord channel uh so we'll be joining in few It's
37:41
Shbaz Ansari why sir deleted the existing cluster and again created a new
37:46
cluster. So uh that was a command sir discussed and uh so sir discussed about
37:53
the recommended thing that is we should prefer using a yml file. So we can also create a cluster by yml file. It's your
38:00
choice and it depends on your use case. Uh it is easier to manage in yml file. That's why I s deleted and showed you
38:07
the other way of creating the cluster.
38:27
Yes. So, Daran, um we will be sharing this PDF in your portal as well as I
38:33
will uh please join the discord channel. Everything will be shared there itself.
38:40
So you can u get the link in your chat box and you can join the discord
38:45
channel.
39:20
uh winkesh it's uh it will be there in your learning portal as well as I think
39:26
we will be sharing in the discord for you to download. Okay.
39:34
So, I would say that everyone please join the discord channel to get more updates. Yeah.
39:56
Yes. So, so joined. So, yes. Thank you everyone.
40:17
Hey guys, uh welcome back and let's continue with the next part.
40:22
So in the last class guys I have explained you the
40:28
very quick information about what is Kubernetes. uh intention is not to train you on the
40:36
Kubernetes world right uh intention is uh if you have a Kubernetes right so how
40:45
you're going to if you want a Kubernetes I can say or the Kubernetes cluster so
40:50
how um u we set up our own Kubernetes
40:57
environment okay either you manage by yourself or give this entire responsibility to cloud
41:05
providers here AWS cloud and they're giving you as a service that is almost kind of fully managed service that's
41:11
called EKS service right so that what guys we have discussed in my last class
41:18
so uh the plan for today is we go more deep into it because yesterday we just
41:23
quickly launched the cluster okay uh but there's let's lots of thing we can
41:28
customize here right so some of the things we're going to see uh today and we'll go to next level right I also show
41:35
you how to use Kubernetes cluster also so very quick uh in one line brief if
41:43
you want kubernetes why you want uh that what I have given
41:51
you some idea in my last class uh where I start the journey from app and then I
41:57
told you if you want a very quick uh app to be launched launch we need containers
42:03
and who is going to manage the container in the bigger environment that the name of Kubernetes come in play. So
42:09
Kubernetes is a kind of management tool for the containers, right? Okay. But if
42:16
you need a Kubernetes or entire Kubernetes cluster, it could it can be very very big or huge. Okay. So rather
42:24
than we invest our money directly on the hardware or or or the operations team
42:29
who is going to admin this guy. Uh right what can we do? We'll go to AWS
42:35
and we ask them that we have a we need some service can you provide they say we
42:40
have a EKS service so just give this responsibility to me and I will and we
42:46
will launch Kubernetes cluster for you who will say AWS guys will say okay here
42:52
the name of elastic cubernetes service come in play okay but how you can
42:59
contact to EK service we who are the user user of EKS service.
43:04
Okay, for this there's a multiple way but one of the sophisticated way that what also AWS recommend is using a tool
43:12
called at EKS uh CTL tool that's what we
43:17
have started with and in my last class we have installed this tool already EKCTL tool and if I show the version so
43:24
that was the uh latest version I'm having right now there was some small
43:30
issue in my path okay because I have multiple versions installed. Uh so I this adjust my path.
43:37
So now whichever folder I go they will pick my latest version of EK uh ctl but
43:43
this issue you will not face maybe because you might have installed EKS on
43:48
first time and you have only one version of EKS. Okay. The only thing is the
43:54
important thing that we come to know is because EKS as a service is keep on coming with a new new feature.
44:02
But if you are a user of EKS and you're using this tool to
44:07
uh to uh connect to this service and to do something on this service then you
44:14
should have the latest updated version of it otherwise either this company will
44:19
fail or whatever the new feature they come up with you might not able to leverage this right that is the only one
44:26
small information I want to give you here okay but yeah I have this tool available Okay. Now if you want to use EKCTL tool
44:35
as this is not the Kubernetes tool. What I mean by this? This tool is just to
44:41
manage this service of AWS. Yeah. Finally the service is going to launch a Kubernetes cluster.
44:48
Okay. But Kubernetes cluster have their own personal commands through which any administrator of Kubernetes will use it.
44:54
That's what we'll see today little bit in more detail. But uh the point is uh
45:00
if you want to use EKS service then this is the command line tool we can use.
45:05
Now to use this tool or the command we have two way either you can use this
45:12
command line with the CLI. This is the command CLI we have. And if I hit enter, they give you all the option the they
45:19
support. For example, I want to see how many uh guys this is also very interesting concept EKS come up with in
45:26
advanced training of a EKS. I will talk about this this facility give us to
45:33
connect our local on premises Kubernetes cluster to the AWS cloud.
45:38
Okay. Just go anywhere. We'll see in upcoming discussion but right now get
45:44
option we have and I can say get I want to get if you hit enter what you want to
45:49
get if you want to get the cluster information so just type here
45:54
I want to get the cluster information I don't have any cluster so this is the command line tool
46:02
okay so either you can go for command line tool
46:07
so that we as the kind of user or the human being
46:13
right we can use the command line to ask the EKCTL to perform something in the
46:19
EKS service just for example if you have a intention
46:24
to create the cluster in EKCTL command EKTL command we have a create command
46:34
okay and what you want to create obviously you guys don't have to memorize this command either go and refer the document over the internet or
46:42
you can just keep it enter or have an S is a help from here you can get what you
46:48
want to create. So in my case I want to create a cluster just type here that I want to create a cluster. Now what you
46:55
can do further about the cluster right again help so these are the option guys
47:01
they they give you here okay so these are the things you can do because
47:06
technically you're going to create a cluster on AWS right but you can tell something because I told you guys
47:12
yesterday okay EKS give you service where they say
47:17
that we will go and manage the cubernetes cubernetes cluster but in the cubernetes cluster guys we have a one
47:23
master that is called manager node and lot of slave node that is also known as
47:29
worker or the compute node you have no control on master that's what we want this master is fully
47:35
controlled by AWS okay but in the worker node worker node
47:41
or the slave node or the compute node you can define what you want okay you
47:47
can tell that you want u you want u this
47:53
instance type how much RAM and CPU need. Okay. Plus you can also define because
48:00
this instance going to launch in EC2 behind the scene. Okay. So you you can
48:06
also define that in this instance do you also want maybe in the future you also
48:12
want to log into this instance. So do you want SS service to be enabled? If yes which key to use?
48:20
Okay. and many more thing or maybe you can define I want to launch this in a region
48:27
okay so let me write some note here what I want I want to define a region which region they want to launch let's say I
48:34
want to define region Mumbai for example okay so in Mumbai which ag you want to
48:41
launch so let's say I want to launch in 1 A and 1 B
48:46
okay so which ag you want to use and second thing case lot of things they will take care for example I can say all
48:54
this instance I want to put in one group okay why if you put in the group I told
49:00
you this part in yesterday class is called node group so AW will auto take care they
49:08
understand it means what we talking about when I launch A and B launch in a
49:13
different different a C launch in different ages maybe in Mumbai we have three ages right
49:18
1 A one C we can define only this two AI we no one to need. So out of three launch two guys in one A and one is one
49:25
one B and something like this. So for this we can also create a node group
49:30
okay node group again creating node group is not compulsory. Again one more thing I want to add here.
49:36
Okay we can directly launch a worker node without putting in the node group.
49:41
Okay, because node groupoup is not consoled from the kubernetes actually right it is given by AWS but node
49:48
groupoup will makes a lot of management for you one of the things what node group manage for you is this concept if
49:54
I launch three instances in node group they will take care one they launch in 1 A one they launch in B and many more
50:00
things they will do I will talk in the upcoming discussion right so so my point is having the node group is always great
50:06
so you can also give a node group a name let's say this is my node group for some
50:12
basic uh worker nodes something like this. Okay. Then I want these instances to
50:19
have a T2 micro and something like this. T2 micro. Okay. So this thing so my
50:28
point is in the command line everything is there. So when you give the cluster name we have a keyword for this.
50:36
Okay. So we can have a name. Let's say my customer has got my basic cluster.
50:46
So you should know what you're looking for. Just come to the help and create your own personal customized commands.
50:53
You can use the region also which region you want to launch. So I want a region Mumbai. Mumbai you guys know is AP South
50:59
one. There's a name Mumbai has. So region we can write here.
51:05
Okay. which zone you want to use they will auto select if you don't type this
51:12
otherwise you can type your zones also so you can type here I want 1 a zone or
51:18
1 b zone mostly is good practice don't tell they will better they will auto
51:23
select okay this makes more mostly sense but sometimes you have some specific
51:29
requirement that I want only 1 a zone only and 1 b only that time you can define if you
51:37
want. Okay. Plus there are a lot of Kubernetes version available. What I mean by this I
51:44
told you guys yesterday Kubernetes is actually main software that's what uh we would like to
51:51
manage right and this Kubernetes has multiple versions because software so
51:58
which version you want to you want to install. Okay, you might have some special requirement based on your some require
52:04
some application. Maybe you want to go for some older version or latest updated version, right? So you can decide here.
52:13
Okay. According to if you go here in in this page also
52:18
according to um EKS the latest version they have maybe you can find somewhere
52:24
maybe in the document or maybe while you create a cluster manually from graphical they will tell you which cubit version
52:31
you want to use. This is the latest default version they have. But my plan is not to launch from here the
52:38
Kubernetes uh cluster from here. But in the command line we can tell the version
52:45
and here this version we can tell. Okay. So let me go for uh uh this
52:51
version and version I want to use for Kubernetes code 1.25.
52:56
Sometime I've seen guys if you don't use the version in the command line in the
53:01
command and ek so they might sometime use older version right maybe 1.4
53:07
something not always sometime that's what you can see here you also default right if you don't give the
53:14
the uh version then they use this 1.4 four as default at this point in time.
53:20
So the the EKC command version change then they we might also update this
53:25
command. Okay, this one. So do you want to use forget? Very very powerful
53:31
service. We'll see in advanced part of it. We'll see there very powerful service. But do you want to give a node
53:38
group a name? Yes, I want to give a node group a name. That's what ng what are
53:43
the name you give? Let's say ng basic right. You can write here this is what the node group I want to create
53:50
or do you want to if you don't want to create node group that's also we can write
53:55
so thing will be exactly same instance we will launch but they not does not maintain inside the node group why we
54:02
need node group one of the reason is that what I told you yesterday and again I explained you today node group is
54:10
managed by AWS not by kubernetes and they say worker node I will manage for
54:15
you means I will decide one I put in 1 A, one I put in 1 B. AS. So it will help
54:22
you in disaster recovery plans. Okay. Then node means when you guys
54:29
heard the term node, node is equals to worker node actually or slave node. So tell me the instance type.
54:37
So which instance you want to use? Plus a T2 micro. Okay. In my case guys, I want to use a
54:45
little bit different node group or so if you search for instance
54:52
type. There are a lot of instance type in AWS either you can see from here.
54:57
Okay. Uh so there a lot of instance type. So I'm going to use T2
55:06
uh uh not uh micro because they give 1 CPU 1 GB RAM. Uh I want to go for T2
55:12
medium in my case. It's not free. It charge you but not much right per per
55:18
minute or per hourly charge because here been behind the scene they
55:24
use Linux OS. Linux OS they they charge you per minute wise. So per minute is
55:29
not big charge but why I'm using this because I'm going to show you a lot of demos. 1 GB memory is enough to start
55:37
the cluster. basic demo you can perform there but uh if you run some bigger app
55:44
bigger port container they will fail they won't run maybe because of memory issues okay so I I I'm going to use T2
55:55
medium in my case or uh maybe to make it more
56:00
better let me go for T2 extra large 4 GB 4 CPU and 16 GB RAM you don't need to
56:07
use is uh but uh but I just want to tell you
56:12
this is what I am I might require to okay but it's not free but you can go
56:19
for this micro if you want to go pre for the work or not yeah manager node they
56:25
will charge I told you 0.1 or 10 cents they charge you okay so that's what we
56:32
have how many worker node you need by default is two if you don't select But
56:37
you can select here and say my uh worker node
56:44
I have let's say three so three worker nodes so as we launch
56:50
automatically they launch three worker node okay was a minimum worker node you
56:57
always need so this will make sense guys when we I will talk about the concept called autoscaling
57:04
okay so it is something like this I will explain in more detail in upcoming discussion but it is something like this
57:09
they start with three work on node and if they they on the real time they
57:15
analyze if they think there's no much traffic there so they automatically
57:20
decrease the node to 3 to two or 2 to one maybe okay to save your money okay
57:27
so but we can decide here what is the minimum I want I don't want to go beyond two
57:33
similarly if the load increase automatically they increase the work node to 3 to 4 to
57:39
4 to 5 5 to 6 but what is the maximum you want to set 10 I don't want to go beyond 10 to save my money okay maybe
57:46
have this budget only that this is the maximum budget I have okay so I'll talk about this concept how
57:52
it work it is called autoscaling group concept we'll discuss about it but I'm
57:58
sitting over here okay every node guys is like a one operating system do you want to give
58:05
some hard disk also because when you launch the OS they need a hard disk right
58:11
so uh you can set the size if you don't set they will take 80 GB by default but you can increase decrease if you want
58:19
okay you can set your volume size also so if you guys know because this
58:25
instances they launch behind the scene okay behind the scene in EBS
58:33
okay so if you guys know about uh AWS. So we have EC2 service. So they launch
58:38
the worker node in EC2C. EC2 service. Okay. And how much instance they launch?
58:44
Three in my case automatically there's zero right now. But they launch three.
58:50
But this instance guys they launch. So for launching the instance and or launching the OS we need
58:56
volume root volume. Root volume guys they take from EBS service.
59:02
There's no EBS service. So how much what is size of EBS you want? That's what they're talking about. So I can say I
59:09
need a size uh let's say footage
59:14
by 80 or we can we can set more and less but you can also do uh because guys if
59:22
you know how to go launch a volume so we have volume types also and volume types
59:28
is the one who will decide the speed and the performance. If you go for IOPS IO1, IO2 they have better speed.
59:35
Okay. So in the terms of hard disk read and write it is called IO operation. You can change but if you don't change then
59:42
by default they GP3 but you can change also if you want to
59:48
okay GP3 or maybe you can write GP3 by default if you don't write the tech or otherwise I can change IO something like
59:54
this. Okay that's what you can do. Next thing is um next thing is do you want to
1:00:02
enable SSS because this they are going to launch instances here
1:00:08
in EC2. Okay. So by default
1:00:15
after instance launch we can't go inside this OS. Okay. We can't go inside this
1:00:20
OS. Okay. So let me go again out. So we're going to go inside this OS because
1:00:26
they disabled the SSS login. But maybe if you think you're curious to
1:00:32
know what is there going inside this worker node what setup they have done you want to see it or maybe some kind of
1:00:38
other maintenance you want to do then you can enable the SSS access okay by
1:00:43
enabling this feature. Okay. So they enable the SS access uh
1:00:50
over here. Okay, for this you have to create your own private key, public key pair in your
1:00:56
local system from where you running the command. So I'm skipping this part for a minute.
1:01:01
Okay, but you can also enable SSM. So what is SSM? You if you guys might know
1:01:07
whenever you launch the instance graphically we can connect the terminal.
1:01:13
So some OS in the as give you a way that without using party putty or SSS command
1:01:18
graphically we can login inside the OS. So this facility is called SSM. So
1:01:25
that's also we can enable okay again depend upon OS support or
1:01:31
not. But let me enable this. Try this at least not enabled. It means firewall also
1:01:38
block this. It's called security group. Plus there's no key attached. So nothing
1:01:44
we can do much uh here. Okay. We can do much here but we can
1:01:51
enable if you want. Okay. Or if you want to enable this. So what can you do just
1:01:56
for knowledge? So in my case in my case I have my uh Windows OS right now. Okay.
1:02:06
Okay. And I want for Windows I want to log to one of the instance with SSH. So in Windows what can you do?
1:02:14
You can create SSH keys that is known as private key and public key by yourself.
1:02:24
Okay. And private key there is more like a password. Don't give keep in your system. Public key you will transfer
1:02:32
to the system. Just call authorize it. You don't have to do manually. This is what they will do for you.
1:02:40
For this in the windows you have this public key private key. So you can what can you do? There's a lot of tool
1:02:45
available in the market. One of the tool I don't know I have or not. It's called key gen tool. SSS key genen if I have in
1:02:52
Windows other download in the Linux and can create somewhere else. Okay. Yeah.
1:02:58
By have this tool. Okay. So this tool is going to create a public key private key. private key is
1:03:05
storing here. So I don't have to uh I don't have to
1:03:12
copy some somewhere else. I might have all the other files. So let me override.
1:03:18
Okay. Enter. Enter. And they create this public key. So in my system I have my own public
1:03:26
key, private key. Okay. But this public key I will
1:03:31
transfer to my OS EC2 instances. Why? So that from my laptop I can log
1:03:38
into the instance without password with the help of a private keys. That's what
1:03:43
normally happen right. So those who know SSS understand very quickly. But this is what normally uh we do for login to
1:03:49
through SSS. So that's what they're talking about in the command line. So if you never SSS
1:03:55
I'll go to your this location this is mostly known as home directive. So this is my home directive windows and from
1:04:02
this file I'll take your key okay and attach to the instance which
1:04:09
instance all the three instance so you can login through SSS if you want. So
1:04:14
let me enable this. But for this keyword, you should have to
1:04:22
generate okay your public key and private key.
1:04:27
And Python guys if you have if you don't have this command in your system you can download this command from the internet
1:04:32
for the Windows Linux and Mac normally have this command. But if you don't have the command so uh we can download putty
1:04:42
and putty website. Okay, they give you uh
1:04:49
uh I think puty generate also you can use and this will also give you commands
1:04:55
behind the scene or you can search for SS keyun command you can find. So again that is not so much important right now
1:05:02
for EKS but just I'm trying to tell you from where you can get this command. H. Okay.
1:05:07
And what else you want? Many more thing we can do. Okay. Many more thing we can
1:05:13
do. Uh we can also give our instances a name. The name of the instances whatever
1:05:19
we want to use. So let me use this. So I want my instance have a name called cube
1:05:27
cubernetes uh worker
1:05:32
node and what I'm going to give. Okay. Otherwise as we progress,
1:05:38
okay, as we as we progress um then u we
1:05:43
will see many more things. Right. One more small thing I want to add here. Uh what I want okay what I want this worker
1:05:52
node I want EK service going to manage it. What I mean by this in the future if
1:05:58
any upgrade come up any maintenance come up. Okay, because this worker node also need some software some you know I told
1:06:05
you yesterday uh container engines okay so any update their patches maintenance
1:06:10
I want kubernetes ek service manage it okay so master they will manage it
1:06:16
completely but I also want my worker node also they manage after install also in the future they manage for this this
1:06:24
keyword called managed keyword uh you can uh you can write here
1:06:30
Okay, you can write here. So that's what uh we can do. Um so so guys this
1:06:36
instances typewise I write wrong is node type is different thing.
1:06:43
Okay node type is different thing most probably is instance type right. So
1:06:51
where it is, so this is the
1:07:01
instance type T2 extra large. Okay. Otherwise there's many more thing guys
1:07:08
to be discussed. So in this training guys I'm going to create cluster multiple time and every time I will do a
1:07:13
different different way and approach. So all the scenario you will understood. Okay, you understood.
1:07:20
So, we'll go and future we will talk about the add-ons. Okay, lot of add-ons we have app mass,
1:07:27
service mass, stto, um, uh, lots of thing is there, right?
1:07:34
So, as we progress, we also configure our own VPC and uh, subnets.
1:07:39
Okay, we can uh, we can uh, perform from here. Right now, this much information
1:07:44
is is is enough. Okay. And uh maybe you
1:07:50
can also do one more thing. I told you yesterday this will write a file of cube config by default here. But we can
1:07:57
change the path also. Okay. So what cube confin file? I will
1:08:03
talk a little bit more about it as when we start using kubernetes. Okay. But I
1:08:09
don't want to change further. This is the basics that I'm using here. Okay. So
1:08:14
this is one big command guys technically. Right. So if you want to create a cluster this is the command and
1:08:20
this command actually we have created we don't not refer any document we created it based upon my requirement. So this is
1:08:26
one full-fledged big command uh with us and because it is a command
1:08:32
so we have to run the command in one single line. So these are the different options here. So I have to putting the
1:08:37
option without with one space in one single line. So I can run it
1:08:44
right. I can run it.
1:08:54
But I I believe you understood right. So any moto over here is is to
1:09:04
launch kubernetes cluster. Yeah. After kubernetes cluster
1:09:09
launch. Now it is all depend upon the cubernetes administer how they want to use it.
1:09:16
There the entire scope of kubernetes come in play. And by the way I told you yesterday also this training is not the
1:09:21
kubernetes training. Okay. So if you want to learn the Kubernetes completely
1:09:28
right so they have a lot of global program available in the market one is the cubernetes CK a training this is
1:09:35
called cubernetes training or CK training cubernetes so these are the kind of global training from Lis
1:09:41
Foundation from where you can learn everything about Kubernetes CK CK
1:09:47
by the way we also provide this so if you want to learn we have a recorded video of mine on classes recently I
1:09:53
delivered You can learn from there also everything about the Kubernetes. So moto is this
1:10:00
training right now what we are doing is not the Kubernetes training. Yeah. Whatever minimum thing we need to know I
1:10:05
keep on telling you guys. So I told you that's that's what my my yesterday class
1:10:11
I tried to explain you away that uh there's no prerequisite but at the same time this is not the training here. The
1:10:19
training is our EKS. In EKSA, I'm taking the responsibility of management of the entire cluster. I
1:10:27
give this cluster to you completely managed. How you want to use that would be your Kubernetes skills.
1:10:34
Okay. And it's not only about again one more thing I want to add. It is not only about to launching the cluster.
1:10:40
It is also about uh about uh the integration of the services. What
1:10:47
I mean by this I show you in today's demo. Very very powerful integration they have ease with other services in
1:10:53
AWS. That's what we need. Okay. But this is one command guys we have now. Now what I'm going to do I'm going to run
1:11:01
this command here. Okay. This is what the command we had created. Okay. Look like very big but
1:11:08
technically if you see the way I constructed this command. So you don't have to memorize this. you go for help
1:11:14
and do it right now. As per our plan, they create a cluster with this name.
1:11:21
They create a node group with this name. They launch in Mumbai. This is what we have uh done. Plus, if you notice,
1:11:31
if you notice, uh we have also enable SS
1:11:36
means SSH. Okay, enable. But it all depend upon
1:11:42
because they're going to use some AMI for launching the OS come Amazon machine
1:11:48
images that will launch the EC2 instances if they support also that's also end point but we enable from our
1:11:54
side and they launch with T2 extra large uh instance type okay
1:12:01
that's one thing and one more you know one more interesting thing is uh we asked them to launch
1:12:08
to launch three instances in Mumbai. So one they launch in 1 A, one they launch
1:12:14
in 1B, one they about to launch in 1 C but they they're very intelligent tool
1:12:20
in a way they know in 1C data center this instant times there were no support
1:12:26
because guys not every instance support in all every region and every a also
1:12:32
so they come to know uh in 1C this instant time not support so they skip
1:12:38
this so out three two they might launch in 1 A and one they might launch in 1B
1:12:44
and vice versa. Okay. So a lot of management kind of thing they are taking
1:12:50
uh over plus they also take my public key from here.
1:12:55
Okay. I have my private key so I can log to all the three instances this co-worker node with my SSS private key.
1:13:04
Okay. So that can also be happen right otherwise you know it will take around
1:13:10
15 20 minutes to have this EKS cluster ready. So if you go to cluster
1:13:17
over here you can see this cluster is been creating with this version this also we have provided this is version we
1:13:23
need okay this version we need and the computing you will see in some time node
1:13:30
group also going to come up right then I'll show you how to use it then I talk then I tell you guys how we are going to
1:13:38
uh why EKS has a huge capability or
1:13:43
integration with the AWS cloud. Okay. So I also very very fantastic
1:13:49
demonstration. Right. Right. So let's come to this diagram again.
1:13:55
So EKS C command if you want to use one way is CLI.
1:14:03
Okay. CLI technically looks simple but I myself personally does not suggest CLI.
1:14:10
There's many more capabilities you can't do in the CLIs. the many more advanced
1:14:16
configurations you have you can't perform from the CLI otherwise the command is very big but sometime most of
1:14:22
the powerful capabilities CLI does not support yeah just for quick test quick
1:14:29
launching doing some basic change checking for example I I can directly go
1:14:34
and ask uh ekctl get cluster
1:14:41
so cluster I tell you this is the cluster launch here or I can say just show me
1:14:49
the node group. Okay. And this cluster name because there's my multiple cluster you guys can
1:14:54
launch cluster
1:15:00
over here. So so they this is not yet created yet
1:15:05
because my basic setup of cluster is going on but is in the creating phase. So you can see so some basic
1:15:11
capabilities a little bit maybe advanced capability you can see a little bit but not everything you can manage the way you
1:15:17
want to manage right. So all here the plan guys is launching the cluster in
1:15:22
AWS and you want to create some kind of very very custom environment
1:15:28
based upon your requirement right so that is a reason I highly recommend to use uh code
1:15:35
that code we write in some kind of way this called vimal way yl is look like a language but it's not language it is
1:15:42
like like a way where we describe what we want
1:15:47
okay and yesterday guys I show you very quick example of YML. So even though if you go to EK uh CL
1:15:54
page and mostly whenever see any code of anywhere EKC mostly you will see uh
1:16:03
everyone use Yman only. So instead of command line what can you do? You can
1:16:09
use the file YL and this is how file look like. That's what I show you in my yesterday class.
1:16:16
Okay, this Wi-Fi guys give you very powerful capabilities. Okay, you can set
1:16:23
up your cluster the way you want and lots of powerful integrations you can also do with third party and many more.
1:16:31
Okay, my my most of the time while launching the cluster I will focus on the WLE file only and a lot of advanced
1:16:38
u integration setup I will show you with this WLE file. Okay. But by those who
1:16:47
don't know about vinyl file, it is just a way very quick information. Those who bison does not know why file. So if you
1:16:54
guys want to uh it is something like this. If you want to store your name, your
1:17:02
mobile number, okay, or maybe your ID.
1:17:07
So how somebody know this is your ID or mobile number. So we always give a variable, right? So let's say variable is name, variable is mobile, variable is
1:17:16
uh is ID. Okay. So we have a lot of format in the
1:17:21
market. So between variable or the name variable also known as key key or the
1:17:26
value you you want to use space or equals to or colon.
1:17:33
Okay. So if you want to store key this key value pair in a YL format. So ML is
1:17:39
the one who give the format they say you have to use colon. So before the column
1:17:45
you have a key or variable after column you have the value mostly values compressible most value we store in uh
1:17:53
double quotes double quotes there's no uh comma here why is again most like a
1:18:00
JSON but not exactly so in JSON you write comma here we don't write comma
1:18:06
okay so there's a key value pair that's what we can see here so here we can say name colon my name instance type this
1:18:14
one desire capacity this one so double quote is not compassive but it's good practice but if you don't write also
1:18:20
this will work okay this is one thing second thing is if you want to store
1:18:26
multiple name one more name we have one more name we have so let's say this is the
1:18:32
information about Raz this is information about Tom okay so multiple information we have one
1:18:40
about Raz let's say this is the mobile number Raj uh this is the mobile number of this guy and the ID.
1:18:49
Okay. So, so now we have three different users or three different u persons here
1:18:55
right and I want to store all the three person in one variable. So I can use some right
1:19:01
or one key. So this is one list the second list the third list. So what I
1:19:07
can do I can create one more variable. Let's have my variable name maybe DB database.
1:19:13
This is variable. So to tell it is variable or a key we use col. And to tell this guy is one element.
1:19:20
This is a second item. This is a third item. So is like a list. Whenever guys you want to create a list, you start the
1:19:28
list with hyphen. So it it is a first list item. It's a
1:19:33
second item. This is a third item. Okay. So technically DB is a one key and
1:19:40
DB is not a normal variable is a list like or array an array how many items they have first
1:19:49
second three third three hyphen means three items they have or three element
1:19:54
they have in the array or the list okay that's one thing second thing in
1:19:59
the yl you have to also take care about one more small thing okay because this
1:20:05
name mobile ID belongs to only one one person or it's one information or one
1:20:12
block of code whatever you say. So if the name we have to give two space here so this guy also have a two space
1:20:18
otherwise yl code will fail. So in the code we have to give a purpose space equal space that whoever belong to
1:20:27
same uh block of code that's is normally known as indentation right so if you
1:20:34
don't give the intention why code will fail so if you know a little bit about python as a programming language same concept is there in python also
1:20:42
so this is like a write syntax of the uh yml code
1:20:48
okay syntax so that's what you can see Here node group is one key.
1:20:54
Okay. But this key have two list. Node group one, node
1:21:01
group two. So it look like a two list. Right? I want to create first node group, second node group. So how we know is a list? Because we use hyphen.
1:21:10
So in this item you will put the information here. In this item you can put the information here. If you see everyone has a space equal space. it
1:21:18
will give less or more one space maybe it will fail. Okay. So you can think node group is one
1:21:26
uh array. Okay. And those who by chance know any programming language there's in
1:21:31
programming language you have multi-dimensional array or associative array or hashes or dictionary whatever
1:21:36
you know it is like a hashes or dictionary okay where they have first information
1:21:43
second information. So yl is a uh very generic way of formatting your
1:21:49
information providing the information okay it's not only for eks a lot of
1:21:55
devops tool in the market they use yl if you go for kubernetes purely or open safe or enible many more other also use
1:22:03
same syntax for yl the keyword will be different okay because node group is a keyword in
1:22:10
eks but this keyword does not make sense in in
1:22:15
in kubernetes or maybe in n enable as a devops tool.
1:22:22
Okay. So every tool or platform uses similar format called yl
1:22:28
but platform to parallel form like eks or open shift the keyword is different. So
1:22:35
from the keyword they come to know what we're looking for. Okay. So this keyword is more like more
1:22:42
like a function running behind the scene. So somebody create a function and
1:22:48
they give the function name node group. So now they come to know I want to set up the node group and what I want to do
1:22:54
set up a node group. They get the information here. I want node group with this name this type 10 instances I want
1:23:01
in this node group. Okay. So what a keyword you see here
1:23:06
like a variable but this keyword internally written by some developer that is mostly like a function running
1:23:14
somewhere and those function they write in one file and that file name they write here there's a file name also
1:23:20
known as APIs so there's a file they write somewhere inside this file they have the detail
1:23:27
about this function so that you don't have to know some developer has created for you our purpose is to use
1:23:34
Okay. So in the simple term if you want to launch
1:23:40
if you want to launch
1:23:45
cubernetes cluster with EKS EKCL tool we use sometime also known as EKCTL cuttle
1:23:52
or EKCTL whatever you say. Uh then if you use YML so through the YML we are
1:23:59
sending the instructions. I want this, I want that. So technically it is known as
1:24:05
declarative language. We are declaring declarative
1:24:11
language. We declaring what we want. How you do that? You know you're intelligent
1:24:16
in it. You know how to launch the node group and the cluster. But what I want I
1:24:21
will tell you and how I tell you by writing this or by writing uh this.
1:24:28
Okay. So guys this is a very quick information about the viml and uh about
1:24:34
this file. So technically I'm trying to tell you those who by chance does not know yl syntax. So this is how yl we
1:24:41
write. So yl is a way to dis to tell someone or to declare someone what we're
1:24:47
looking for. Okay. And we declare here we launch in I want to launch in region this one.
1:24:54
Many more thing we can write. Only thing is you should know the basic
1:24:59
syntax of that I have quickly explained to you. Otherwise as we pro more progress I keep on showing you more
1:25:05
syntax and more and more I show you more and more practice you become comfortable on the uh yl syntax.
1:25:14
Okay. So now onward guys I will prefer
1:25:19
not to um launch cubernetes cluster with a command line.
1:25:26
Okay, it can launch if you want but you can't do much changes
1:25:31
but with the help of IML code there many more advanced settings you can do.
1:25:38
So if you see here in the left side, okay, there are lots of settings you can
1:25:45
configure. Okay, do you want to connect with EMR cluster is a Hadoop big data.
1:25:53
Okay. Or do you want to go for registering with EKS uh connectors or
1:25:58
maybe you want to do a node go custom DNS and many more thing we have or you
1:26:05
want to go and do some setup for secured in KMS or you want to do some setting
1:26:11
for networking VPC subnet IM okay means the point is you're going to
1:26:18
launch a Kubernetes cluster in AWS Okay. So you can tell everything about
1:26:25
the not the manager node or control plane about the worker node
1:26:31
what how much of memory you need which policy role we give
1:26:37
okay how much resources we give RAM we give security will provide networking setup will do for you
1:26:44
okay so they have a very fantastic document here as I'll go and through lot
1:26:50
of concepts in upcoming discussions Okay. So this level of settings,
1:26:57
okay, is not available in the command line. That's what I'm trying to tell you. But initial go is good to go for
1:27:02
the command line. Otherwise, we will focus more in this code.
1:27:07
Okay. So what I'm going to do by the meantime because after the cubernetes launch I'll show you how to uh use the
1:27:14
cubernetes cluster very quickly even though it's not cubernetes training but I'll show you some of the basic command
1:27:21
intention would be to make you comfortable with the cubernetes so you can do something on the cubernetes
1:27:26
second intention is by those command line by those command line um
1:27:33
you I can show you the intricacies of EKS services with AWS other services
1:27:40
like EBS or ELB load balancer and many more that's also I will tell you right
1:27:46
so by the meantime to save our time right now
1:27:52
again if I go back to my this setup my EKS cluster is still there and now if I
1:27:58
see the node group some difference was there okay what you will see Here
1:28:06
you will see here that uh because we asked them to launch three instances
1:28:12
three instance they're launching with this type okay minimum and maximum is this one
1:28:18
this will I'll show you when we go for automatic scaling what are this we'll discuss and this is the managed
1:28:26
so worker node is all managed so anytime any patches or whatever they want to do
1:28:32
they will do for you for us they will manage for us. Okay. So that's what you
1:28:38
can see the details here. So what I'm going to do right now, yeah, it's done, right? So let's go for the
1:28:45
demo. So cluster is up. Okay, is active. That's also they
1:28:51
showing you that point in time. Now it's become active. Okay. And according to our setup what I
1:28:58
can see three desired cap we have because we asked them to launch three. So it means in the EC2 right if I
1:29:06
refresh now you can see three instances going to come up and you can see that we
1:29:12
also define the name right in my command line we have defined uh the name of my
1:29:20
instances the same name going to come up okay and if you guys have 1 a 1 b 1 b
1:29:27
they use because node group 1 c I told you that does not use why because the
1:29:32
type is the type is T2 some max name that was not supported 1 C.
1:29:39
Okay, this is one thing. Second thing is there's a worker node and if you notice
1:29:45
in the worker node okay if you go to security
1:29:51
okay and you guys know uh every uh worker node is a EC2 instance and every
1:29:57
EC2 instance is uh is u kind of attached
1:30:02
with firewall that's called security group and if you guys see the there's
1:30:08
two security group attached so if you click on this security group.
1:30:13
Okay. And if you notice SSS is enabled, right? Means we can connect to this instant via
1:30:21
SSS from anywhere in the world. Allow SS. Why is there? Because I told you in
1:30:26
the command line I want SS access and that is reason they allow the firewall
1:30:32
and that has the keys also. Okay. Otherwise if you don't write this option they don't allow the firewall and
1:30:39
not the keys also. Okay. So this is one thing. Second thing
1:30:44
is second thing is uh maybe uh Walmart some more thing.
1:30:52
Yeah see that is guys this key also see here key pair. So this instances they attach this key
1:30:59
and those who by chance does not know this but if you want to access any
1:31:04
instance we have to attach a key this called public key
1:31:10
okay and and whoever had the private key who can that these guys can login so my
1:31:16
laptop has a private key I can log into those instance but that is this public key here and this public key I uploaded
1:31:23
here okay you know I uploaded here by this keyword they take from my system
1:31:28
only okay and that's what they uploaded here in this location you can see also
1:31:37
here this is what I uploaded so if you try to uh check this public key okay
1:31:44
from here after download maybe you can see this is same public key that you have in your local laptop public key not
1:31:50
the private key private key you belong it belongs to you so it means if any instances is uh if
1:31:57
you want to login two thing you need you need a key attached okay and second thing you need uh
1:32:04
firewall everything been set up here because of this keyword
1:32:10
it means from my laptop I can connect to this instance which
1:32:16
instance any of these instances on the public IP over
1:32:22
on public IP okay Mostly the username may be issued to user. I don't let me
1:32:28
check. So they say yes or no guys connected
1:32:33
right? Why are they connected? Otherwise they won't show you this line. It's because we have firewall
1:32:38
and we log in. Uh right now guys uh they will show you this message mostly
1:32:44
because of the permissions. So either you can change the permission or we can use git bash. So one so one more command
1:32:51
line tool I have in my laptop that you can download from the internet. Okay.
1:32:58
So sorry.
1:33:04
So get B is one command line tool that mode give you look like like Linux
1:33:09
command line. We can now can see landed right. So I forgot this.
1:33:16
So from my laptop I lend it to the worker node. All right, because EK
1:33:21
service is serverless for the major node, right? You can see guys, there's no measure node visible here because
1:33:29
node they're running inside somewhere and they never give the access to you because they're fully managed.
1:33:34
Worker node is not fully manage managed. What I mean by this it's so your portal
1:33:40
maybe you want to do some changes your own you can do it and that is one of the reason they show you here plus they give
1:33:47
you access also. So I'm right now I'm inside the worker node this worker node over here. Okay. But all the things
1:33:55
whatever I need to do on the worker node they given to you. For example
1:34:01
for example in the worker node they give you pre
1:34:06
uh pre uh software for the for the worker node.
1:34:12
For example I told in the worker node we need container engine.
1:34:17
Okay. So if you see here uh if you see here uh docker is not
1:34:25
there. All right. Podman if you know is not there but if you see the process
1:34:31
okay ps command will show you all the processes. And here you can see container d engine is running.
1:34:39
Okay this container d. Okay I told you.
1:34:45
Okay. If you want to launch a container, you need container engine. Either you
1:34:51
can use cryo or the container D. Okay.
1:34:56
So here I told you in EKS they use content D as a container engine. What a
1:35:03
container engine on the top of container engine we run a container. If it is not there
1:35:10
contain won't be possible. Okay. So that's what they give you here.
1:35:16
Who set up this? Who set up this EKS for you? Otherwise
1:35:21
setting up this and there many more things they set up. As we progress, I'll tell you about these container engine. I want to show you it is there running
1:35:27
already processor running. It means in the future when we launch a container
1:35:33
with Kubernetes, they will take the help of this guy and launch in this worker mode.
1:35:38
Okay, this is one thing. Uh one more thing I want to tell you guys again this training is not about cubernetes neither
1:35:44
about container. Anyone who have known knowledge of container. So I have one training available in IIC connect is our
1:35:51
YouTube channel and if you search for docker is a YouTube channel here where I
1:35:57
have uh provided is free training obviously in YouTube. So here uh we have a detailed discussion of docker from
1:36:03
very basic to advanc. Okay. And um a lot of information about containers and how
1:36:10
they work, why they fast, what is happening behind the scene is is over here. So if anyone want to know know
1:36:16
complete series of docker, you can learn from here. If you have no idea about containers or the docker
1:36:23
concept is same. So those content information whatever learning here in docker same thing apply in content also
1:36:31
or we can get the idea of how content work also work. Okay. So this is one thing. Yeah. But
1:36:38
finally work or not come up as per our requirement. Okay. Many more thing we will see about
1:36:44
it. But I just want to show you very quickly they are launch and manageable. Right.
1:36:51
And if you just click on this connect for example I connect here and if you click on this connect
1:36:57
and if you go to instance connect and use the username let's say EC2 user because this is what the user um they
1:37:04
give you. Okay. And if you click on the connect
1:37:11
connect so you will see it is also connected here. Right. So without using SS also you can
1:37:19
connect by this way. This also one facility AWS has but it connect because
1:37:25
of this keyword. Okay. So we can I can also kind of work
1:37:31
on node by this graphical tool also because of enable SS.
1:37:36
Okay. So my point is we launch a work or we decide what we want by the command
1:37:43
line or we decide by this kind of YL file that's what we see in upcoming
1:37:49
classes we use YL file all day so I just told you guys what happening behind the
1:37:54
scene but main thing is okay technically we don't have to go here much
1:38:00
and go inside this but we can go but we don't have to go much okay finally cube
1:38:06
Kubernetes has been launched by EKS little command by a service called EKS. Okay, with master and slave. So let's
1:38:14
say this is your entire Kubernetes cluster running. Now we can hand over
1:38:19
this Kubernetes cluster to our IT team who is going to use it
1:38:26
and why they want to use because they want to launch app.
1:38:32
Okay. So for this when we launch the
1:38:38
cubernetes they give entire detail in this file that I told you already.
1:38:45
So this file contain everything about where the cub is running and all the things over here. Okay. So my team I can
1:38:55
give this file and they get the IP address and the login and password how to connect to
1:39:02
Kubernetes. Okay. But only thing they need now guys role of EK is complete. We have a EK
1:39:10
service launch Kubernetes. Okay. Now the role of the IT team who want to use it.
1:39:16
The user of Kubernetes come in play and use Kubernetes user use a command called cubectl. That's what they use.
1:39:24
This command has no relation with AWS or EKS. And yesterday I already downloaded this command. Okay. So one of thing this
1:39:32
command I can show you. This command will show you the cluster info.
1:39:39
Okay. So they will tell you Kubernetes master node is running. By chance here
1:39:45
you can see the IP address of master node by chance. Technically you can't see as such the
1:39:51
master node running here but by this command we are connecting cluster and ask you where the master
1:39:59
node is running because finally whatever you u
1:40:06
who the user of the kubernetes technically internally you connect to master node only. So in the kubernetes
1:40:11
we have master and slave. So because we always connect to master only. So this
1:40:16
command will fetch the information or tell the information where the master running somewhere in AWS obviously.
1:40:24
Okay. Otherwise we can see dump option also here that we can see here also
1:40:31
that will give you some more very detailed information about this cluster. So you want to see
1:40:36
the entire information of this cluster what is happen what is there already many more thing you can see here not
1:40:43
these many information right now might not need but one thing you can see here in this cluster we have a node at this
1:40:50
IP address okay and many more things right it will
1:40:55
show you right now it's not required to know okay to make a simple command so qctl
1:41:03
have a command called get so those who know Kubernetes or Bychant does not know Kubernetes. So in the Kubernetes there
1:41:11
are lots of thing we have and any information you want to see and read we have a get command cube shield is always
1:41:17
we write get command we use for read and I want to read what node information. So
1:41:23
in in my cubernetes how many node we have?
1:41:28
Okay mostly they will show you master node worker node both but here guys EKS will
1:41:37
hide the master node from you because they are managing fully so they only showing you the worker node. So these
1:41:43
are the worker node. Uh if you are managing your own kubernetes then you can see the master
1:41:49
node also. Here in the role you can see master manager node. Okay. But in case that you does not see
1:41:56
the detail of master node as such because they fully managed as a kind of serverless.
1:42:02
So these are uh worker node and this worker node.
1:42:07
Now interesting thing is you don't have to go to AWS. Okay. Uh Kubernetes team can see the
1:42:15
worker node details. Even the one of the worker node is this one. This one three nodes we have we can see here.
1:42:21
Okay. And the three worker node get command will give you a summary of the nodes but you want to see the describe
1:42:27
detail of it. So there's a describe command we can use and then what I want to describe for
1:42:33
example I want to describe this this system. So here we can give the name which I
1:42:39
want to describe in detail. Okay. So here this node
1:42:45
they describe in detail. Okay. And this entire information going to come up. Okay, one thing they show
1:42:52
you here is okay that this node
1:43:00
a lot of things they show you this name of the node is using T2 extra large
1:43:07
belong to this node group belong to this cluster okay in AWS they're using ondemand
1:43:14
service there's a lot of way we can get the uh instance in as logo spot
1:43:19
instances and dedicated host They they use on demand they using this AMI
1:43:26
they earning in 1A okay and they use base Linux OS a Mumbai
1:43:32
region they use one a they launch second thing they're talking about this instance is having this internal or the
1:43:40
external IP address this public IP so maybe uh this is what they're talking
1:43:45
about 23 is the instance they are having
1:43:50
Okay. And if you know about AWS, they'll normally give up two IPs. One is public IP and one is private IP. So they're
1:43:56
showing you this is the private IP also. Uh they have 147. Why 125? We might see
1:44:02
in the future when we need it. But this is the IP they're showing you. Okay.
1:44:08
About the instance plus they're telling you uh they're using the container runtime not cry.io is container ID.
1:44:15
Docker is not the runtime. Okay. Or container engine I can say.
1:44:20
Even though whoever who print this message in this command line they might does not know properly but this is also
1:44:26
not the runtime the right term will be container engine should be right term here whoever print this message in this
1:44:33
command runtime is actually C run or run C. So what are those? Again we are not purely in the container classes. So I
1:44:39
don't want to discuss. Okay. Interesting thing is the provider ID.
1:44:46
So who is the provider of this node? AWS cloud from where in 1A.
1:44:53
Okay. And who this instance ID aa this.
1:45:00
So this instance is the one who is a provider. Provider means who give this node to me. AWS gives, Azure give,
1:45:07
VMware give your own bare meta system give. So provider means who give this
1:45:12
AWS give this uh worker note to me. Okay. And many
1:45:18
more things they have. Okay. Um that's all this is also
1:45:25
sometime useful allocated resources in this node right now. Right. Right, we
1:45:30
have some RAM and CPU out of this 8% CPU we're using right now or around
1:45:37
around 0% maybe or 140 MB RAM. I think we have given 8 GB RAM to this guy. So
1:45:44
this much RAM we are using at this point in time because nothing we launch much. Okay. So they're also showing you and
1:45:51
this live status again if you run it might change if they change there
1:45:57
right. So it might be changed maybe if if we use more or less. Okay. And this
1:46:04
also u the information that is very important. I'll show you the use of it.
1:46:09
Okay. But right now they say not already ready to use means we can use this node in a cluster.
1:46:18
Okay. But if a node have some issues some error so this will tell you this go
1:46:25
events. So what happening this node what is happening in this node everything they
1:46:31
show you in the events. So guys this is purely the cubern thing but this come help you a lot.
1:46:38
Okay. So let's come to our main part. I just want to show you very quickly. So technically
1:46:45
we don't need to go for as cloud. Everything we can control from here. Okay. Two things we can control. Setting
1:46:52
up the entire Kubernetes we control with EKCL command and after Kubernet launch
1:46:58
whatever you want to do in the Kubernetes in the container world we can control with cubectl command. Okay. Now
1:47:07
what I want to do here so my plan is something like this. Let's launch some app so that can we can feel this
1:47:14
cluster. So the way I explained you guys Kubernetes yesterday, okay, why we need
1:47:21
Kubernetes, okay, let's say this entire Kubernetes
1:47:27
setup or the cluster or the platform so that I can launch my app here.
1:47:34
Okay, app here. But if you want to launch the app, you
1:47:40
know what you want. Okay, you want a OS operating system like let's say Linux
1:47:46
and on the top of operating system you need some server services who will run
1:47:51
your app. This also sometime known as runtime
1:47:56
and then on the top of this you have to put your the code of your app in PHP or
1:48:02
Python or Java and run it. Okay. So these three things you need
1:48:08
right minimum obviously you need hardware also
1:48:14
physical hardware RAM CPU but a software perspective because OS is
1:48:20
software software you need these three things right so normally what we do guys
1:48:26
if you want to launch OS services and app in the container
1:48:33
world those who buy doesn't know container so what we'll uh very common practice is this entire
1:48:40
package this called software we copy in or we bundle in in one box or
1:48:50
one software and that is known as image actually mostly known as container image and they
1:48:56
also very commonly used in the market called docker image
1:49:02
okay so those who know how to create your own container image or docker mesh
1:49:07
they can create your own. So if you go through this training of docker mind what I was talking about there I have
1:49:13
one entire complete uh class on how to create your
1:49:18
own image this container image. Okay the point is
1:49:25
the point is yeah if you know about AWS for example I think everybody know about AWS basic. So in AWS EC2
1:49:34
will give you RAM and CPU but on the top of RAM and CPU or hardware
1:49:39
what you want you want uh some OS to be launched. Okay OS content again same layer you
1:49:46
have a base OS plus your some services or maybe your app or code. So from where
1:49:53
we take we take from AMI AMI again your OS image or image from
1:49:59
AMI we launch this. Okay similarly in the container world
1:50:05
instead of the AMI we use a container image.
1:50:13
Okay from the container image we can launch this OS and you guys know in the in the container world this is known as
1:50:19
container. But because you are launching this container
1:50:24
okay with the help of Kubernetes. So Kubernetes use a term called port.
1:50:31
Okay we port. So my point here is what I'm trying to tell you just I'm just giving this information those who are
1:50:37
very new in container otherwise there's nothing very technical. Okay. So
1:50:42
whichever app you want to launch you need a container image. Either you can create your own or you can find lot of
1:50:49
content image available in some public website. One of the famous one is called hub.docker.com.
1:50:57
Okay. Where you can find lot of images. Some of the image I have copied there in my account with 13. This is my account
1:51:03
ID. Okay. So here I uploaded a lot of
1:51:09
images. Okay. So this is the one of the image uploaded. I have great great download 1
1:51:15
million. That's nice. Okay. But if I click here,
1:51:21
okay, this is the name of the image. It's more like AMI but is a container
1:51:27
image. What this image contain OS plus some
1:51:32
interpreter or web server in my case PHP interpreter and on the top of this I put some basic PHP site.
1:51:41
Okay, it's called app. So this image is good for testing purpose. So I'm going to use this image.
1:51:47
Okay, that's what my plan is. You can also test with this image if you don't know how to use it, how to create your own. Okay, so let's do uh how to do
1:51:56
this, right? So I want to launch the app from this image and I want to give one
1:52:01
more vocabulary here. Okay, here uh if you want to launch a
1:52:08
app that is now when I use the word app now onward I can use the word container
1:52:13
or when I use the word container instead I use the word called port. So I want to launch a port.
1:52:21
Okay. And launching the port in the Kubernetes.
1:52:26
Okay. How you launch? You launch from the image. Which image? This one. Or we can use
1:52:32
anything. Okay. So launching the image. So launching the port from the image. This
1:52:39
consists called deploy or deployment. So I didn't deploy anything yet. So I
1:52:47
can ask my Kubernetes command that I'm the Kubernetes user. I have the cluster connected. How many ports I have? So get
1:52:54
command we can see. And if you notice here I I have no port running at this point in time.
1:53:01
Okay. So if you want to launch a code then in the Kubernetes we have a create
1:53:07
command and here you can say I want to deploy something that's called deployment
1:53:14
I want to deploy from the image which image this image or use something else
1:53:20
also this image okay and I want to deploy and because
1:53:26
you can deploy multiple port multiple apps so every deployment you give a name let's say I'm going to give a name
1:53:32
called my web. Okay, that's all.
1:53:37
So what happened when I run this command? I am the cub user I my my uh
1:53:44
the way I explained to you. Okay, from this command I contacted
1:53:50
Kubernetes and asking to launch a port somewhere.
1:53:56
Okay somewhere where they launch and now it's a complete headache of
1:54:03
headache of cubernet is mastered with the three worker node they can launch anywhere that will be their headach right
1:54:11
sorry enter now you can see this deployment created
1:54:16
and now if again you go to ports you can see your application like last time was not there but you can see this
1:54:21
application what a name I've given there's some random number they give you and they start creating the container.
1:54:28
Okay, technically it look like it is port but they using the word container and in some second you will see it will
1:54:34
launch the launch even the first time they take some
1:54:40
second extra because they this image they download first locally and then
1:54:45
run. So first time it will take some second but otherwise when you launch one more time in the future okay they're
1:54:51
very quick within less than second they launch for you. Okay. The beautiful thing is
1:54:58
beautiful thing is again if I explain the setup what I explained you yesterday. We have the master in my case
1:55:05
we have three worker node. Okay. We as a user does not know how
1:55:11
many worker node we have or maybe we can know but we does not require to know any other things right. We are just sending
1:55:18
as a user the requirement to the Kubernetes Kubernetes
1:55:24
that I want my app to be launched from this image or port to be launched. Your
1:55:30
master will decide okay will decide where to schedule it
1:55:35
where to launch it. So on the fly they might feel this is a work or not B work or not C work or not. They might decide
1:55:42
let's say launch the port in C. So this food or the app they launch what do you
1:55:47
see here maybe in C. Okay, where the launch uh we can see
1:55:54
also from here for example in cubectl I can see all the nodes we have
1:56:00
three nodes we have but if you want to see this port where the launch so there we can pass one opide
1:56:07
oh wide option they will tell you this d little bit more in detail
1:56:14
okay so what they show you here is this particular port is running that's nice but they launch in a node mode called
1:56:22
254 this called 254 this one
1:56:27
okay who launch cubernetes master launch and then master just a name I told you
1:56:33
yesterday there's a lot of program running in the master the main program who decide where to launch is called
1:56:38
scheduleular cube scheduleuler so this is the program running in the master somewhere okay this is the one who
1:56:44
decide by some kind of planning and logics right that that's called algorithm they have to launch
1:56:52
Okay. So that's what done by master they launch here. Okay.
1:56:59
One more thing we can I want to show you here is one thing I told you about yesterday is uh cubernetes one of the
1:57:06
main key of Kubernetes fault tolerance. due to any of the reason this entire node goes down.
1:57:15
Okay, entire node goes down or maybe this could fail terminated accidentally
1:57:21
maybe. Okay, as a IT operation team, we don't have to worry about Okay, as operation
1:57:28
team, we don't have to worry about Okay, Kubernetes will handle this.
1:57:34
They handle this. Okay, they keep on monitoring the port will launch. They keep on monitoring
1:57:39
every second or less than a second. As soon as they delete it, automatically they relaunch new port. Maybe the system
1:57:47
in the same system or maybe here maybe here where they find better reliability would be the launches. So any fault
1:57:53
happen they will tolerate automatically. So fault tolerance happen automatically and anything that will fail automate run
1:58:00
that is also known as resilience. So this setup what cubernetes give you and this community we launch with EKS
1:58:06
there's a different point but give you very highly resilience uh setup. How can I show this? Right now
1:58:15
this board is running guys. I intentionally delete this port. So we have a command. So if want to read
1:58:22
something get if you delete something then we can say delete. What you want to delete? Node or port many more things. I
1:58:28
want to read port which port multiport we have. We have to give the name.
1:58:33
Okay. And if you notice guys this port they have given this name W something something with four minute ago they
1:58:39
launch. But if I delete this guys as soon as delete automatically they launch one more without asking. See here they
1:58:47
launch one more. Okay. Initially take some time.
1:58:52
Why? Because maybe this time they're planning to launch other node because where whichever node they they launch
1:58:58
first they have to download image. Image little bit bigger in size sometime. So it takes some time to download. This
1:59:03
image size would be maybe some MBs. All right. 100 200 MB maybe.
1:59:09
Okay. But if image is already there, it will within a second as you delete or
1:59:15
something happen, they'll launch. It won't take much second. But if you see here new, they launch. I does not ask them to launch. They're monitoring as
1:59:21
soon as I delete they launch a new one. So for those who know Kubernetes is a
1:59:27
very basic thing you know I might know but I'm just trying to explain the one who are new in cubernetes. Now if this
1:59:34
time this time this might launch in different computer last time is what different
1:59:40
node now they're launching different node okay again they will launch uh one more
1:59:47
uh point so technically this is a container running okay and one more thing you can do if
1:59:53
you want to know more about the container so you describe so anything you want to describe detail so I can say
1:59:59
in the port that I have with this name I want to describe more in detail.
2:00:05
Okay. And from here you come to know we are running this port.
2:00:11
Okay. And uh we are running this port with a engine called containerd
2:00:17
from this image that what I given. Okay. And uh this image we actually direct
2:00:23
from web docker website. Okay. And this image is so this container is assigned
2:00:31
to this computer. So in the event we can see some scheduleular you know cube scheduleuler
2:00:37
schedule this container container or port to this computer.
2:00:44
Which computer? This computer that we can see here.
2:00:52
Okay. And finally I told you guys initially they download the image. So it would take some time otherwise they
2:00:58
already download because they download only once. Now in this node we have this image already there. So next time when
2:01:04
something happen and we launch the content there again they will launch very quickly.
2:01:10
Okay very quickly. I want to tell you one more small vocabulary here. Okay
2:01:15
this is master and this is independent computer. just go work on node
2:01:22
Linux but how master nodes keep on communicating work on node how they keep
2:01:27
on monitoring this food and many more thing they keep on monitoring or keep on communicating so what happened guys in
2:01:34
the worker node we installed one program that's part of cubernetes program and we
2:01:40
install this program in all the worker node and this is a program that is one who keep on communicating the master and
2:01:47
this is a program that will first time register with the master and I am the work on node. I will help you.
2:01:53
And name of this program that we installed in all the work on node is called cubelet.
2:02:00
Who install? Because this is more node is managed by EKS service. So EKS will
2:02:05
manage this install this program and register this program to the master node right that's what we can see mostly in
2:02:13
cubulate cubulate. So cublet is in the work in this worker node down image is they are the one launch the container.
2:02:20
So master node actually is sending the instructions to the cublet and say I decided to launch port in you. Now this
2:02:27
entire respons to download the image and launch the container keep on telling me if something fail
2:02:34
I can take the further decision on it. So cubin is one program run on all the worker node one only one program they're
2:02:40
on the worker node that easy reason guys when I go to worker node this is a worker node right if you see the process
2:02:47
again you can see content also running
2:02:52
but there's one program running here is called uh cublet you will see
2:03:00
somewhere cublate program is also running here only one program per worker node
2:03:06
Okay, per control they're running. So that is also one uh point to it's not
2:03:13
the new thing those who know cub is very basic part but I just trying to give you information here. Okay, this is one
2:03:20
interesting thing. Now one powerful demonstration I want to show you.
2:03:25
Okay, very powerful demonstration. Before this I want to add one interesting concept. every port is equals to let's say
2:03:34
there's a port is equals to
2:03:40
one OS and every OS guys has their own personal IP address.
2:03:49
Okay. So if you want to see what is IP address of the port.
2:03:54
Okay. So in the port if you run o wide here they tell you the this port has
2:04:00
this IP address okay this is the IP of this port this OS
2:04:08
okay point is from where they get this IP address
2:04:14
okay that's one very interesting point right where they get this IP address
2:04:20
okay if I launch so many more port they also have their own IP address just to quick demonstrates right I want to
2:04:26
launch one more port so for this I use the same command I want to create one more deployment
2:04:34
okay let's say D1 is the name and from the different
2:04:39
image so there's one more image guys available on docker many more you can find is httpd is image that has again
2:04:47
some basic estimate page deployed already just for testing purpose so one more port I launched
2:04:56
Okay, they're again downloading it takes some time initially for the launch. But here this port also have IP address.
2:05:06
Okay, by chance this port launch in different node. This port D1 launch in
2:05:12
different node. Who decide your cube scheduleuler? But they have the IP address.
2:05:17
They have the IP address. Okay, this is one thing. One more thing
2:05:23
I want to add. Right now guys, I'm in my local laptop.
2:05:29
Okay, in my local laptop for my local laptop. Okay,
2:05:35
if you notice guys, this port is running inside this instance.
2:05:43
Inside this instance. Okay. So from a local I can log into
2:05:48
this instance if SS is enabled. But if SS not is enabled, I can't log
2:05:54
inside this OS. But but SS enabled or not enabled to this uh worker node, I
2:06:03
can log into my pool directly directly from my laptop. So that is what the fresh given by
2:06:09
Kubernetes. Okay, for this in the Kubernetes we have a command called execute.
2:06:16
I want to log to my this particular uh
2:06:22
port and after login I want to take the terminal of this port is interactive
2:06:28
terminal. Okay. And I want to get a bash shell
2:06:33
of this. This is one command of cubit is client clip
2:06:39
command. Okay. So technically guys here I my
2:06:44
laptop but I lend it to my port. This is I'm inside the port. You can also confirm this the name they give you
2:06:49
here. Okay even though this port is running in one of my EC2 instance but they have the
2:06:56
SS enable or not does not matter. I can directly login to my port here. Why I
2:07:02
want to login here? Just want to show you this port is like a real OS right is a real OS.
2:07:08
They have their own IP address. Okay, see here this app brothers same
2:07:14
they will show you here this this pool right now guys the way I set up inside this pool I have set up
2:07:20
the web server you can see my web server is running here and here in this port or the OS I put
2:07:28
some PHP pages here where the PHP page I write some code where I write welcome to
2:07:34
viml web server and some please speak commands if config command I write
2:07:40
Okay. So I just want to show you this is like a real OS. The board is contain contained like a real OS where my PHP
2:07:46
application is running. Okay. This one thing one more thing I
2:07:51
want to uh uh check here is from this port I want to try to ping to this
2:07:59
uh this port. Okay. Ping to this IP address.
2:08:07
We have a connectivity. And guys believe me or not this is a very powerful thing it's not a small thing is pinging
2:08:15
pinging is the connectivity and by chance this IP address have running with some kind of website actually so I can
2:08:22
also curl to see the website
2:08:28
running on this IP address you can see this this port running with the website with it
2:08:34
works kind of things they come up right so I can able to connect so one port we can access to other port. Now
2:08:40
interesting thing is okay it's not small thing they have with this connectivity let me come out from this over board
2:08:48
okay what I'm trying to tell you that this is very very powerful concept okay
2:08:54
why is powerful let me explain to you okay you know what happened
2:09:01
if you know little bit about a little bit about container technology
2:09:09
Okay, if you have your one laptop
2:09:16
and there's maybe one more laptop, both are somehow connected to network
2:09:23
Wi-Fi. Maybe they have a direct connectivity, you can ping to each other, right? So let's let's say laptop
2:09:30
IP 1 and two because they have a network connectivity they can ping but in this laptop
2:09:37
IP IP 1 if you launch a container let's say here
2:09:44
okay and in this laptop also you launch a container contain different OS running inside this laptop
2:09:51
okay and if the IP of this content let's say 100 IP of this content let's say 200
2:09:56
00 even though this
2:10:01
container running inside this laptop, this container is running this laptop and both the laptop behind the
2:10:07
connectivity even they have a connectivity physical connectivity but by default behavior of
2:10:14
the container and the network they're set up is this container is not able to connect to this container. They don't
2:10:21
have a D connectivity or anyhow any other connectivity. This container
2:10:27
running in this laptop won't have the connectivity. The behavior of the container
2:10:32
technology does not matter container D or docker whatever you say here by default behavior is of the networking is
2:10:39
is not security. They have some B behavior those who know understand the concept of netting network translation.
2:10:46
Okay. So by behavior is okay uh this container
2:10:53
is isolated means they feel this is the entire internet they can't see anything
2:10:59
outside this they isolated nobody can come to this and this guy can't go out
2:11:07
similarly this guy is also isolated nobody can come in is nobody can go out
2:11:13
there by behavior we can change it but this is what they Okay, that easy I was talking about.
2:11:21
Okay, if you notice here, this container is running in IP 254. Different node.
2:11:27
Let's say this is 254. Second container or port same thing
2:11:33
running in 145. Let's say this is 145.
2:11:38
Okay. So, first container in my case having IP 64 here. Let's say
2:11:45
this is 64. This kind ID 121
2:11:51
okay 121. So here I want to show you the way the
2:11:56
cubernet set up here especially in EKS. Okay. Even though if you uh if you
2:12:03
launch cubernetes also by your own vanilla cubernetes you will
2:12:09
see there also if the two port running in different different node they don't have a D connectivity. If you try to ping by default you won't you will see
2:12:16
there's no connectivity even though if you go to pure kubernetes also the open
2:12:22
source one vanilla kubernetes you will see there they don't have a connectivity there this network
2:12:27
connectivity we can do something there but by default does not give you but in the ease who will launch a cubernetes
2:12:35
for you they give this facility okay what they give they do some kind of
2:12:40
network settings so that This two port or container can able to
2:12:47
communicate each other via networking. You can see here I had done curl also HTTP ping also everything they have the
2:12:53
connectivity they feel like they belong to same network. They feel like they belong to same
2:12:59
network. Okay. So guys in the container world if you give your port this capability
2:13:06
they feel they belong to same network. Maybe they're running different computers altogether.
2:13:11
Okay. But they give they feel they belong to same network. They have a direct connectivity. So this concept in
2:13:16
networking world okay especially in the container world here is called network overlay setting.
2:13:27
Network overlay setting. Okay. And if you launch your own personal cubernetes there also we can do
2:13:34
network overlay setting but we have to configure it. And for this there we have some kind of
2:13:39
drivers available in the market. or do the overlay setting. Overlay means
2:13:45
this container will somehow overlay come to this container different computer
2:13:51
have a connectivity some we have to do some driver we have to store there do it
2:13:58
okay and in container world if you want to do some setting in the networking world
2:14:05
okay so there's a concept we use called CNI container network interface CNI so
2:14:11
there's called CNI drivers available or the overlay and there's a lot of CNI
2:14:17
driver a de a de a de a de a de a de a de a de a de a developer guys everybody has different capabilities because networking is big big domain all
2:14:23
together what you want to do how you want to transfer network packets secure
2:14:28
or maybe some performance change or portal and many more things okay so if
2:14:35
you just search very quickly about kubernetes cni
2:14:41
uh drivers or providers So there's a plug divert also known as plug-in here.
2:14:48
Blender is one famous name. Calico is the one name available in the
2:14:54
CN world right. So but you can see many more name
2:15:00
available this network plugins or the driver. So my point here is
2:15:07
I'm just trying to give you vocabulary here again but but in a vanilla cubernetes you have to set up the
2:15:12
flannel or the calico driver even though if if you guys go through my cubernetes classes uh of ck cg there I one chapter
2:15:21
on it where I show you how to set up the driver for overlay okay it takes a lot
2:15:26
of time but we can set up it okay so if you very quickly go and see there lot of
2:15:33
CNI ever who can do this setup for you and there's a uh for this runtimes either
2:15:41
for cryion content okay and if you see some name here
2:15:47
uh they might show you this is the cubin official website
2:15:53
okay and if you see the network providers okay so you will find some name of the
2:16:00
site driver so just go and find somewhere there's a page keep point changing over there right but
2:16:06
there's a lot of CN drivers available what I'm talking about right a point is
2:16:11
one name pl one name is
2:16:17
calico view many more
2:16:22
question is in AWS right now this cluster running with EKS and the two port able to
2:16:30
connect to each other maybe they're running different computer and host independent right there's a possibility
2:16:36
also they're running at a different data center also 1 a 1 a 1 b
2:16:41
even though they're able to connect communicate means AWA has use some kind of plug-in or the driver
2:16:48
so which plug-in driver they use so AW has their own personal plug-in actually they use here
2:16:54
okay and this plug-in name what they use is called VPC plug-in
2:17:01
so they may mention somewhere here also maybe. Okay. So there a lot of plug-in
2:17:07
available in the market a lot of complicated their own plugins. Okay. So AWS is using their own plug-in. There's
2:17:15
a lot of list here. Maybe this their like for examp
2:17:27
plugin. No this not one. Maybe it's not listed in this list. maybe but AWS has
2:17:33
used their own plug-in here. This was CNI uh uh plug-in
2:17:39
because of this they have this connectivity. Okay, they're known as VPC IP or VPC uh
2:17:47
plug-in they use behind the scene. Okay, just show you knowledge I'm
2:17:52
talking about. But my point is you don't have to worry about this. This is what one of the one one of the feature they
2:17:58
give you in AWS cloud. Otherwise, if you search for AWS EKS CNI
2:18:06
plug-in maybe VPC plug-in, you can find some quick link VPC plug-in they they use
2:18:16
over here. So, this is plug-in they use. has been created by AWS for the Kubernetes
2:18:22
cluster that you can use in your personal
2:18:28
Kubernetes also we have a lot of many thing to do but here in EKS
2:18:33
okay uh they give you or any extra thing apart from the
2:18:39
Kubernetes these company provide to you
2:18:44
okay is mostly known as add-ons so they are the add-ons they give you.
2:18:51
So if you see in this ek page also maybe they can see some pages for
2:18:57
add-ons here. So e also a command through which we can see how many
2:19:03
add-ons we have. We can install the add-ons somewhere they give you some command. Okay I'll show you. Yeah, here
2:19:10
it is. Add-ons and add-ons command to C. My point is
2:19:17
okay is not a by default behavior of the cubernetes but but uh uh here let's get
2:19:25
hold for setting
2:19:46
So this is what they tell you. Okay. So they tell you about all the versions
2:19:51
they have and many more things. Okay. But this is again very interesting uh thing uh they have
2:19:58
over here. So this is the again is the command we can see uh that about the
2:20:05
add-ons VPCC and add-ons. So if you want to see
2:20:11
u with command also does we have any add-on installed or not. Okay. So this
2:20:17
is the as CLA command. It's not a EKCL command but this command also we can use
2:20:22
to see for example I open my command line tool and run this. And here I want to
2:20:28
describe add-ons for my cluster. In my case guys, we have created a cluster that what we can see with EKC only
2:20:35
because cluster things we can see with EK C command. Get cluster. My cluster
2:20:40
name is my basic cluster. Okay. And
2:20:47
basic cluster. Okay.
2:20:53
So describe add-on operation don't found in cluster. So maybe whatever the guys
2:21:00
would be defy add-ons or
2:21:06
so whatever the command will be maybe this but I show you with the with the ek command this command also sort of work
2:21:12
but maybe I have to write some role and maybe or I don't know something to do okay but point is it can describe how
2:21:19
many add-ons they have. I'll show you the EKL command. This command I have to again figure out what challenge.
2:21:26
Okay. And then maybe name different what I have right now with me. Okay. So point
2:21:32
is uh point is it look like very simple we are doing a connectivity lot of
2:21:38
networking thing happening behind the scene. You don't have to handle that's what I'm trying to tell you here is okay
2:21:44
don't have to handle and that easy reason guys whenever you launch a cluster in EKS
2:21:51
they launch one VPC for you what VPC so those who know AWS they know what is VPC
2:21:58
otherwise if you guys does not know what is VPC and subnet in AWS so I have my
2:22:04
recorded video um so those who are learning AWS under me right now CSA training we have to
2:22:09
provide this recorded video long back okay otherwise you we will provide to
2:22:15
everyone if you want but if you go to AWS cloud
2:22:20
okay u cloud and there's a VPC page here or VPC service here
2:22:27
okay if you notice guys whenever we launch EKS cluster automatically they launch your own
2:22:34
private lab that's called VPC mostly you see only one VPC available
2:22:40
but you can see there is two VPC available. Okay, this VPC automate launch by EKS
2:22:46
crale command. And what this VPC technically means
2:22:52
technically means here what they're trying to tell you here is they say whenever you launch your u uh EKS
2:23:01
cluster we will create our own lab networking lab or networking setup
2:23:09
in as world this networking slab instead of only a VPC.
2:23:14
Okay. And inside this VPC, if you launch any OS, maybe EC2 instance
2:23:20
or or uh port in Kubernetes, I will decide I will give the IP address to
2:23:26
this guys. And what IP address I will give? I will give the IP address of this range.
2:23:34
That's what you can see here guys. The IP of the port come from this range. It's coming from this VPC.
2:23:42
Okay, that's one thing. Second thing is uh this VPC guys, if you go and select
2:23:50
this VPC here, this is named 7763. Uh this one. Okay, every belong to so
2:23:59
some subnets. Okay, here they launch four subnets.
2:24:06
Okay, who launch EKL command for you? In every subnet they give a
2:24:12
range of IP addresses. Okay. And technically it look like this.
2:24:18
Those who know about again VPC and subnet and I highly recommend if you
2:24:24
guys missed the class of VPC just do it. Very important class. Okay. Those who are learning AWS we provide it to you.
2:24:31
Okay. So this is a VPC and VPC guys normally you can think VPC is a big
2:24:38
office and in the office you have a lot of rooms the room number one or room number two every room they have their
2:24:44
own network settings. So this entire office is known as VPC
2:24:50
and these rooms are known as subnet. Subnet one, subnet 2, 73, subnet 4. That
2:24:57
what you can see here we have four subnet and every subnet have their own personal range of networks.
2:25:06
Okay. And this range means if any computer put in this room these many computers we can
2:25:13
put means these many IP address we can provide. Okay we can provide it means in this
2:25:19
room finally my port my point is my port is going to launch either here or either here.
2:25:25
So port launch here. So what range we have the subnet will give from here
2:25:33
a port launch here. What range we have in the subnet we give here. Okay, we can give here. Now point is
2:25:41
guys, my point is it means in this subnet maximum number of port you can
2:25:46
launch is 8,186. There's a limit. Maybe you have RAM CPU
2:25:52
available in the Kubernetes but every port need IP address. So if
2:25:57
you try to launch a port more than this then you can see a port will fail and they give the error out of the IP and IT
2:26:03
IP range something you can get it. Okay. So that easy reason this is a
2:26:08
default setting guys they have done while launching EKS cluster they launch this VPC and there's four subnets with
2:26:16
this range but you have some specific requirement that while launching the EK
2:26:21
cluster you can decide what is your VPC or the name of VPC what
2:26:26
range you want to give total how many lab you want to launch okay and every lab subnet what are the
2:26:32
range or maximum IP you want to port will in the EKS cluster port
2:26:39
actually take the IPS directly from a subnet there the same location where your EC2 instance also launch
2:26:47
so in the same subnet also we can launch E2 instance okay so we launch E2 instance here in
2:26:55
this lab all right they will take the IP address from this range what are the IPs available so it look like EC2 instance
2:27:03
also running here port is also running here by chance port running inside issued instance only but I'm talking about individually issued instance if
2:27:10
you launch they will take the IP from this range okay so by chance if you know if you
2:27:15
launch a uh launch instances right
2:27:20
so when you launch the instances they ask you you're going to launch instance and in the instance which VPC you want
2:27:28
to launch so you can edit and now you can say you want to launch in this ones here This number will come up here and
2:27:35
this they have four subnets. Which one you launch this one? This must be available. This one this might be
2:27:40
available will launch then this is Essence will launch in this
2:27:48
lab and this is the same lab where some of my port also sorry. So technically
2:27:53
now both have a connectivity. The port EC2 E2 have the port connectivity has some requirement you can do.
2:28:01
It's also possible that this port running with the application and this application want let's say some database
2:28:09
so I can launch EC2 instance and my database I'll set up there the port running application they will fetch the
2:28:14
database from there or you guys also know in AWS we have RDS service
2:28:20
relational database services right so I can launch a port
2:28:26
in this subnet and RDS also So we launch there. So they have a connectivity because typically what happen the way
2:28:33
the VPC set and sub okay if if anybody
2:28:39
want to go outside come in they won't allow you within the
2:28:45
subnet they can communicate to each other but we can change also there's a different point so if you go to a VPC
2:28:50
classes I talk you there about how to go out or come in internet gateway net
2:28:56
gateway many more things we discuss there so again this is not the pure AWS class right now or not the cubin class
2:29:03
but I'm just trying to refer okay if you know does not know then go
2:29:08
to VPC classes you will get entire context but interesting thing is they have set up for us so we go go to VPC
2:29:16
class you know it will take a lot of time to set up this manually but what are the best practices they they feel
2:29:21
they have set up for you but if your requirement no I want to set up my own
2:29:27
VPC my own way own subnet we have to attach my own network gateway or internet gateway own personal security
2:29:34
firewalls in my EKS cluster
2:29:40
you can guys perform anything how with the help of this kind of yl
2:29:45
file so this yl file when we write now on word we will uh we will uh customize
2:29:54
everything with the uh one file
2:30:00
Okay. So that's what uh I just want to tell you. So Intelly they're using VPC
2:30:05
CI plugin over here. Now one more interesting demonstration I want to show you is very very
2:30:11
interesting. Okay, that is right now this port is running
2:30:18
then I can connect locally and see the output. But this code is running with application and I want this application
2:30:25
to be to be uh uh to be accessed by a public guys.
2:30:34
This internet guys you are listening to me online whichever city you or country belongs to you can
2:30:40
also hit this board and see my application my website that is typically known as expose.
2:30:48
Okay. So interesting thing guys here to know first of all the way I explained to
2:30:54
you port is a container container run in this one OS and technically nobody from outside this
2:31:01
OS can come in first of all this issue but this issue has been resolved okay so
2:31:07
that other computer can also come in why because of this Olay network plug-in CI
2:31:14
network plug-in that I told you already but second challenge is because all Those containers
2:31:22
are running the node and this node is running in this VPC and by default
2:31:27
behavior of the VPC if anybody try to come in come in anywhere does it not allow you
2:31:38
okay this is a challenge okay
2:31:43
so AWS perspective they give a way If somebody want to come in your own lab
2:31:51
VPC own network setup okay AWS give away and that concept
2:31:58
called internet gateway okay internet gateway so if you go to
2:32:04
VPC page VPC page
2:32:12
okay in the VPC there's a concept called internet gateway this will help
2:32:18
that anybody publicly can reach to this entire IP range they can connect
2:32:26
again beautiful thing is it has been created for us okay who created again my EKC it will
2:32:34
come out they create an internet gateway for us it means anybody with help of
2:32:39
this gateway like a router actually those who don't know router through which anybody can come from the public
2:32:44
world to this particular any of the labs and any of the computers
2:32:50
here this ports okay here but how they come how to create a port
2:32:58
okay is very one interesting concept we have to apply here okay and guys this is very
2:33:04
interesting demonstration what I'm going to show you my intention is you know what I'm to show you my intention is
2:33:10
is u is to give you access that you can see
2:33:17
my website because this is a final objective right why you are launching the code here so my public guys can access this
2:33:23
my public guys can access this application okay this is my entire my intention is
2:33:30
right okay but how can you access that's why I'm to
2:33:35
show you the command but before this I want to show you one more interesting concept the concept is uh what cubits
2:33:42
give you okay they say right now This application is running here
2:33:48
is running here. Okay. And this application is a OS running with app. Let's say this OS
2:33:56
running app here have some IP address also here. If you see this is the IP address
2:34:01
121. Technically if some client try to connect it
2:34:07
okay we have some limitation right means in one app at one point in time parall
2:34:13
connection is called concurrent connection we can't we don't have unlimited right maybe you have internet
2:34:20
bit better but it's all different application and the server we have a limit just for example let's say limit
2:34:28
is of the connection is 100 means At one point in time 100 client together can
2:34:34
connect. It means your application goes wild and more than 100 can come at that point in time they will see application down.
2:34:41
They won't see the connectivity. It's not good thing for the business right it
2:34:46
does not give a better name to the business. Okay that is what we want always. Okay, we won't always based on
2:34:54
the the research of marketing other things they will tell you or your team will tell you after analyze right they
2:35:01
say we have we going to have more than 400 clients
2:35:07
okay but we know one port can't have more than 100 connection how you know
2:35:13
your operation team can can tell you because by that some kind of testing or load testing they have some number going
2:35:19
to come up right so you can ask or load testing team they will tell you some basic number okay but point is let's say
2:35:28
maximum limit is 100 and there's possibility your your analytics team or
2:35:35
your kind of who is analyzing your data with some machine learning or something they say there's a possibility in excel
2:35:42
going on there would be more than 400 clients going to come up okay so what can we do we can launch one two three
2:35:49
four applications or four port of the same copy same four port of same copy.
2:35:56
So one can handle 100 100 100 100 100 or almost 400 connections total we can
2:36:01
handle. So whenever guys you want to create one more than one copy of somebody that is
2:36:07
called replica or replicas and if you have one copy you want to add
2:36:13
more more more you add more traffic you can serve more
2:36:20
uh client you can serve more load you can serve then it's called scaling this concept is called scaling
2:36:25
most known as scale out or also known as horizontal scaling
2:36:31
okay So um so um cubernetes has a great tool if you
2:36:39
want to scale it or replicate a replica of it then it's very very simple we can
2:36:44
do so there's a tool of kubernetes but what a can give to I'll show you in
2:36:49
a minute very very powerful thing a will give you but let's say we talk about kubernetes as a kubernetes
2:36:56
okay you launch a port with a deployment we launch a port with some deployment
2:37:01
Actually this is a deployment we use my web my web is deployment is the one who
2:37:07
launch this port because we create a deployment we launch a port with the deployment but I can say kubernetes do
2:37:15
one thing I have uh want to scale it I have a deployment that says I need only
2:37:23
one but I tell my deployment my web that I
2:37:29
want to increase my replicas plus to four that's all.
2:37:35
So one click as per the requirement within second your four port will launch here same
2:37:45
copy the different name different IP address but they belong to same image
2:37:50
same application they're running here okay within some second four port launch
2:37:55
for you four apps the launch for you so one can add 100 100 let's say 400 plus
2:38:00
the the header okay this is a cubernetes command pure cubernetes command.
2:38:06
Okay. And obviously they they will if you run the wide command you will see everyone
2:38:14
has their own IP address one will run in different node other different node different node different perode they're
2:38:20
running right but because of the uh if they want to communicate locally because they have a old network so they can
2:38:28
communicate if you want because sometime again we are not going for the duction if you know a little bit about
2:38:35
application normally application has to share the sessions or caches information. So we have some caching
2:38:40
layer. So I want my application can come to this one this one also. Okay. So if
2:38:45
they don't have a local connect with each other so some thing will fail. So I'm not going for that part discussion
2:38:52
right now. But my point is networking we require between this that what they give you by CNI driver.
2:39:00
Okay. My intention is different to tell you this command. So this is very common command if you know Kubernetes. So
2:39:06
deployment has a now four port everyone is running. Intention is different to
2:39:12
tell you this concept. The intention is okay if you're running replica or same
2:39:17
ellip application four time everyone has a different different IP address or
2:39:24
maybe sometime you see there's thousands of thousand port running. Okay. Um I do
2:39:30
remember if you see the u the Netflix case study
2:39:38
okay they are running more than one lakh around 0.1 million applications same
2:39:44
copy okay so having thousand thousand very very common
2:39:51
okay but everyone has own IP address so the client perspective
2:39:58
I can't give all thousand IP to client and say hit one if BG hit two hit BG if
2:40:03
three keep on changing client never happy with this so that is the reason we have one more centralized program come
2:40:08
in play you guys might know this and this program is called load balancer
2:40:14
and that has only one single IP address so we'll give only a client one IP
2:40:19
address that's what you see in Amazon or Google or Facebook you always have the IP of load balancer
2:40:26
okay but what happened when this client come to this when first client come we
2:40:32
this load balancer will connect to this this particular uh app when second
2:40:39
client come they connect this app third client come they connect this the third web come they connect this fifth 6th 7 8
2:40:46
so technically they're balancing the load that is in the normal load balancer program
2:40:52
okay so that's one thing right interesting thing is kubernetes has an own internal
2:41:00
load balancer. Okay, first of all, in the cubernetes
2:41:05
world, this load balancer is known as service. They also use SVC.
2:41:12
So if you talk about the Kubernetes perspective, Kubernetes has an own
2:41:17
service that's called load balancer that they have on they can create more also.
2:41:24
Okay. But that service or load balancer they
2:41:29
create with the help of program software. So softwarebased kind of load balancer and software thing guys is
2:41:35
limited with the with the limit of the OS where they're running.
2:41:41
Okay. So if the software of service is running in some OS this OS has limit RAM
2:41:46
and CPU and network they will slow down because entire client is coming via load
2:41:51
balancer. Okay, if load balance is down maybe run one million application behind the scene
2:41:58
to balance the load of millions of customer but lower balance is weak
2:42:03
not optimized for network RAM CPU where they're running not secure not reliable
2:42:09
thing will fail okay and here guys very powerful concept we have and the concept is
2:42:18
is uh because right now is Kubernetes right is running on the top of EKS service
2:42:28
and EKS is a part of AWS and AWS has very strong program for the
2:42:34
load balancer. This very very famous program very highly powerful and secure reliable and the name of this program of
2:42:40
AWS called ELB is a elastic load balancer of AWS. You guys might know this.
2:42:47
Okay. So we go for ELB again some part of EC2 service only.
2:42:55
So they have their own personal load balancer highly optimized.
2:43:00
Okay. If you see the a EC2 page this is load balancer I'm talking about.
2:43:07
So I don't have any load balancer set up here but we can launch the load
2:43:12
balancer. We click and launch the load balancer depend the requirement. Okay.
2:43:19
So for example, for example, if you want to go for very high speed load balancer, then we go for
2:43:26
NLB, NLB load balancer. Okay, if you have some requirement of uh
2:43:34
ingress uh uh setup okay, that's what we'll use
2:43:40
a lot in real examples like microser. Any more examples? uh just very quick information just for
2:43:47
example uh very small example if you just search for Google right and if you write less source so it's less source in
2:43:54
the last by looking at this URL uh
2:44:00
domain name is same IP is same understand you have to go to Google search
2:44:05
but same google.com same URL same IP address if you write Gmail for example
2:44:12
or mail for example by looking at this name they come to know you have to connect to Gmail.
2:44:19
Okay. So this very simple example this called ingress right. So
2:44:26
so in the big application world right ingress is very very powerful uh need
2:44:34
that application load balancer ALB will do application load balancer will do for you. Okay. And if I
2:44:42
want to do many more uh advanced setup, I want to observe it. I want to manage
2:44:47
the traffic. I want to uh encrypt the traffic between because right now if we talk about Kubernetes,
2:44:54
right? And you want between the pool you want traffic to be captured or to be modified or to be transformed to be
2:45:00
encrypted with MLTLS or monitor. Lots of
2:45:05
things is there in the if in the world of containers right thousands of cont
2:45:10
running all right if you talk about again awsamon.com right then then there's a concept called
2:45:19
service mass come in play so again this training is now about service mass where we have a powerful tool called stew
2:45:27
okay but in the bigger application without the service mass okay managing the traffic and kept interfing observe
2:45:34
the traffic monitoring the things between the port very very complex is very impossible right so there the role
2:45:41
of role of uh service mass come play okay
2:45:49
and one of the great tool in the service mass in the market called ste
2:45:54
of things they can do with this too and the related component right like Kelly
2:45:59
they have zu they have to do again why I'm going to this direction here. uh but
2:46:08
point is my point is lot of component we need uh
2:46:15
right component we need let's again come to a main area where I started okay so
2:46:23
that's a part so point is kubernetes they give load balancer service but they
2:46:30
are not so powerful scalable optimized performentoriented okay so what can we do okay what can we
2:46:38
do we'll tell my u kubernetes because you're running with EKS and EKS running
2:46:44
with on top of AWS and as this powerful load balancer
2:46:51
that is used by all the top balancing network load or traffic why not we use
2:46:57
ALB okay I know your Kubernetes ALB not part of you for you it is
2:47:03
external load balancer Okay, as a cubernetes perspective
2:47:10
why I node we use this. Okay, interesting thing guys is if you
2:47:15
configure your own cubernetes called vanilla using the external load b is very
2:47:21
challenging. You have to store again a lot of plugins and drivers. But here in EKS because we launch a
2:47:27
cuber EKS okay they have pre- setup driver plug-in available for ELP
2:47:33
you technically you don't have to do anything okay point is okay whenever you launch a
2:47:41
load balancer or the service in AWS that time I just said I mention one
2:47:46
keyword okay and with this keyword we can tell I
2:47:51
want to use I want to use ELB or Not just just tell this and beautiful
2:47:58
thing is okay we are using cubernetes but my entire traffic in the kubernetes to a
2:48:06
port will be go via elb load balancer of the AWS and second interesting thing is
2:48:13
u uh you don't have to configure it okay if you notice here this page is
2:48:21
my this page where I was of uh uh this one.
2:48:28
It's not even configuring load balancer, right? So those who know load balancer, you know, even though it's very simple, but take a lot of time, right? To
2:48:34
configure this load balancer. But you will notice guys, the entire load
2:48:40
balancer will be uh will be configured for you.
2:48:48
Okay. So summarize, let me summarize this what I'm talking about. lot of information I given to you but let me
2:48:54
summarize okay what we want I want my pool to be
2:48:59
have multiple copy at least a multiple copy to serve all the clients
2:49:05
all the clients but I need load balancer without load balance thing won't work nothing will
2:49:12
balance okay now from where we'll take the load balancer everything is running right now
2:49:18
in the AWS sorry in the kubernetes code and everything running in the cubernetes if you see here.
2:49:26
Okay. But what I can do, okay, I'll tell my cubernetes we are
2:49:32
going to launch a load balancer that's called service. But internally,
2:49:37
okay, this load balancer is come from outside world. This called ALB. This
2:49:42
called AWS high-end load balancer.
2:49:48
Okay. So this load balancer is full look like Kubernetes but actually in they
2:49:53
using ELB. Okay. And one more thing guys, if in the
2:50:00
Kubernetes if you're using some any external load balancer, then again you to install log drivers and setup, right?
2:50:06
But you don't have to do here. Why? Because we launched this Kubernetes with
2:50:13
EKS. They give you all the batteries included or setup included whatever we need mostly. We can customize there's
2:50:20
different point in my advanced training of um EKS right now basic is going on.
2:50:26
We'll talk about how to customize the way you want to customize but basic thing they give you preset up.
2:50:32
Okay. And that is what guys I was talking about initially. Launching the cubernetes is not a big deal. Having the
2:50:38
integration of other other services like VPC like ELB is what EK give you extra
2:50:45
support by default with a high uh with proper tested and proper high optimized
2:50:52
um high optimized way I I can say the best practices. Right. So let me show you
2:50:58
this demo. Okay. Now this command is very very interesting. I love this command actually. Why? Because I want this four
2:51:07
container of port to be balanced with a load called service and I want the
2:51:13
service to be exposed to outside world. So in the cubernetes those who know kubernetes this is very common command
2:51:19
we use. I want to expose my deployment name my web because this is deployment
2:51:24
who launch my launch my four port this ports.
2:51:31
Okay. And uh this is what I want. But I want
2:51:38
to create my own load balancer. This go service. Let's say my load
2:51:44
balancer service whatever name you want to give. Okay.
2:51:49
Those who know cub you know this command will create a service for you or the load balancer for you. But they use
2:51:55
cluster IP means the private load balancer used by the software is very
2:52:00
good working good but if the system has limited M and CPU or network they slow
2:52:06
down in the huge traffic and we're creating this setup for the big big setup right so that is reason we
2:52:14
can use one concept called type even though let me help take a help on this command and there's a guys option here
2:52:20
called type okay and Here we will use a tag called
2:52:27
load balancer type. This also known as external name.
2:52:32
Okay. So here I'm going to use a type that's called load balancer.
2:52:40
And that's all guys. Just by giving this keyword by this keyword.
2:52:46
Okay. We are telling to Kubernetes that you have some external
2:52:53
uh connector to the external load balancer. Just go and check they have actually ELB. So contact to ALB and I
2:53:02
want our service load balancer will be work as a by the ELB. I want to use ALB.
2:53:08
Right now it's not there but you can see automatically they create for you ALB. And one more very small thing
2:53:14
nothing very much important but this guys load balancer will always connect to the uh port application and
2:53:21
application guys always run some port number so we don't know which port number they're running so if 80 port so
2:53:28
to tell to load balancer where which port to send this request so to write
2:53:34
one more keyword here port 80 okay so those who know a little bit kubernetes or maybe open shift also this
2:53:41
is a very commonly used command we But this is the beautiful keyword we have. Just buy one keyword. You know
2:53:46
what happen? Just hit this keyword. Okay. And you will see in your in your
2:53:54
account automatically they start spawning the load balancer.
2:54:00
Okay. You will see one load balancer start see automatically with the best
2:54:05
practices. Okay. Okay. And if you run the uh get
2:54:10
service or load balancer command, you will see one new come up. And automatically guys, they show you the IP
2:54:16
address extra IP address. And this IP address
2:54:22
guys is the IP address of the ELP load balancer. So this is AWS load balancer.
2:54:27
If you click here, this load balancer have their own IP address. This is a public IP address. So this is the IP
2:54:35
address in my AWS account but is visible in Kubernetes world. This is pure
2:54:40
Kubernetes command but they can see it. They can see it.
2:54:47
Okay. See it. But guys if you know about load balancer it takes some second initi launch
2:54:54
because behind this load balancer there are three instance running. So they're not yet connected. So they're checking
2:55:00
the health of behind the scene. Now they can say very quickly they come up right. So those who know about
2:55:07
how to create ALB load balancer you know it takes some time
2:55:13
to set up sometime initial learning it fail sometime but very quickly they launch setup thing is working great
2:55:20
interfacing means anybody from the internet can access this okay access this uh this particular load
2:55:28
balancer okay now it means
2:55:33
if Anybody anybody who want to connect to my port
2:55:41
pores okay obviously they're running in the world of container nobody can come in
2:55:48
again they're running in the VPC world in AWS nobody can come in but without
2:55:54
any restriction now anybody who know this URL because we exposed this by this URL anybody can see my website
2:56:02
in this port so now When I hit this URL, you can see my website is up. See here
2:56:10
website is up, right? So this is the IP of load. Interesting thing is this IP is
2:56:15
public. I can give this IP to my uh my uh customers public one. They can see my
2:56:22
application. But internally it is the ELB IP address and all the power of ELB
2:56:30
you know they have a super powerful you can achieve ELB is again managed by AWS
2:56:36
more traffic come of the increase the network bandwidth limited kind of thing and thing will work okay and finally
2:56:44
they lended to this port and every port is a
2:56:49
different different uh system so if you and over wide every port is different IP
2:56:55
address intentionally the way I create my PSP application intensely I print the IP address of the port to tell you right
2:57:03
now maybe you use ALB or ELB for example imagine load balancer but finally you
2:57:10
lended to the port how I know I printed the IP of the port you finally lended to
2:57:15
by this port and I also want to show you one more thing all this port is balanced by load
2:57:22
balancer. It means if I refresh this page again one more time, you can see IP change, right?
2:57:29
It means you now you landed to this port. And who is doing this load balancing for
2:57:35
you? Load balancer. Which load balancer for the cubernetes perspective?
2:57:42
This load balancer internally. This load balancer is actually been uh el right. So if you
2:57:50
just very quickly describe they might show you something describe the service in detail.
2:57:58
Okay. So this is maybe not here in detail but internally they have some
2:58:04
driver running. I'll show you somewhere. Okay. So ingress means the traffic will
2:58:10
come via this load balancer and this load balancer has been connect to the
2:58:16
back end to 1 2 3 four ports. Which are ports?
2:58:22
These are ports. Okay. And again you press you can see IP
2:58:29
will change again. They landed 219 219 and so on.
2:58:35
And second interesting thing is now all this code is running in different different node and this node guys is
2:58:42
running in 1 a d center 1 b d center due to any reason
2:58:48
if your node fail your port will relaunch to different node.
2:58:53
Okay, if entire data center fail, AG fail again other AOS have a node available
2:59:00
because of node group. This was a rule of node group. They launch some instance different node uh node they launch some
2:59:07
node in the different ages different ages. So entire ag fail
2:59:12
because some natural disaster or climatic or conditions may be then a still my other worker node there
2:59:22
and they are running okay and uh and uh and my entire pool will be launched over
2:59:29
there for the technically for the client perspective whatever kind of damage going to happen right even though I can
2:59:35
give this URL to you also in your chat message because it's a public so you guys can also So uh
2:59:44
also connect this and you can see every time you refresh the IP will change. Sometime you might change because from
2:59:51
local caches. So you can try this uh testing from opening your command prompt
2:59:56
with the curl command. Okay. So when you connect this IP IP 103 come up again try
3:00:04
219 come up again try 103 come up. So they keep on doing load balancing right?
3:00:09
how the login server will happen. Okay. So beautiful thing is those who
3:00:16
know bisonense know kubernetes or maybe openc this is very common thing you might have seen there having the s service or load balancer that was not
3:00:24
the main part I explained though even those who watch does not know kubernetes
3:00:29
or maybe open sift okay because open was a tool run behind the scene kubernetes
3:00:34
only but the main thing is the integration right okay this load
3:00:41
balancer is not the load balancer of internal cubernetes. They're taking this load
3:00:48
balancer from the outside world. Okay, that is called uh ELB
3:00:57
ELB load balancer. Okay, interesting thing is right now they're
3:01:03
taking classic ELB that's also getting great no doubt
3:01:09
in it. Okay. But if you talk about load balancer world,
3:01:14
okay, there are lot of very new fancy advanced load balancers that you can see
3:01:20
when you create ALB, NLB that also we can take.
3:01:25
Okay. So for this we have to
3:01:30
change some setting while creating the load balancer. So while we create a load balancer, there's a concept called
3:01:36
android we have to write or when we launch the cluster okay
3:01:42
we launch the um cluster with e EKCTL.
3:01:49
So there also we can define which load balance you want to use NLB or GB or ALB
3:01:55
we can define. So when I go for my EKCTL advanced discussion we write these
3:02:00
lines. Okay, there I will uh talk about it and
3:02:06
because you know because when you try to create this kind of website right now I want to add one more thing here guys. So
3:02:13
you can think this this icon that you see here is also one app and this information
3:02:19
okay coming from blesser this app and internally in the cubernetes world okay
3:02:25
that one application one microser is one port one port so more and more guys hitting
3:02:32
this in the same point time more and more traffic come up and this entire traffic go by ALV load balancer and
3:02:39
they're heading to this port and more traffic going to come Okay, we scale it. There's concept
3:02:46
called autoscaling also. We'll discuss about how we autoscale this HP concept in Kubernetes. they automate scale it
3:02:54
or the port is launching on the top of node more port launch more node we need
3:03:00
again there's a concept called node scaling also uh worker node in my case
3:03:05
upcoming discussion we'll talk about autoscaling also of the node AS concept
3:03:11
that also increase okay so my point is in the Amazon if you
3:03:17
have this part of this application running here just for example servers uh the way explained yesterday search
3:03:22
application running for example more load come up you don't have to worry guys now even though the the if you read
3:03:31
the uh see the video while I was showing you.com that VPN all the guys are
3:03:37
talking about senior senior developer they say now we just focus on the look and feel and the application and product
3:03:44
application part right we don't have to worry about more load come up less load come up automatically kubernetes or EKS
3:03:51
handle everything for us. Cubernetes will handle the pool increasing. EKSC is handling the node increasing because
3:04:00
as a cubernetes stand point of view they can only see the port when more traffic come up they can
3:04:06
increase the port automatically. I show you today replica manually but they will there called HPA through which they
3:04:14
automatically launch. But if you don't have a node how the port will run then
3:04:20
here the role of EKS come in play. EKS say I keep on listening and seeing if
3:04:25
you're launching more port I will launch more node in EC2 instance and connect to you. That what the EKS will do for you. Okay.
3:04:33
And in the world of if you want to go more in deep then this this microser can
3:04:39
this microservices mean this port can this port then how can you secure the
3:04:44
traffic how can you observe this how to monitor this you want to see the entire view where you know this entire if you
3:04:51
see guys big website right and millions of port is running behind the scene okay
3:04:57
at one point in time how the topic is moving here and there's entire view I want for monitoring and management
3:05:03
perspective. Okay. So that also we can do on the top of Kubernetes. So there the role of service mess come into play.
3:05:10
So Kubernetes is very very very optimized to maintain the service mess
3:05:15
with lot of product available in the market. One of the good is STO. So you can launch the ST again not part of this
3:05:21
program but I'm just trying to tell you after having this QA set up uh we can go to the next level.
3:05:28
Okay. And by chance guys uh a lot of guys also talking about yesterday but by chance if you want to learn the STO so
3:05:34
this is one of the very powerful advanced program of STO service mass from Red Hat is official program 328
3:05:42
and this is the premium program from Red Hat Red Hat where they're talking about STO
3:05:50
whenas open ship is again like kubernetes also so is to server mess and the interesting thing is guys they're
3:05:56
covering everything about server mess Okay. Where serto or open of the kubernetes jar kei
3:06:05
routing security chaos testing resilence on the service me strategy. So
3:06:11
technically this is one of the biggest from very basic to all the advanced um
3:06:16
program on service meto. So this the even though this is the biggest level in the terms of architect
3:06:23
management in the world of admin or architecting and setting the
3:06:29
entire design of your big big uh setup that you see in Netflix and Amazon and
3:06:35
all the things. So this program we launched yesterday guys somebody asking me I told them we'll discuss a little
3:06:42
bit today. So this program we have interesting thing is this is a premium program from Reddit one stop product in
3:06:47
the red and we launched this program recently we're going to start this telling soon very basics
3:06:55
okay on the open ship same time with kubernetes also okay and interesting
3:07:00
thing is this program is also associated with the global examination
3:07:06
okay with like transit and trailers between between the port and all things
3:07:11
uh so This also included uh a lot of design pattern
3:07:17
okay how code board and micros service and thing communicate to each other okay
3:07:25
plus this uh training also included your global examination also this ex uh 328
3:07:32
so if you want to go for this learn this entire training read lab for practice the software for
3:07:39
this the the guided books plus the entire exam
3:07:44
uh global exam of do288 you guys can join it because this is
3:07:50
ready premium product normal cost of this program is not by us is done by red
3:07:55
hat is more than 50 60,000 rupees just for entire setup lab Rolexes training
3:08:03
examination coupons all the things we try guys to make it uh very much uh
3:08:10
comfort we We have launched it already uh I don't know I think 26,000 somewhere
3:08:15
around plus 500 something we we have launched this program for you I think we
3:08:22
are the first one who launched this program in India market okay so if you want to learn this entire training you
3:08:28
guys can join we are trying guys uh because uh I know 26,000
3:08:34
5 also a kind of big amount we're trying whatever the way we can make it more uh
3:08:41
comfortable to everyone is not with us but we are trying with ahead if we can do so we'll update you guys as more help
3:08:50
in the financial form if we can do okay so for this uh what you guys can do one
3:08:56
minute guys hold for a second
3:09:04
okay so for this I just need one support from you um even though also register
3:09:09
with us is service mess of you guys only uh but uh I stopped sharing my screen
3:09:15
for a minute. So what we are doing this time we are not doing actually normally in the red world uh but because I know
3:09:23
this is a very high in price it's not in our hand but we are trying to
3:09:28
to uh keep a no to red hat if you have a lot
3:09:34
of red perspective the customers if you have a lot of customers who trying to go
3:09:42
for this exam result we can try to get more coupon or more discount Okay. So anyone who I don't know what
3:09:48
your plan of service me so if you have a plan for service and message just fill this form I put in the uh your chat
3:09:56
message. Okay. uh uh only this form perspective
3:10:01
would be I believe uh would be uh just to see your interest if you want to go
3:10:06
and maybe maybe they have the remark in this form that I given in the chat box
3:10:12
that will might also can write some remark about
3:10:18
that this fees is high and when we want some some any kind of
3:10:26
support in terms of extra coupon I don't So I'm not saying we are giving this any coupon is not on our hand but if you
3:10:33
have a big number bulk number so we can able to talk to red hat and come up with
3:10:40
some better uh kind of discount for this premium product right okay otherwise if
3:10:46
you guys don't have other training like open safe and and we have done already for you but this is not much we can't do
3:10:53
much so we are trying this way this approach also okay so my point is this This is what new praying we're going to
3:10:59
start soon. If you want to join you can you can join or fill the form if you're interested what kind of help we can do
3:11:05
further if we can able to do it we will definitely try. So this form is there in
3:11:10
your chat message. Okay. So yeah coming to this this point of um of
3:11:17
code and we launch uh this service but interesting thing is whatever you see
3:11:24
here. Okay. Is completely customizable.
3:11:30
So we can use some facility from Kubernetes and some facility from EKS service.
3:11:37
Okay. And we can say no I want a load balancer from AWS only but I don't want
3:11:45
this load balancer that is they give you by default classic one
3:11:51
is also good but I don't want classic one. Mhm. that because we might have many more
3:11:57
things that classic does not support. Okay. So let's say I want to go for ALB.
3:12:04
ALB gives me a concept of uh you know routing and uh a proper ingress
3:12:12
controller and many more things. Okay. I want to use this then according I want to set my ingress controller. So
3:12:19
what are this is again advanced part. So guys in my next part of EKS training.
3:12:24
Okay. because today we are going to conclude the core training of EKS. Okay, by my advanced part we'll see how
3:12:32
we customize this. I'm just giving this as example otherwise this is just one one example but maybe
3:12:39
there's a possibility my need some storage extra hard disk.
3:12:46
Okay. So if you know Kubernetes, we normally take the hardest from base system in row row uh in the vanilla
3:12:54
cubernetes, right? But here okay we launch a port in the cubernetes but
3:13:00
cubernetes will take the hard disk take the hard disk from EBS
3:13:09
or maybe recognization of sort or they will take the hard from EFS
3:13:15
or many other services like this. So we launch a port in the Kubernetes but because they are running with the help
3:13:21
of EKS so they connect to other services and take the hard disk from there or take the storage from there.
3:13:28
Okay. So if you know a little bit about guys cubernetes you guys might know concept called PVC and PV that take the
3:13:35
storage and if you know the SC storage classes okay so if you notice guys here they
3:13:40
already have one driver included for EBS in Kubernetes right
3:13:47
otherwise if you run a normal cubain you won't see this driver preset okay you won't see this driver okay but
3:13:55
this driver helping the cubern is that whenever you need a storage contact to
3:14:00
EBS and get the storage by chance they're taking uh GP2 EBS volume but
3:14:07
again we can also customize this driver I'll show you how to do in the future classes where I can say no I want this
3:14:12
driver IO I want this performance or I want my hardest to be encrypted
3:14:18
okay so all those setting also we can do here again with ekill command we can do
3:14:24
and again here the role of add-ons come in play So in EKCTL as a one who will help you in the add-ons management right
3:14:32
so they have the add-ons create and we can get okay so so I'll talk about the
3:14:39
add-ons in the next class but they have add-ons
3:14:46
okay here so let's say I have a cluster in this cluster I want to see
3:14:54
the add-ons addons. Yeah. So there or no add-ons here as
3:15:01
such in this cluster but we can install the add-ons
3:15:07
that give you what extra we need. Okay. That is not given by EKS.
3:15:14
Okay. So we have add-ons for extra volume for EFS and any more things. So again EK file
3:15:22
the YL file when we run in the next class. So we'll write the add-ons and accordingly we changes. So my point is
3:15:28
okay technically we are running our workload
3:15:34
in the Kubernetes world. Okay Kubernetes UT the grade in
3:15:42
container management that's what Kubernetes will do. We are not taking taking anything from Kubernetes. A
3:15:48
Kubernetes need need storage
3:15:53
that we'll take from AWS. They need load balance we take from AWS. They need security we take from IM
3:16:00
right like RB controller all the things. Okay. I mean further integration we take from and because these services very
3:16:07
very strong we took from there and for this we have add-ons available and
3:16:12
add-ons are the one who give actually driver and plugins for you so there are a lot of add-ons
3:16:17
available we'll see in the upcoming classes uh to uh to see it okay so
3:16:23
that's all guys uh I think as a base code level uh base code level uh this
3:16:30
much information is enough I'll try even though we have way of closure of base training also
3:16:36
prii is coming in a minute and she will explain you how we going to close there
3:16:41
maybe some small formalities because we also providing a training certificate for the EKS based training to everyone
3:16:48
so see we'll let let you know but next thing is uh point is I'll try to cover
3:16:56
this training in such a way because normally when you learn EKS it has been
3:17:02
prerequisited that you should know Kubernetes but I'll try to explain a way that even though if you does not know
3:17:08
Kubernetes I'll try to explain every bit of it with with with EKS and explain a
3:17:14
lot of concept of EKS what they provide you as a service okay as a as a service one last I just
3:17:22
want to show you very quickly okay EKS might be very interesting in EKS guys
3:17:29
right now in your cluster Okay, I am running with
3:17:36
a node group in this cluster where right now I
3:17:43
am having um three node running
3:17:49
but if you think you have going to launch more port you need more capacity more node we can scale the node also
3:17:56
it's called machines also so launching more port is due Kubernetes
3:18:02
when launching more machines node is duty of ekl or ek service.
3:18:08
So here in ektl uh we have a concept called scale.
3:18:16
I want to scale my node group.
3:18:21
Okay. Which node group? Node group. Which one I had? So this was
3:18:27
the uh uh node group I have. H where it is.
3:18:33
So get node and this is node group I have. So I want to scale
3:18:41
this node group and this node group belong to a cluster and I have a
3:18:48
cluster having this name because every cluster had a different different name group or
3:18:54
same node group also. Come on. This node, this is my
3:19:05
cluster. This is the name of my node group. Uh
3:19:11
uh is ng basic. And here they're asking you tell me the
3:19:18
new details. Okay. So this is the help. So that here you can see I want my number node. Now
3:19:28
this time would be four. That's all.
3:19:33
Again you don't have to worry. It means they're going to launch one more issue to instance. They launch the instance.
3:19:40
They set up the instance. They install the cubulate cubulate program there. Contain engine there register with the
3:19:45
master and technically they scale the cluster.
3:19:50
Okay. scale the cluster more trust node we have better more resources we have
3:19:56
and um and more code we can launch but here I'll launch this uh scale my node group
3:20:04
cluster manually but there can also automate it so in the guys in the as you
3:20:10
know we have a cloud watch so cloud watch is keep on monitoring the real-time RAM and CPUs okay and we can
3:20:17
say as this much RAM and CPU increase then automatically add one more node one
3:20:23
more node one more node this go to scaling that's can also be done in my advanced discussion we'll talk about
3:20:28
this how we can do those but so as a complete manual perspective EK
3:20:37
service has this great tool EKCTL that is very great in all aspects so I would
3:20:42
like to guys conclude uh this EWS EKS basic or the core
3:20:48
training next Guys, we continue with EKS advanced part uh training. So, we'll go
3:20:55
for Q&A. Okay. But before this, Priti has some announcement.
3:21:00
If you see four instance launch and now node uh
3:21:07
size if you see was now four and if you cube command also we write get nodes as
3:21:14
a cubernetes perspective also. Now we have four nodes uh with us. one is not
3:21:20
ready because still there's some kind of cube program running they're trying to
3:21:25
register in some time after the register it become ready it's been ready we are ready to use it right so there's so much
3:21:32
automation right and that's kind of involvement is very much enough to do the things right so first of all guys
3:21:38
pri has some announcement for you then I'll come again and then any query if you have till date you guys can ask me
3:21:44
priy over to thank you so much uh sir also Finally uh
3:21:49
it was an amazing 7 to 8 hours of your core advance sorry the core EKS uh AWS
3:21:57
EKS Kubernetes training uh with with the help of women serve was been made available to every participant who was a
3:22:04
part of few of our previous programs uh we had selected some exclusive learners like you know my earth 1.0 or 2.0 or 3.0
3:22:12
flow. At the same time, few of my learners from Open Shift who got this
3:22:18
opportunity to learn AWS EKS core training absolutely free of cost under
3:22:23
Wimbleda search guidance and we are also providing a certificate because what we have realized in the market is this AWS
3:22:30
EKS certificate is really having a high value. Okay, all the industries the real
3:22:35
production environment industry if they see that yes you have this AWS EKS training certificate your uh chances of
3:22:42
getting better roles better profiles better jobs increases and that's the reason despite it was a free training we
3:22:48
thought that we should issue a certificate obviously it will be given to the ones only who are a part of the training right now the ones who have
3:22:55
attended the training effectively so uh I'll close it I'll close this link I will not be accepting anything after
3:23:01
this I have just shared a LinkedIn link with you all on your chat box. You can just check that. Please go there and
3:23:08
share whatever you have learned under the guidance of none other than the industry expert Mr. Wimmel Daga
3:23:14
absolutely free of cost. What was your wow moment? Your technical wow moment with Wimmel sir which will also help us
3:23:20
understand that yes you attended the training live with Wimmel sir. I'm again repeating this training will give a
3:23:26
certificate only to the learners who attended this training live and hence it is a request to go on this link and
3:23:32
share your technical learning whatever you have learned under Wimbleda sir I can see maximum of you all are
3:23:38
professionals out here many of you were sending me DMs also yesterday that Pi thank you so much for this core EKS
3:23:45
training because it will really help us in the production environment uh carry forward from next weekend the EKS
3:23:51
training will continue but only for the ones who have registered for the advanced EKS training as it is mentioned. Uh please share again the
3:23:58
link. It's already there. It's been sent to everyone. I'll just reshare it for everyone again.
3:24:06
It's there in the chat box. Please comment and keep the screenshot
3:24:12
ready. We will soon share the link with you where you have to upload your comment and we'll then be processing your certificates.
3:24:22
Yeah. So I'm just repeating two three things which happened today. One is this process for your uh core AWS EKS
3:24:29
training certificate. This is the process. Second is as women had come across and you know he always does
3:24:35
something for the community. So he was thinking that if we can request okay the
3:24:41
red hat people for Isto with something as more as a financial support as a coupon or something. So I hope that firm
3:24:48
was also circulated by women. If you are looking for that help, please fill that form today itself because we'll be
3:24:54
sharing that across and that benefit will be given to only those who have filled the form in case if some benefit
3:25:00
comes up after talking to Red Hat tomorrow. AWS enablement training is fully completed. No Mayor it will
3:25:06
continue over Tuesday. Wiml will announce when will it get completed but yes we gave this EKS as an extra part to
3:25:12
AWS enablement training that is over today. Can we register right now for a EKS
3:25:19
advanced training? Uh Shikhar Deshmuk. Yes, you can. Uh my you can get in touch
3:25:24
with my team very soon or else I'm dropping my number out here. You can just WhatsApp me. I'll be able to revert
3:25:31
you guys tomorrow with every detail which you're looking for.
3:25:38
That's my number.
3:25:46
Yeah, that's it from MySar. So over to you for the Q&A. Thank you so much.
3:25:51
Yes, it is a part of the RSCA track. Ashish DO328 is a part of track.
3:26:02
Uh for 1.2 if it it was mentioned that the advanced EK is free then accordingly the link will be shared with you guys.
3:26:08
Thank you so much. Over
3:26:13
to you women sir. Thank you.
3:27:16
Uh yes guys uh any query if you have you guys can ask me.
3:27:27
Yes. Anyone who is a part of any AWS advanced architecting training that
3:27:33
is also going on advanced architecting training EKS advance is free for you guys. Anyone who are part of EKS
3:27:40
advanced architecting EKS advanc also free. So you guys will be joining next week I just I'll just take this over. So
3:27:48
uh guys uh advanc EKS is absolutely free of cost for two or three set of people.
3:27:54
Obviously, it was been made absolutely free of cost for our very own Earth learners, Earth 1.0, 2.0 and 3.0
3:28:01
learners. At the same time, the ones who have enrolled in advanced architecting in AWS, advanced architecting in AWS,
3:28:09
the ones who have enrolled for that course, for them advanced EKS is free of cost. Yeah. Thank you.
3:28:26
So,
3:28:32
so uh I'm just trying to take can we go only for training for subto
3:28:37
uh guys uh prians uh right now this redhead official training uh what 328
3:28:42
whatever number would be they normally come with bundle with training with lab with books with exam coupon.
3:28:51
So if you have this exam perspective or sorry redhead official training perspective they come with a bundle
3:28:58
uh even though they do have exam only training option but that is almost the same price that is same what is here
3:29:04
right so better why not we can take the exam also because exam itself is 16,500
3:29:10
rupees if redhead right so it's better same price if you want to give so better go for exam also
3:29:20
So ALB redirect traffic to uh 80 port but there would be hundred of port
3:29:25
running on a single instance running on the same port. No actually uh Adil um
3:29:32
u that that is managed by managed by uh
3:29:38
your uh service. Okay. So service is the one who actually
3:29:43
connect and send the traffic to the port. The AT port is belongs to the container port.
3:29:50
So what I mean by this? Okay, if I if I show you very quickly my screen.
3:29:57
Okay. So the port that I use here
3:30:03
cube come on cube ctl get
3:30:09
service the port number 18 that used it is a container port
3:30:16
okay and 80 port is run inside the port. So if you had thousand port running so 80 port not belong to a node computer or
3:30:23
the worker node right this port belongs to container running inside the port so
3:30:30
they will not they will not conflict okay there's a container port
3:30:40
please come with a training call enthos and even though instead of enthos um we
3:30:46
are going to build this kind of uh our own product. I think you're talking Google Anthos, right? So, we're building
3:30:53
our own product, right? Uh so, I think if you come if you know about uh our
3:30:58
summer program, right? Where we are building our own multi-hybrid cloud platform, right? So, SS there's no plan
3:31:05
for Enthos but yeah maybe in the future we might come up predicate enthos training but uh those who are pursuing
3:31:13
the students and again this message is for you also. So in the summer program we have one project we're going to build
3:31:18
our own app platform uh from the scratch where we will create
3:31:25
our own hybrid multicloud is everything hybrid multiloud everything in the one
3:31:30
single product okay and summer I think we have launched
3:31:35
who want to go for summer there's a lot of project this is one of the project we are going to get our own cloud machine
3:31:42
learning MLOps metavors we have quantum computing we have So huge level of
3:31:48
content program we are launching we launched already. So uh because we are somebody asking here so I'm just giving
3:31:54
this name. So this is the website for the summer the creator.1 the creator.1
3:31:59
there you can see all the projects we are creating uh in summer and the
3:32:04
training also. So not only not about uh the
3:32:11
project uh we also first learn the technologies then we integate multiple tools and
3:32:16
technology and create our own projects okay many more thing here so this the created one so anyone who is looking for
3:32:23
summer program industrial program summer training whatever the name you have okay you can apply here apply for the summer
3:32:31
uh program and these are the tools and technology we are learning
3:32:36
Okay. And um so this entire site and this is one of the project we have
3:32:43
create our own cloud hybrid multicloud uh this one AI machine learning devops
3:32:51
metawors and uh mlops deop edge computing IoT all the things and and the
3:32:59
quantum right so we learn everything learn multiple things connect integate
3:33:05
and create our own projects the product right So there's lot of things
3:33:10
uh summer guys Anika this will be on on offline. So after
3:33:15
we have a this is a one of our Linux world main platform right. So after
3:33:23
because of the covid we went to online but it was no summer actually just a training but actual summer program where
3:33:30
we paid the projects and also launch startup we we uh we uh presenting just
3:33:38
by event that we have startup event to investors a lot of things happen in the s I can't talk much right now but yeah
3:33:45
it is offline this year there's no online Okay. So
3:33:52
advanced EKS cab will be starting next week. Next week we continue with advanced EKS.
3:33:58
Okay. So those who want to join advanc EKS also. So you guys can can join. Better session would be go for advanc
3:34:05
and AWS advanc EKS automate come up or only if you want to go for advanced EKS
3:34:11
that also can join. What is enable SSM? Uh Sanka I told you
3:34:17
that time. So uh SSM is one of the feature. So if you want to have this
3:34:22
facility to start or launch your OS directly in
3:34:28
your browser, this is one more thing SSM can do for you. But if you there's many
3:34:33
more thing SSM can do for you. So if you have and the part of my AWS CSL training
3:34:39
going on that I uh talk about uh system manager service.
3:34:46
So if you want to use the system manage service completely then also we have to enable SSM in your nodes or your
3:34:52
instances. So there's one service in AWS that are some of the demos I show you in my
3:34:58
training of CSA AWCs. So system manager
3:35:04
is a huge service. So if you want to use this service to
3:35:09
manage your uh instances so instances need to have SSM agent installed. So
3:35:16
that's also use of SSM. Okay.
3:35:21
Yes. Uh guys uh this very common question you're asking you here this EX 328 training is include exam also right?
3:35:29
This also good thing right? So this training include exam also. The normal red hat examination rate global exam
3:35:36
rate is 16,500 IST uh Indian currency INR. So this training include your exam
3:35:43
also where you have get the exam coupon and valid for one year second attempt free. Okay. So that also include in this
3:35:50
train in this training. Okay.
3:35:59
So any query guys related to summer program you can contact to pri and my team they will help you further
3:36:06
or you can apply the form also. So what is different Q load balancer and the AS load balancer? Uh um SUM is very
3:36:15
harder right now to explain me. If you are a part of AWS CSA training or basic training in my upcoming class this topic
3:36:22
is going to come up where I'm going to explain you about the load balancers.
3:36:29
Okay. And uh that's one thing but very quick note this is a kind of real load
3:36:36
balancer. or maybe they're running on top of some real hardes. Okay, in Kubernetes the load balancer
3:36:43
service they are kind of software based. Okay, so very mature they are but
3:36:50
software is a limited in the terms of performance. This is one small difference I'm talking
3:36:55
about but uh is this is in itself a different topic. So during the training
3:37:00
of AWS that is going on right now maybe a part of it we'll discuss in detail there.
3:37:09
Yes, open s also we can do the same thing. Open s also use cubernetes behind
3:37:14
the scenes. So in open s also we can uh connect to the external load balancer by
3:37:19
applying the driver or if you launch open sift on the top of AWS same thing going to happen.
3:37:26
Hello sir can I enroll into advanced architecting
3:37:32
or can yes why not? So that's also a provision we have if anyone who already
3:37:38
register with advanced EKS you can sift yourself to advanc architecting so remaining fees will be refunded to you
3:37:44
okay and we adjusted whatever the process would be that can also be possible
3:37:50
uh no does not require any programming skills right we are going to do everything from the command line the way
3:37:56
we are seeing in this training of cubed as a command and ekctl command and they
3:38:01
have their own command lines so there's no programming knowledge you need is admin tool or DevOps tool you can say.
3:38:11
So it does not require any programming
3:38:16
guess uh uh we can also change the name right now if you notice this load bench has the bigger name uh bigger name but
3:38:24
uh there's one service in AWS called route 53 where we can give our own domain you know ww.wiml.com or viml.com
3:38:30
or something like this. So this service called route 53 in AWS
3:38:35
prove which we can give your own simple smaller name whatever to give.
3:38:44
Uh yes Amul we have a 288 training also after 10 minutes so I will go to next
3:38:49
train. So morning keep on delivering. Yeah, those who are in open safe developer track, we have a training
3:38:55
today uh at in uh after 8 minutes.
3:39:00
Okay. Yes. Uh Sams, we have a training also available for dynamic programming. So
3:39:06
those who want to learn dynamic programming uh I think is one of the main part of DSA.
3:39:12
Uh so we have a DSA training also going on in Python and C++. I am the one who is taking this training and uh that also
3:39:22
and we have dedicated training also on dynamic programming. We're covering every aspect of dynamic programming. So
3:39:27
we have launched long back but maybe this year we will launch again one more time you guys can join.
3:39:34
Okay. So I suggest Anurag better CLI is good no
3:39:40
doubt but when I go for advanced part you come to know lot of thing we can't do from CLI then we have to write the BL
3:39:46
code by code makes more sense can I run join the running batch I I
3:39:54
suggest not join the running batch because I covered lots of thing there lot of uh we reach to the tree topic
3:40:00
okay and we cover lot of real use cases in uh and uh link list and dynamic array
3:40:08
and a heap and many more. So we have done a lot of things there. So I don't suggest to join running patch.
3:40:17
Okay. So
3:40:23
uh come in we are going to uh discuss far
3:40:28
I believe in in this EKS advanced training. So we going to discuss far over there.
3:40:44
link of EKS advanced training please. Uh so I think uh my team will provide you
3:40:49
in your respective group for EKS advanced training and uh maybe in hasht
3:40:56
EKS if some team of mine listening so you can we can put the link over here or
3:41:01
maybe team will give you guys in your WhatsApp group how to rest for EKS.
3:41:10
Okay. Uh now if you somebody asking me different open shift in the cubernetes
3:41:16
if you know open safe wise now you can compare
3:41:22
okay uh you can compare uh open s is a full complete tool end to end. So if you
3:41:29
want to manage entire thing from end to end okay then open safe. So we can put
3:41:35
the code they will take the code convert into image and then then they deploy it
3:41:42
in Kubernetes. So a they monitor it many more things is there right. So is end to
3:41:49
end tool where one of the part of open shift is Kubernetes but Kubernetes only doing Kubernetes thing. Okay. So, so I
3:41:58
think if you if I if you if you know about OpenC we have a BC controller right they build it for us the code into
3:42:05
containers images right we can't do in the Kubernetes right but technically
3:42:11
openC is no competent open behind the scene using Kubernetes but they add many more thing on the top of this okay
3:42:22
so Mouhammad 180 exam query if you can ask to my team they will help whatever you're asking.
3:42:32
So how a thing work? So cube guys will
3:42:38
use the conf file right? I told you when you're in the AKCL they will download the conf file in your system okay in the
3:42:45
default location. So they take it from there. Otherwise if you have conf file you download in other location then you
3:42:51
can pass cube config keyword in a cube command and you can give the file name.
3:42:56
Okay. So they take the credential from there or in the upcoming class I'll show
3:43:01
you how to take the credential from AM and other way also but by default they take from cube config file.
3:43:09
Okay. So can we earth 1.0 learner can get the
3:43:17
course uh Arvin for you this EKS basic advance we make it free for you. So
3:43:23
obviously uh whatever the hen portal access you need for EKS we will provide
3:43:29
definite to you. Yes web uh advanced EK training free for
3:43:34
earth 1.0 earth 3.0 or 2.0 zero. So that for PTM already announced.
3:43:46
Okay.
3:43:52
So actually you can um I think my one of my team has provided
3:43:58
you the link here of uh how to register for EKS.
3:44:03
Okay. And u I think we have a coupon also for this. Don't don't register with the entire payment. Okay, this is the
3:44:11
website. They have they have coupon applied already. So this is the fees you can join.
3:44:17
Okay.
3:44:23
So image repos can be can be join can we have single port to run uh per you can
3:44:29
also have some use cases where in one port you can launch multiple containers also. the multicontainer port maybe in
3:44:36
advance discovery case I might have some use case there to be discussed okay or
3:44:42
maybe if you go to cubern training also we also discussed lot of use cases there like side sidecar pattern and many more
3:44:50
why we need multicontainer in one port right so
3:44:58
so that's all guys uh I hope you understood autoscaler we will discuss in ease and advance part way
3:45:04
So we have autoc color discussion there.
3:45:13
So any guys any query registration on AWS training or ease advance and
3:45:21
my team will give you details in the group. You can contact to my management team they will help you.
3:45:28
Okay. Uh uh yes u uh Arvind uh if you don't
3:45:37
use Elbenx ingress controller they give you that
3:45:42
capability okay but instead of engineext inress controller we can use ALB application
3:45:49
load balancer of AWS similar capability we can head but with the power of AWS load balance
3:45:57
okay so data science also we launching soon guys we'll update
3:46:03
Okay. So that's all guys. Uh cloud
3:46:08
observability uh we will discuss in the cloud watch training guys. So they have a lot of tool for this and there's some
3:46:15
other integration also. So in the uh the cloud watch training that is going on
3:46:20
AWS we will talk about especially if you're part of sysops training AWS
3:46:25
sysops that is where we discuss about cloud observability monitoring and many
3:46:31
more things pressing in very detail okay so uh that's all guys see you I
3:46:39
believe you enjoy this training of EKS and all the best we'll see you guys in some other training and good day take
3:46:44
care and all the best bye good


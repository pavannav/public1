ript


11:23
Hey guys, uh very good evening and let's continue with the next part. So in the
11:28
last few classes, uh we have talked about load balancers, right? And I take this class already in
11:36
very detail, right? And we talk about uh four different load balancers we have in
11:42
AWS. This is so classic load balancer right and application load balancer, one
11:49
is NLB network load balancer and one is gateway
11:55
load balancer right and almost all the load balancer guys we have discussed in detail with their use cases. Okay. And I
12:03
explain you um how we configure and how we going to use this right. So all these
12:09
things plus uh proper architecture also it is not always that we have to only
12:15
use ALB okay sometimes we have to use ALB and LB together to to you know so to
12:22
uh set up this right to so some of the involvement. So today's plan guys, we
12:27
are going to start a new topic. Okay. And the topic name is called autocaling
12:32
group. Okay. So that is a topic uh we plan for today. Auto
12:40
scaling group. So what I mean by this right what is use of this topic? So till date guys what we
12:48
have done if you just forget this topic for a while. Okay. uh what we have done
12:53
we have a client okay and client uh is uh trying to
13:00
interact with our server and the better practice I told you always try to send
13:05
the traffic of the client via load balancer okay maybe initially you might have one
13:13
single instance that is called EC2
13:19
having one sub uh uh one web server we have okay uh so that uh my client will
13:27
connect to the web server via load balancer but why we'll go via load balancer maybe I explain you the concept
13:34
maybe at the point in time we have just a startup company and we believe that
13:40
there will be not hundreds and thousands client going to come up to access our website let's say our website can handle
13:47
100 connection per second and we know there's No not huge traffic uh load
13:53
going to come up in this application. Okay. But as a proactive plan okay
13:59
because we might be growing growing company and there's a possibility and mostly there's always
14:06
possibility okay that the that the traffic going to increase or client
14:12
going to increase okay in this context I started
14:18
by this setup. Why this setup? because my load balance is there. I will give this one public IP with the port number
14:24
to the client. So client will only remember my IP address or my port number to connect but behind the scene behind
14:32
the scene my traffic has been proxied or routed to my uh actual backend servers.
14:38
But why I go for this setup I again and that's what I'm trying to again explain you. But in my last class I already
14:44
explained this concept to you. One of the reason is if the more client going to come up let's say
14:50
in a in a second more than 200 300 clients or connections per second going
14:55
to come up one single server won't able to handle okay so in this case what can
15:01
we do without changing the IP address and the port number and updating the client that we are going to launch more
15:07
server we can add multiple server behind this we can add one more one more multiple
15:14
system we can do We can we can connect. So I can launch one more instance. Let's say this a same
15:20
copy I can launch one more time. Same copy I can launch one more time and connect and register the server with the
15:25
load balancer as a backend service. So my client doesn't have any
15:31
visibility. Okay. They will again keep on coming same IP same port now but load balancer
15:36
balance the load. Some traffic will go here. Some traffic will go here and some traffic will will go here.
15:43
So that's what guys I explained in my load balances classes. But in this case, okay, we as a cloud admins or the IT
15:52
guys, what we are doing here, okay, we are monitoring our
15:59
servers. Okay. Or maybe we are monitoring our traffic on the server. Okay. And what we
16:07
are checking let's say as per our understanding we we
16:13
have checked that my server the maximum traffic they handle let's say is 100
16:18
connections per second. Okay, let's say this is the information
16:24
that somehow we collected and there's a lot of performance oriented tool or
16:30
benchmarking tool available in the market through which we can check that your respective server can handle
16:38
how many connections per second or maybe system guys you have a RAM.
16:44
Okay, maybe you have given 8 GB RAM to the server but we can check by some kind of performance tool that if your if your
16:52
RAM is consumed over 6GB or over 90% the applications doesn't behave properly
16:58
they become slow and doesn't behave properly and doesn't properly give the response to the client or maybe they're
17:04
very slow okay or maybe my some of my performance team or the benchmarking team means they
17:11
will set the benchmark they check if system has some CPU and if your load of
17:17
CPU go above 80% the application become very slow
17:22
or maybe they check the about the network bandwidth and say if your network bandwidth is
17:29
consume over 60% in and out traffic all right your our network becomes slow and
17:35
all the client will face the network issues so these are the factor we corrected how
17:42
by some of our team relative to IT or networking or performance tone team or
17:48
performance monitoring team they collect these informations. So these are the
17:54
uh benchmark information they collected by some kind of tool or by doing some
18:00
testing on the tool or stretch testing hundreds of things can we can do to collect this information
18:06
okay it means it means let's say initially we have one single server running server number a okay and this is
18:14
the uh information we have okay and this information let's say we have as a cloud engineers
18:21
okay cloud engineers we have this information over here. Okay. And what we do, we keep on monitoring our server
18:30
to check does we are getting a connection above 100 second connection
18:35
per second. Does my RAM uh
18:40
utilization go above 90%. Okay. Does this one this one happen? So my cloud
18:46
engineer will keep on checking this information. This is called monitoring. And why they monitoring? Because they
18:52
keep on checking if any of these any of these uh you know happen.
19:02
But guys, one more please. I'm so sorry guys. Uh I don't know why I forgot to
19:07
share my screen. So I think a lot of things you have lose. But technically
19:13
this was the let me again explain you. Okay. Uh I don't know why I forgot to
19:20
share the screen but yeah so this is a load balancer we have four load balancer guys we have discussed and uh today the
19:27
plan is autoscaling group that's what we'll we'll see in a minute okay and
19:32
what I'm trying to show you this is what the last example what I have explained you in my last class okay when the
19:38
client head to the load balancer I will give a fixed IP and port number to the
19:43
client as the plan initially may start up we only on one single instance
19:50
let's say a one single instance okay and by why we put the load balancer because we never
19:57
know in the future when the load increase I might have launched one more
20:02
computer and one more computer to balance the load that's what we have discussed in the load balancing classes
20:09
okay and for this we we we are the cloud engineers and uh our duty is to keep on
20:15
moning and why to monitor because we have to launch one more computer to balance the load or maybe if the load
20:22
increase more we have to launch one more computer 111 maybe hundreds of thousand computer we have to launch
20:29
and for this we as a cloud engineer or as a human being or admin guys we should
20:35
have some kind of parameter with us or some kind of metrics with us okay that
20:42
has might be given by my some performance team and Let's say one
20:47
system the resources the way the the you have given the resources
20:53
one system might handle 100 connections per second or might not work about 90%
21:01
RAM been consumed or the CPU go about 80%
21:06
application goes down or network become 60% everything goes down as a network
21:11
speed and data get in post maybe or that the data to put. So this information is
21:19
just giving a hypothetical number right. So some of our team they give this kind
21:25
of metrics or the parameter to you to
21:30
whom? Maybe let's say cloud engineer or who are managing the load balances for you. Why they give this information to
21:37
this cloud engineer? So they keep on monitoring the system and whenever any
21:43
of the parameter anything happen that the RAM goes above 90%.
21:50
Okay. In this case they uh feel if RAM is above 90% being utilized okay then
21:57
application become slow. So client will face the difficulties in the applications. In this case, our cloud
22:04
engineer manually go and launch one instance. The first
22:12
step that is a manually done and second step is they register this
22:18
instance to this particular uh load balancer. The second step they will do
22:25
after they do now behind the load balancer we have two instance running and now your this is the by default duty
22:34
of the uh load balancer to balance the load. So any of the issue come of RAM or
22:40
CPU that that that to be managed. Okay. And that is the reason why we need a
22:46
load balancer. But adding one computer again my cloud engineer has to now mer
22:52
two computers together computers together m two computer together and if they see
22:59
if all computers RAM and CPU again hit above this benchmark okay they have to
23:05
launch one more computer how again manually but launching guys computers here or
23:11
adding instances here behind the scene load balancer is known as scaling
23:17
And here we are doing a scaling manually. Okay, manual. But guys, again manual
23:23
thing is not good. You guys know okay maybe
23:28
[Music] you are launch your app the app goes viral suddenly viral at at 9:00 9 at
23:36
night 2:00 or 3:00 maybe my team might not be so much active that point in time. Suddenly huge traffic come up a
23:44
thousand thousand clients come up to access your applications but that point in time you have one system running or
23:49
my engineers is not active they're not monitoring maybe that point in time or some point in time or maybe in the
23:55
weekend for example okay in this case okay if any of the metrics hit or
24:02
parameter hit application goes down and client won't see and access your application properly even though we have
24:09
the load balancer but who going to launch one more computer who who is going to scale my my computers or who
24:15
going to scale and adding more is H2 instances because there's nobody manually monitoring or there there's
24:22
nobody available here to manually add the computers for scale the computers or
24:27
scale instances okay that is a very very critical issue
24:33
again to overcome this issue what can we do I want this exactly same infrastructure
24:39
as a load is based upon my parameter. Okay, this parameter is more or less but
24:45
based on the parameter I want to scale more computers to balance the load so traffic my client will receive the
24:52
better performance. Okay. Only thing what I want to do instead I depend on my team or my engineers or the human being
24:59
or I depend on the manual thing. I want the scaling to be automated.
25:05
That's what we are looking for. Okay. and to do scaling automated. Okay,
25:11
we have one uh component or we have one service in AWS and that is called
25:17
autocaling group as so autoscaling group is one component or the subservice of
25:23
EC2 I can say. Okay. Uh that has a capability to autoscale the
25:30
it means whatever your human being is doing what they're doing
25:36
first they are monitoring what is happening. Okay. Second thing they're monitoring
25:42
with respect to uh the parameter that is most metrics. Metric means if your for
25:49
example if my laptop right now my laptop I have 16 GB RAM for example. Okay. But
25:55
my this task manager in my windows is keeper monitoring and say at this point in time 52% of the RAM has been used.
26:04
So my current memory utilization in my system is 52%. So this is called
26:10
metatrix. So matrix is 52% of memory. 70% of my CPU will be used right now.
26:16
The 1% of disk is being used right now. That much of my Wi-Fi or network card has been used right now. So
26:24
checking your current status of your hardware or your resources. Okay. And there is hundreds more things we can do
26:31
with other things also. Okay. And known as metrics. So my current memory
26:36
utilization if you want to know that is known as current memory memory utilization metrics in my case right now
26:42
as 52% is going up and down every second every millisecond also
26:48
okay so rather than my engineers or human beings is keep on monitoring or
26:54
monitor the metrics okay we ask autoscaling group they will do for us how automated
27:03
okay and Then we'll ask them okay that you are moing the matrix okay but I'm
27:10
going to tell you some rule rule and the rule is if my RAM goes
27:16
above 90% then do something if my CPU goes above 80% then do something
27:24
okay I will tell the rule and based on the rule they will do something and mostly whatever what they do mostly we
27:31
will ask them to scale Okay. So when the this rule hit
27:37
okay then they will the third thing and what they do mostly they will launch the issued instances and add behind the load
27:45
balancer and it will be anything other things also I'll give you some more example sometime
27:51
okay so typically whatever human being is doing they monitoring manually but here I want this
27:57
moning to be automated then based on my other team they given this rule or
28:03
information that if you have this matrix and above this then thing will go down or slow down maybe or might not be here
28:10
properly. So this information they have so they keep on checking the rule what they what they monitor against them.
28:16
Okay. And whenever they find that your RAM is about 90% for example then they
28:22
will manually go and launch the EC2 instance or scale the computer and maybe put behind the load balancer. The third
28:29
thing they will doing but I want this all these three things to be automated
28:34
and this is the duty of your auto scaling group.
28:40
Autoscaling group is the one who will do for uh you only thing that autoscaling group won't
28:48
do for you. Autoscaling group is a one service. Their duty is to autoscale
28:56
means launch the computers and put in the load balancer
29:02
when when this rule hit. Okay. But only thing that autoscaling
29:09
group can't do they don't know how to monitor. Okay. They don't know how to monitor.
29:15
And for monitoring we have a one dedicated service available in AWS and
29:21
that is very very powerful service all always with any other service this service we always use
29:28
okay and that's the name of service called cloudatch cloudatch
29:35
so cloud is watch is a independent service I'll take a dedic dedicated class on the cloud watch hundreds of
29:42
things they have to be discussed in the cloud watch but cloud watch has a one of the capability is to monitor the metrics
29:50
met is the RAM utilization CPU utilization some something like this they have this capability
29:57
okay so in this example if I just try to create recreate this example one more
30:03
time to give this clarity what we are going to do so what I want
30:09
I want I have one web server running DC2
30:15
Okay, I want somebody's keep on monitoring this instance. What they monitor? The
30:22
current RAM, current CPU, current hardest, IO, throughput, hundreds more things you can monitor. Okay. So, you
30:29
want to monitor the metrics metrics. So, metric monitoring we would
30:34
like to do. Okay. And I want this metric monitoring to be done automatically. Means we don't
30:40
want to manually go and check the commands of Linux and Windows and check ourself.
30:45
Okay. Instead what I want I want some tool will do for us automatically and the name of that tool is called
30:52
cloudatch. Again this is one of the things cloud can do. Even though cloud has some more
30:58
capabilities in my next class or next classes I will talk dedicated on the
31:03
cloudatch. We'll see that remaining capabilities and more capabilities of the cloudatch.
31:09
Okay. So Cloudatch is service that has a capability to keep on moning your
31:15
instances. Okay. And after they retrieve the information
31:21
okay for example let's say this RAM is been been you used let's say 5% RAM has
31:27
been used. So Cloud will retrieve this information and say the RAM utilization
31:33
right now in the system at this point in time is 55%.
31:38
this information that it now who want to use the information that will be your choice. So we have lot of services in
31:44
AWS AWS we have okay these services can
31:50
contact to cloudatch and say uh can you give me some information about the live infrastructure
31:56
let's about this instances okay so one of that service that
32:01
normally and mostly depend on the cloud watch is autoscaling group is the one like this there's hundreds of other
32:08
service in AWS they're very much dependent on cloud watch So in the cloudatch class I will talk more about
32:14
this autoscaling group is one service they say cloudatch I just want to keep on
32:22
giving this information to you about this instance that right now in my real
32:28
time the memory that is been utilized is let's say 50% just keep on giving this
32:34
information to why because somebody the cloud engineers has created a rule rule
32:42
on me. Write a rule on me. Okay. And the rule would be that just keep on checking
32:49
this instance number let's say a or this instant ID let's say a and when my
32:56
memory utilization goes above or equals to 90%.
33:04
If this rule match, if this rule match then then do something.
33:13
Okay. What to do? Okay. Depend upon my cloud engineer what they want me to do.
33:19
Okay. One thing they might want me to do when this go above 90% then in this case
33:26
do one thing. In this case do one thing. Send a email to my admin department. for
33:33
SMS to admin department that's for notifications. Okay, that's for notification.
33:39
This is one thing you can do. Okay, in this case we have a different
33:45
service in AWS. This is called SNS. Okay, simple notification service. The
33:52
service have capability to send SMS and email. So AS is one service who can contact to
33:57
the service and they send the notifications. Okay, maybe other things there's a
34:04
possible they might contact to some IoT devices
34:09
and ask them to buzz the alarm you know let the lights and LEDs might
34:17
not be so much useful but maybe some cases in some security
34:22
to give a more you know way to alert things they might contribute IoT devices
34:29
so we have a green grass kind of service or maybe other services in AWS that has
34:34
a way to manage the IoT devices or maybe what we can do if this memory go about
34:42
90% then I can ask a do one thing contact to EC2 services and launch one
34:48
more instance of the same copy okay of same copy of A means you guys
34:56
know whenever you launch instant we use the A1 So we can ask them use the same AMI and
35:03
launch exactly same copy and after this instance launch then after this restore
35:09
this instance to this load balance server. Okay as a backend server
35:14
as the uh as the backend server launch one more as a backend server. One more
35:19
as a backend server. Okay like this hundreds more thing we
35:25
can do. Okay. So what action you want to perform?
35:31
These are the actions. Any one action, any two actions you can perform depend upon your requirement.
35:37
Okay. Let's get hold for a second please.
36:13
So based upon based upon the rule
36:19
who create we crowd engineer had to create only once actually okay based upon this rule and say when this will go
36:27
about this okay so 90% we decide okay who decide cloud engineer
36:33
From where this 90% come up maybe you or maybe my other team member performance
36:38
team can find out that if your applications go above 90% RAM
36:45
utilization they become slow. So they have a performance tool or benchmarking tool. They give this information to you.
36:50
Okay. So this number come from here. Who give your performance
36:56
team give this information to you? Where this information come from? This is come
37:03
is keep on coming in the real time from a service called cloudatch they give this it means if my current RAM go about
37:11
91% 92% is my inst instance this rule match and if this rule match I will do
37:17
these things so finally what happened let's say this instance is going on running a right now
37:25
right let's say this maybe one load balancer we have that has been registered with the load balancer and if
37:31
this instance is 55% then it's go to 64% maybe go up to 80%. My claw wash is keep
37:38
on sending this information to a say no my rule is this rule match no 80%
37:46
go more than 90% no it means I won't do anything
37:51
okay I won't trigger anything I won't do any action automatically but let's say this RAM after some time go about 91%
37:58
live monitoring is done by cloudatch they send this information to AS
38:04
okay or maybe I can say a is one who's picking the information From there same almost same kind of thing right to understood understanding and if now
38:12
let's say memories had become 91%. this rule match it means something critical
38:18
there that's what crowd engineer architecture planned and they auto
38:23
trigger they launch these action any of these action or two two or three these actions and they launch one instance
38:30
from the AMI same why because I want to do load balancer and for balancing the load I need both the A and B should be
38:37
same copy okay the launch one and launch
38:42
so that is called is auto this is the process of happening autoscaling. So again very quick revision if you have
38:50
load come up you put load balancer and for this you scale 1 2 3 4 10 computers.
39:00
Okay that was manual here but in our case same thing is going to happen but
39:06
it will be automatically pure automatically. So scaling
39:12
will be happen automatically.
39:17
Okay. In this case after B launch then I keep on mering this guy also.
39:23
So I'ming the RAM of this guy. I'm also ming let's say mering the RAM of this guy. Okay. Again same rule apply. Let's say
39:30
we by writing the rule we we are checking the memory
39:35
utilization as average. Okay. If both the guys average goes over 90% then we can launch one more
39:42
computer. One more computer has been launched computer number B see
39:47
then let's say this guy is using 40%. At this point in time again three is
39:52
running scale automatic happen we are checking the average of all three and all three average goes about 90% again
39:58
we launch one more one more launch. So we can keep on scaling again and again.
40:04
So idea is very simple if client is coming that's good thing for our business
40:09
business right so I don't want to restrict the client I want as the client
40:17
come up okay they will be publicly served so autoscaling will be help us to
40:23
automate this thing but there's a possibility more and more can come up
40:29
more and more computers going to launch and more and more computers you launch more and more cost you have to be beer
40:37
your company might have the budget on the cost okay and based on budget you say no maybe more current come up but I
40:43
won't invest more than for more than 10 computers okay where you can set a max limit
40:50
max limit and say if my auto scaling launch more than try to launch more than
40:57
10 computer I won't allow maximum computer that I going to allow is to launch 10 maybe happen and more load
41:04
going to come up maybe my all client connections become slower down that's a different point but I can't be more than
41:11
10 computer as a budget or the cost so I want to set a maximum 10 depend upon the
41:17
budgets and depend upon other other reasons also you can set the max limit also in the auto scale
41:24
okay that's what we can do and in scaling world
41:31
in a scaling world I told him Last class also scaling means one computer add one more
41:37
add one more add one more add one more is called scaling okay this scaling is known as scale out
41:45
scale out scale up scale up is a different concept
41:51
so don't be a scale up if you have one computer in one computer if you have 8 GB RAM
41:58
in same computer if you increase the RAM let's say four more GB In one single computer if you want to
42:03
add any resources in the one single computer this scale up
42:09
okay but one computer running if you launch one more computer one more computer this is scale out
42:16
okay but if you remove the computer the computer dam the computer it's also
42:22
scaling but this scaling is not a scale scale in scale
42:30
scale. Okay. But in the one computer if let's
42:36
say total RAM is 4.812 but if you decrease the RAM and you after all you
42:41
make the RAM 2G for example this go scale down
42:48
scale down scale up in one single computer. So any resource if you add and
42:53
remove in one single computer scale up and scale down. But if you launch more
42:58
computer let's say like a parallel 1 2 3 4 5 scale out remove in this area is
43:04
called scale in scale. Now in this example right here
43:10
right now in this uh in our example we are talking more about scale out and scale in. Okay. So there's a there's a
43:18
requirement for example there's one computer is keep on running we add one more we add one more more
43:25
load come up we add one more it's for scale out okay but we can get one more rule and
43:32
say maybe not load is not coming continuously right they come for 1 hour two hour full day half day okay till the
43:39
load come up I keep on paying the amount for the resources because if you launch more computer more amount you have to
43:46
But I can ask my autoscaling group to do one thing create one more rule. A rule
43:52
would be as as load decrease.
43:57
Okay. If you think only two computers can handle the load. So then this OS damage this OS only run two computers.
44:07
Okay. Just keep on checking the load. If you think load can be managed by two computers
44:13
the remaining part. So it will save our cost. So automatically do scale in.
44:20
So here the rule guys I was talking about you can create both the rules.
44:25
Okay rule when to do scale out
44:31
means add more computer when the RAM goes above 90%. For example or CPU go
44:36
about let's say 70% something like this. Okay. At the same time we can create one
44:42
more rule and the rule would be of scale in when to terminate the resources based
44:48
of instances. The rule would be would be something like this. If my RAM is goes
44:55
less than equals to let's say 60%.
45:00
In this case I can remove one component maybe two components.
45:06
Okay. So we can do scale in means remove the remove let's let me use the word remove the EC2 instances and here I'm
45:16
going to add a EC2 instances for example okay so we can create a rule for both
45:22
side that makes the instance right because the managing and balancing the post also very important so we can can
45:28
create both the rules over here okay and we can set the maximum limit
45:34
okay or we can do one more thing here. Okay. Because you know guys when you plan for
45:39
the infrastructure mostly the setup is not is not like this. We have a load
45:45
balancer and we always is not like this. We always launch for one single
45:50
instance. Typically at least minimum two computers we always run.
45:57
Okay. Two computers we always run. Okay. Maybe three we always run.
46:04
Always run. Okay. And that is a maybe less a typical
46:09
use case. Okay. Maybe one computer running in 1A data center, one is running 1b data center, one is running
46:15
in 1 C data center. Something like this. You guys know because of the high availability of your uh disaster
46:21
recovery or your data centers uh failing part.
46:26
Okay. So I can say when I do a scale
46:32
in okay maybe initially I I will go maximum to 10 but it's computer is not
46:41
uh the resources is not is free then decrease to nine then decrease to seven
46:47
then six but minimum I want not less than three I always want to give even the load we
46:54
have or we don't have the load load we have we increase but even though we have no load minimum computer I always need
47:01
three. So we can set the minimum limit also. Minimum limit three.
47:10
Okay. Or I can use one more term here. Okay. In any of the cases,
47:17
any of the cases. Okay. I want my desire is three. I always want three compar. So
47:24
there's one more term guys that is not actually equal. There's some different I will tell you the difference. But almost
47:29
equals to minimum this desire but there's some difference we'll see in
47:34
some example in some time maybe tomorrow. Okay, this limit. So there's three limit guys we can set here.
47:40
Minimum, desire like right now for some time this they think it is a like a almost equal but there's some
47:46
difference. Okay. So minimum we can set or desire we can set three. Okay. In any of the cases
47:54
in scale in means terminating phase don't go beyond three. Minimum run three
47:59
at least always. But if you keep on scaling this scale out sometimes only
48:05
scaling keep on scaling till maximum 10 time beyond this one of the big reason
48:11
is mostly the the uh cost other reason maybe
48:16
sometime we have a lot of attacks happen okay we know in in in any of the cases
48:22
we won't get more than customer more than 10 computers if something goes 10 it mean some might some attack is going
48:27
on so there's no make to want to waste the time that so my my security team
48:33
will have better time uh to just check the issues but by the meantime don't increase more
48:40
okay that will I'm going to increase the cost of the infrastructure at a company
48:46
okay that is also one of the reason why we always want to set the max limit okay
48:52
so this is some of the terminology I have given to you and the very interesting use cases and what the
48:57
process of autoscaling Okay to do more and more in the
49:03
autoscaling group right you should be great in cloudatch so I'm not discussing
49:09
cloud watch right now maybe tomorrow I might take this this topic and then we'll add more advanced thing in autoscaling group in tomorrow but today
49:15
let me at least use the autoscaling group at the basic level okay so this is guys the entire uh
49:23
process and the architecture okay so so let's continue with the practical of the
49:28
autoscaling In the simple line as summary, if you want to launch multiple computers
49:37
without manually, you want to launch automated without any human being, then
49:44
the use of autoscaling concept come in play. That is simple, very simple line
49:51
auto scale. Okay. So let's go and launch this. So
49:57
I'm going to use AWS cloud. Okay. and in AWS
50:15
what I'm doing right now. Okay,
50:22
right now we are guys running with these four instances
50:28
in in my case right now and in the last class guys we I have created one
50:34
load balancer already. Okay, name is
50:41
the application load balancer in this load balancer. Uh right now if
50:48
you see the detail in this load balancer right right now if you see the
50:54
listeners. So this load bas is connected to my
51:00
my uh what I say the target group.
51:06
Okay. If I click on this target group,
51:12
in this target group even though let me check in this target
51:19
group we have corrected two targets
51:24
two targets is been corrected right now they're using but there are two targets been corrected
51:29
okay so that was guys we have done so right now what I'm going to do this is
51:35
what guys last we Okay. So what I'm going to do even though I let me do this back very
51:42
quickly one more time from initial. So otherwise you will might sometime be confused. So what I'm going to do
51:50
before the autoscaling group okay before autoscaling what I'm going to do I'm going to set up my load
51:57
balancer so I can connect my uh my autoscaling group with the load balancer. So I'm going to set up one
52:04
autoscaling group sorry uh application load balancer.
52:12
Okay. And you guys know any client come to auto uh application load balancer
52:19
they will always connect to the target group.
52:25
Okay. So traffic will be sended to the target group that you guys we have discussed in ALB classes and in target
52:33
group you have one computer, two computer, three computer based on the computer they will balance the load.
52:41
Okay that's what guys you know till now. Okay. Now what I'm going to do till date
52:49
till date these computers launch by us how manually
52:57
and this computer will attest and register to this target group by us how
53:03
manually okay now today what I'm going to do okay
53:08
I'm not going to launch any computer by myself and I'm not going to connect this
53:14
instances to the target group by myself. I want this to be done automatically
53:21
and who will do for me my autoscaling group. So right now the vector will be
53:26
something like this. Okay, right now I'm going to launch a empty kind of target
53:35
group. tag group let's say tag group would be
53:40
named let's say uh my target group in this target group there
53:46
will be no instances obviously okay and I'm going to launch one
53:53
load balancer called uh sorry application load balancer
53:59
that connect group and I say here in my application load balancer any traffic come to you to any of the URL
54:07
any of the route path send you okay from the from the client
54:15
but any client hit to application load balancer yeah they send to target group and
54:22
target group we have no instances obviously finally error going to come
54:28
okay then I will go and launch the instances but in this case I'm going to launch the
54:35
instances with the help of autoscaling mode not manually. Okay. So let us first create this set
54:42
up. This will be again the quick revision of my last class also of
54:47
right. So what I'm going to do I'm going to create a first target group. We'll talk about a autoscaling in some minute.
54:56
I'm going to launch a new target group here where I'm going to add a computers
55:02
okay to this uh one. Let's say my target group go.
55:08
Okay. Everything same. I'm changing my VPC. This is the VPC guys we had created. I'm using that VPC.
55:15
Okay. And health check is same. No change. Uh let me decrease the health
55:22
threshold for two. And let me decrease my interval let's say to five or or
55:28
maybe time out to SF4. All right. This one has been discussed already in very very detail.
55:35
Okay. And here in this target group, I'm not going to register any of the
55:40
computers. Okay. This computer will be automatically restored. That's what I want to see. Okay. So there's no target.
55:50
This target group is empty. Okay. So this target group what I
55:57
created right now okay is have no targets. So it is like a
56:05
blank blank. Okay only thing I'm going to do I'm
56:11
going to attach this target to my ALB. So ALB is not yet attached.
56:19
So let me connect create one ALB here load balancer.
56:26
Okay. Application load balancer I'm going to create here. Let's say my ALB 4.
56:36
Okay. Again interfacing put into same um VPC.
56:46
Okay. And I'm putting the ALB into my public subre. Let me add one more LB for
56:54
auto state of the ALB. public. Okay. Security group I'm giving
57:02
allow my LB some kind of security group we created in the last class. Okay. And
57:08
this is the port I'm using right now port 80. and say anybody who come my to
57:13
ALB on port number 80 okay I will set defroction target I set
57:22
this traffic to this guy okay so tagger will be my target
57:29
okay that's all anything else go and that's this was a quick revision of my
57:35
last class everything we discussed in last class very very detail okay so this is what guys I
57:41
group is provisioning in this case. In this case, if you see the target group now, this target group,
57:51
my target group, sorry, my target group,
58:00
it's kind of to this ALB. But in this target group, we have no instances. So, this setup guys is one time setup.
58:07
Either you can do it manually or you can do with the AWS command line tool or you
58:12
can do with a terapformm that would be your choice one set
58:18
okay but main thing is there's no instances there's no there's no
58:26
there's no computers here we're going to launch this computer I want that to be automated
58:33
okay so who will launch that's what the autoscaling will come play. But before this, let me check this is still
58:40
provisioning right now. When you when this guy launch and then you click on
58:45
your name or the DNS name and when you hit
58:51
okay that time you will see right now service 303 means the instance is still
58:58
loading is not been launched still provisioning. Now active active right
59:04
now if you click hit enter and what you see guys this error come up
59:11
this error also means this load balancer is active
59:18
they're sending this traffic to this target group but in this target group we have no instances we have right now that
59:25
is 503 error come up service temporarily unavailable that means your there's no
59:31
components behind the scenes the load balancers. Okay. Now, who is going to launch
59:37
this computers auto scaling group? We can do it manually, but I want to be
59:44
automatic. So, for this we have to go for auto scaling group.
59:50
Okay. So, how can we do? So, there is the concept called launch configuration and auto scaling group. First, we have
59:58
to set up the launch launch configuration. I did very simple. Okay. I want this
1:00:04
computer to be launched how automatically and if you want to launch any EC2
1:00:10
instances automatically. Obviously have to tell about this instances that when
1:00:16
AWS is going to launch this instance what you want which AMI you want to use
1:00:22
which instance type you want to use and some more details.
1:00:27
Okay. Because this instance if you launch manually then we can select all the things right while launching the
1:00:33
instance but this instance is going to launch automatically. So you have to do
1:00:38
and create this setup once there is called when you will launch this what
1:00:43
configuration we need what configuration we have to use. So we
1:00:49
have to use set up this launch config again once at only once initially.
1:00:55
Okay. So we have to go and use launch configuration. I don't have right now. Let me create one.
1:01:02
Let's say this is my um launch configuration for
1:01:10
for my let's say for website. Okay. U N CH for website.
1:01:19
Okay. So here what we have to say whenever whenever I want to launch the
1:01:27
AC2 whenever I will use this configuration
1:01:33
okay I'm not going to launch right right now but whenever I want to launch okay I need this configuration and when
1:01:41
when my autoscaling come in play so when autoscaling want to launch one
1:01:47
computer here I will use this setup to launch launch one more computer I will use this setup launch one more computer
1:01:54
I will use this setup launch and every time every time going to launch use same setup then all the computer will be
1:02:01
exact same some configuration that's why that what I want behind the road right same instances the same MI and same
1:02:08
setup okay so here I'm going to use AMI
1:02:14
let's say I'm going to use AMI that is we created or you can use other other one also This is what the I created my
1:02:21
account with instance type. Okay. So I want to use the instance type
1:02:28
if they have T2 micro. I want to use this free one. T2
1:02:35
micro. Okay. This is what we can use. And do
1:02:42
you want to add some IM role? I don't need any other things. any other things advanced details
1:02:49
any other details like RAM other things any hard disk extra any security group
1:02:56
maybe because these are the web server so I want to use a pre-created security group let's say uh security group allow
1:03:02
web server that's what I like to use okay key pair if you want I want to
1:03:10
choose a key pair what I have let's say this
1:03:15
That's all. So whenever
1:03:20
auto scaling happen, I want this configuration to be used to launch this
1:03:25
setup or this like this. So one time confession we are doing here and this is
1:03:30
known as launch configuration we have set up here. Okay, this doesn't launch
1:03:39
any computer right now. I'm just setting up this launch configuration.
1:03:44
Okay, so this setup and sorry this configuration has been done.
1:03:49
Okay, they're not launching any computer. For example, if I go to my instances right now,
1:03:56
right now in my computer, I have only
1:04:01
four com four computers there or one is running I can say only one is running at this point.
1:04:07
Okay. So this launch config only we are just setting the configuration part when
1:04:13
I want to do automated this is what I need. This is what I need. Okay. But who will
1:04:21
launch this launch configuration? Who will use this setup? Who will use this launch configuration? My autoscaling.
1:04:30
Okay. Now here the autoscaling makes sense. I will ask autoscaling.
1:04:36
Okay. and say do one thing whenever you do autoscaling
1:04:42
use this launch configuration and launch the computer phone and when you want to use whenever
1:04:49
anything triggers I explained to you so whenever I create a rule and rule means when my memories
1:04:57
goes about 90% 80% CP like this hardest
1:05:02
I go about like this something like this when the rule match Okay. So who will check the rule moto
1:05:09
scale. So whenever this rule run and check condition is right that's called that in
1:05:16
that case you have to trigger this launch configuration and launch the
1:05:22
computer. Okay. Okay. So now guys finally
1:05:27
what we have to do we have to finally go and set up the autoscaling group ASG
1:05:33
autoscale. Okay. So autoscaling group is that's
1:05:41
what guys I explained to you is a collection enable automatically. Okay something like this. This is what I
1:05:48
have explained to you and some of the example you will see max size mean
1:05:54
desired they're almost same there's some difference I'll discuss about the mean and desired okay and this scale out as
1:06:01
we need you can do another facility also we have here when example also we have
1:06:08
here now in the autoscaling group let me give the name first name my
1:06:15
auto scaling Okay, think in this way now onward
1:06:21
instead my human being from my IT team is going to monitor
1:06:30
the the um the computers manually.
1:06:35
Okay, this manual thing will be automated by this book
1:06:42
and whenever something trigger okay then they you use this launch
1:06:49
template okay I don't have any launch template
1:06:55
okay now there's some difference between launch template and the launch configuration we have actually created
1:07:00
launch configuration okay so what the difference I'll tell you in a minute but let me switch to the launch configuration.
1:07:08
Okay. So there's some difference almost they're same but there's some difference between launch template and the launch
1:07:13
configuration. We'll discuss but right now in my case I created a launch configuration.
1:07:19
Okay. What difference? I will tell you in some minute maybe in the next class. So we have
1:07:25
created a launch configuration. Okay. Launch configuration we have
1:07:32
created. So I that's why I'm going to select here launch configuration. This is what we have created.
1:07:40
Okay. So whenever this autoscaling group trigger this launch configure to be used
1:07:47
according to this setup. Okay. My instance will launch
1:07:54
automatically. Okay. Next
1:08:00
network would be where you want to launch this instance because they are not yet launch going to launch in the
1:08:06
future. So where are the autoscaling group? Okay, launch a new computer this one.
1:08:13
Which VPC you want to launch? So I want to launch this guy into my VPC.
1:08:21
Which is you want to use? I want to launch this guy into public or private.
1:08:27
Let me launch in the private as per way we have done in last class also mostly we put the computer behind this load
1:08:33
base in private world. So this private AG I want to use. Okay this
1:08:40
private also and sorry there we have one more private
1:08:45
this private also two we can use why because I want to highability. So my
1:08:51
autoscaling group launched some instance in this private instance some in this private instance. So because of my
1:08:57
agility zones goes down failure we have other copyright in other computers that's what
1:09:03
the concern I have explained my last classes okay click next advanced configuration
1:09:11
do you want to launch this computers okay these computers
1:09:16
behind the without the load balancers maybe we can launch without load balancer also there's some use
1:09:23
cases where I want to launch more computers ers without load balancers. There's some specific use case for this.
1:09:29
But in according to our use case, I want to launch this behind the load balancer.
1:09:35
Okay. So I want to launch behind the load balancer. Okay. So do you want to create a new
1:09:41
load balancer? You can create also from here or do you want to use connect the existing ones? In our case, my load
1:09:47
balancer already exists. I already created this. Okay. Now, which one you want to use?
1:09:54
the older one or the newer one means ALB NLB GLB I
1:10:00
want to use the newer one newer one we have a console target group target group is a part of new one in classical we
1:10:06
don't have any target group concept any so I to put in the newer load balancer
1:10:13
that I already created and tag group also be created which target group we have to use so this is target group I
1:10:19
created my TZ I want to use this target group It means my autoscaling group when they
1:10:26
launch the instance they will launch they will launch in this target group.
1:10:34
Okay. Health check you want to do for example like I'm not changing here. So by default health
1:10:40
check what they have I would use that one. Okay. Other things we want going to
1:10:46
discuss right now but nothing very technical it's cloudatch. We'll talk about the cloud watch in the future.
1:10:53
Okay, here the the uh scaling policy coming from
1:10:59
okay means when you want to launch a
1:11:04
computer what is the maximum limit minimum or desire you have so let me set
1:11:09
one one for all just for I don't want maximum I have more than one minimum one and desire one
1:11:18
okay let me use one means whenever this autoscaling groups
1:11:23
Created created we asking my desire is one. That means
1:11:31
whenever you create just check do you have any instance running any instance
1:11:37
running here. Okay. If no then my desire is one at
1:11:44
least one you have to launch and that case guys because of this one. Okay. You will see one computer automate launch as
1:11:51
soon as you create this. So example right now
1:11:56
right now in my target group
1:12:03
in this target group we have no computer nothing is great.
1:12:09
So we asking in this target group if you have zero but I'm I'm asking my desire is one. So
1:12:18
as soon as my auto stream group created because your desire is one means we
1:12:23
looking for this is my desire and that is not there. So this will go and create
1:12:29
one for us. Okay scaling policy guys I will talk about
1:12:36
this concept in in tomorrow class but the way I explain to you this concept you know cloud watch metrics rules.
1:12:44
So creating the rules all those things has been come in the scaling policy
1:12:51
right now I'm not creating any rule I'm going for by default with no rule means
1:12:57
whatever setup I am writing here that according to the setup will work for example if I write three
1:13:03
three will launch okay there's no rule so this computer will launch automatically but there's no policy they
1:13:09
are not going to use any cross to check the matrix Okay. So that's what I'm doing. So my
1:13:16
I'm controlling my launches with auto string. Right now there's no
1:13:21
rule checking or policy checking but how to write a rule I will discuss tomorrow. Okay. I'm going for bio numbers.
1:13:29
Okay. And then click next. Okay. If you if you is instance uh
1:13:38
terminated launch do you want to send any notification SNS that was I was talking about again I'm not doing right
1:13:44
now but after SNS topic we'll learn I'll show you how to add this again nothing very technical
1:13:50
click next as a tag click next and the setup
1:13:57
okay according to this setup this setup is a setup for
1:14:02
autoscaling group and Autoscrew group uh sees here. Okay. You have configured me
1:14:10
in a way that you set me your desire is one.
1:14:17
So I'll check your target group. If the computer is not running there of comp
1:14:23
instance is not running there anything and your desire is one. So this you guys
1:14:29
called current uh status or current state if current state is zero and your
1:14:35
desired state is one. Okay in this case mean what I'm looking
1:14:40
for is not there. So I will launch one for you automatically. You don't have to manually do it. That's what I will do
1:14:47
for you. But how I launch? I need a configuration. So you have already given me the configuration, right? I will use
1:14:53
this configuration to launch. Okay. And that's what so when I click
1:14:59
create according to my desire. So they're updating my capacity.
1:15:06
Okay. Updating my capacity here. And because our desire is one.
1:15:14
Our desire is one. So in any of these a zone they are launching your instance
1:15:21
according to a capacity. Right now they're launching. only the instance is one.
1:15:27
Okay. But in sometime what you will see okay in your target group one computer
1:15:33
been added in sometime. Okay. Plus in EC2 also you will see one
1:15:40
computer launch in EC2. Okay. So behind this they're launching in some time after they launch you will
1:15:47
see it being launched. Okay. I think this is one they launch right now I believe.
1:15:55
Okay, I think this is one they launched right okay behind this. So this instance maybe
1:16:02
they might have launched already maybe. Okay. So this instance has been
1:16:08
launched according to our plan which we we submit and as you can see our
1:16:14
autoscale group name this one. So this instance has been launched by my autoscale group. Okay. Okay, but if you
1:16:21
see the other instances guys all other instances guys we have launched manually. So there's no
1:16:27
autoscaling group name cover manually we have launched but in this instance
1:16:34
okay it's been launched by autoscaling group automatically this come
1:16:41
and after they launch they will add behind the scene in my tiger group of the lower balancers.
1:16:49
So you see here they have been load here. See here they've been loaded automatically. One has been registered
1:16:54
and we healthy because I have the health check. Okay. Now if I go to my uh my uh ALB you
1:17:02
can see this website going fantastic right working great. But this time this
1:17:08
instance come automatically and it's been completely managed by autoscaling group. One
1:17:15
beautiful thing guys about the auto steering group is because our desire is
1:17:22
let me refresh this page because our desire is
1:17:27
one they launch one for us. Interesting thing they keep on watching this due to
1:17:33
any reason if any reason if your instance is terminated
1:17:41
I manualize terminate this instance if instance terminated.
1:17:47
Okay. Autoscreen group is keep on checking. Okay. If they find instance terminated
1:17:54
okay but your desire is one they again relaunch one more new phone. So you see
1:17:59
here in a minute you'll see one more instance they're going to launch in sometime as soon as they see because
1:18:07
they keep on checking the health check as they find the health is down.
1:18:14
So the health is down the remove from here from your target group. Autoscreen
1:18:21
will see that has been down. Okay. Then they relaunch one new for
1:18:28
you. So in sometime you see guys automatically one more new going to come up in some time again guys they're
1:18:36
doneing after this they have some kind of grace time also that's what I'll show you how to change but in some time
1:18:41
you'll see one automatically launch okay even though guys in the autoscaling
1:18:46
group also you can see the the the you can see these options also for example
1:18:52
my desire is one okay and if you see The activity
1:19:00
okay activity guys is the about the notification but in the activity history
1:19:07
here you can see that right now initially when you launch I had zero but
1:19:12
because your desire was one so they've launched one 0 to one it's called
1:19:18
scaling auto scaling scale out but sometimes you'll see one more history come up see here they check the
1:19:26
instance out of service in EC2 indicating you have terminated or
1:19:32
stopped the instances. Now this information come in your autoscaling group automatically.
1:19:39
Okay. And now in progress in sometime you you will see they will launch one more so one more history come up and now
1:19:46
what they say I found you have zero instances now again we are increasing to one this go prein service.
1:19:55
Okay, that's was successful and your load bench SC your ELB
1:20:01
connections has been drained out means it's not able to connect. It looks like instance terminated or stopped.
1:20:08
So they ask autoscaling group because desire is one. So launch one more. So
1:20:14
pre-in service is going on and sometime you will see there was successful one
1:20:19
more instance launched. Now if you see
1:20:25
if you see here one more new computer has been launched right now and this has
1:20:30
been launched again by auto in by autoscaling code and that has
1:20:36
been automatically registered to your target and finally if you hit enter
1:20:41
you'll see the game the new website. Okay, but maybe if you want
1:20:48
uh let me show you some more options here instance refresh that is again that is
1:20:55
not monitoring that we will talk about the you know all the
1:21:02
things in some time but yeah instance manager let me show you some important things if I can show you yeah this is
1:21:08
what guys you can see okay instances one is in service and one is terminated one
1:21:13
I launched terminated that's also come up here and service also been visible here. Okay. But let's say in detail of
1:21:23
this instances we have one desire but let me edit this and let me increase my
1:21:29
desire to two or let's say three. Okay. Now I'm asking
1:21:36
I'm asking that my total desire is three. I want my auto telling is keep on checking and if they don't have free
1:21:43
they will launch three for you. Okay. But but obvious guys
1:21:49
okay if design is three you want three but you want you won't go more than maximum right?
1:21:58
So you need to say maximum at least three. Maximum means right now guys I'm
1:22:04
launching by setting this values but tomorrow guys when I test with the cloud watch so as the more RAM use they launch
1:22:12
one more one more one more. So let's say you can set I can't go more than 10.
1:22:19
Okay. So whatever desire would be means desire means when I set up the issue
1:22:25
instances I want always two but desire obviously can't be more than maximum.
1:22:31
Okay. So that's what the warning is. Now you set your your
1:22:38
uh desired tree. Okay. and they're updating your capacity.
1:22:44
So automatically they're launching total two more or total three they're trying to make and in this case if you see your
1:22:52
activity of autoscaling group in the history okay and that is they say now
1:22:58
you change your then your limit constraints here and you
1:23:04
asking for three right now is one so I'm I'm doing auto scaling for you scale out
1:23:12
okay and trying to make a difference of real current and desire current is one and desire is three I'm doing scale out
1:23:18
for you and now in the automatically
1:23:24
three total two more instances but total three is going to launch here one two three one two or maybe one more they
1:23:31
launching okay and as soon they launch that has
1:23:36
been registered here see one more they also launching behind the scene in some time they also
1:23:43
been rest of you. Okay. And now if you do the autoscaling load balancer means load balancing load
1:23:51
balance by itself both has same data but intel you guys know behind this and I
1:23:56
explained in my last class they are doing load balancing one and other
1:24:02
okay so that is the whole idea. Now three has been launched now this has been launched keep on running.
1:24:10
Good thing is due to any of the reason if one of my computer goes down instance goes down.
1:24:16
Okay, maybe let me stop in this case not the terminate your autoscaling group will restart this
1:24:24
guy or maybe create a new one. Okay, but they make sure it should be
1:24:30
always three. Okay. When used is stopped by sometime you see this will
1:24:37
again because your desired is three. So make sure the instance total uh
1:24:44
running at any point in time would be always three.
1:24:49
Okay. So this is some of the vocabulary I explained to you about the autoscaling
1:24:56
group and the colon configuration. But this will make more interesting when
1:25:01
this thing to be automated. This is automated only but enter automatement means now this will be done by checking
1:25:09
the rules the school metrics for this I have to first explain you cloud watch and after I explain the
1:25:15
cloud watch then we will we will connect this rule in the autoscaling code setup
1:25:22
will be almost the same there was some extra attribute I will add okay of the
1:25:28
cloud watch and the rules here and that will be as soon the network goes down or
1:25:36
above this benefit or RAM CPU. That's why I'll explain to you. So this launching new and adding you will be
1:25:44
will be um more makes sense. Now this one is first dering
1:25:51
okay because this is goes down. So from autoscaling group the target is ruring
1:25:57
this called draining also. Okay. And after training because my DJ
1:26:03
is three then launch they will launch one more here this rest. So one more new right they launch and
1:26:09
the resting here everything is automated you don't have to worry about that. Okay so powerful service. So typically this
1:26:17
is the way we always use right. So automatic launching the instance is done by launch configuration right desire and
1:26:25
checking the rule done by autoscaling group. Everything put in the target group. load balancing is done by ALB.
1:26:33
Network performance loading is done by NLB and above this we have DNS all those
1:26:39
component connect together have powerful setup that's what the very uh that's what the particular typically the
1:26:45
architecture in the real world also okay so that's all guys we'll continue
1:26:51
this topic this topic is not yet complete we'll continue this topic tomorrow any query if you have you guys
1:26:56
can
1:27:04
No ras discussing on the data dog doesn't makes any sense as a different tool all
1:27:09
together but we will come up this kind of tool training also like data talk new
1:27:16
splunk app dynamics at the different training you guys can join that
1:27:24
Okay. So any query guys if you have you can
1:27:31
ask me. Yes. Kas Rasu I will talk about launch
1:27:40
temple also and plus the difference also different minimum desire difference also
1:27:46
in my tomorrow class. Okay. Yes. Argo we can integrate with
1:27:52
Prometheus also not in this class but if you are the part of my Promethus training I will tell you how to
1:27:57
integrate the matrix monitoring of AWS with the Prometheus in my promethus class
1:28:07
I know autoscaling and loss are not the same job load balancer to balancing the load
1:28:15
of the computers who the computer can say who will launch the computers
1:28:20
automatically is done by auto scale. Okay.
1:28:29
How the modeling of low bener work? I think I told you puja already in very detail the when you this this diagram
1:28:35
when I show to you right I explained in very very detail. Okay. This process has
1:28:42
been done by cloudatch. Okay. This demo I'm going to show you in tomorrow class. You will see practical
1:28:47
way also. Okay. But the process of monitoring is done via cloud watch. This
1:28:54
what I explained to you. But tomorrow I show this part demo in my tomorrow.
1:29:08
So uh Sudhaka in my last class I had discussed in very detailed discussion on ALB and LB plus I show the demos also
1:29:15
right of ALB and LB in my last classes.
1:29:26
So horizontal scaling and horizar
1:29:35
adding more and more computers is called horizontal scaling.
1:29:40
If you do it manually that is normally known as hor horizontal scaling. But if you uh if computer added automatically
1:29:48
then it is mostly known as horizontal autoscale. But typically we're going to use this
1:29:54
bigger word we always use the word called autoscaling. So when we say autoscaling it means computer is adding
1:30:00
okay in the horizontal way. But only difference what you asking is manual and remote.
1:30:14
A brief on adding is easy to configure OS to my AMI. Nothing person my AMI is
1:30:22
the AMI we already created in my initial classes in this training only where I show how to create our own AMIs.
1:30:29
Okay. So that was I explained you that's why I keep using CMI otherwise if you
1:30:35
use the blank AMI or AMI you do always configure the uh web server for testing.
1:30:41
Okay that was only reason.
1:30:47
Thank you so much sir. Uh we teaching of VPC and it will also help me interview for British company that very nice uh
1:30:55
big trend uh congress for my side.
1:31:06
uh person I explained you already a load balancer is sending the traffic to load to back end ser server right why the
1:31:15
reverse proxy concept I explained in my lesson classes that's how it work
1:31:25
okay uh while there's No security group in
1:31:31
NLB. If you see the NLB here. Okay, let me
1:31:36
show you the load balancer. Okay, this is what the NLP guys we have
1:31:41
created. Okay, NLB we have created. And if you try to see in the NLP, we have no
1:31:50
security groups. Okay, there's no firewalls. If you see anywhere
1:31:56
you won't find any uh security group in an LLB.
1:32:02
Okay. But if you go very interesting question somebody asked me what do you ask me guys? But if you see any other
1:32:08
load balances like ALB in ALB guys we have a uh security
1:32:15
groups. Okay. Why? Because NLB guys is is very
1:32:22
highly performant for network traffic. So what NLB do actually behind the
1:32:27
scene. Okay. Any other load balancers the client is actually connecting to the
1:32:34
load balancer. Load balancer take the request create a new session. Okay. And
1:32:40
send to the target computers like AC any other load balancer like ALB, CLB, other
1:32:46
guys. Okay. So it means for the client perspective
1:32:52
they are connecting the ALB or create a session
1:32:57
to the ALB. Okay ALB and sending the all the
1:33:02
application data to ALB ALB is one who checking all the application layers data at the ALB side and creating new
1:33:09
connections and to the send EC2. So with the EC2 perspective traffic is coming
1:33:14
for ALB. So ALB is a client for EC2. That is the reason in the security group of EC2 we allow the IP for ALB.
1:33:23
When the ALB we have a separate security group that we allow the IP of clients
1:33:29
okay because client perspective guys they are connecting to ALB. They think ALB is a real server and that is we have
1:33:35
a security group in the ALB is what I explained to you. But in NLB guys you know what happened. Okay, NLP work and
1:33:43
the network layer they don't have a capability to create assessments or don't have a capability to check the
1:33:50
application headers. Okay, so any
1:33:55
traffic come from the client. Okay, NLB is mostly look work like a
1:34:01
router not a proxy server. any traffic come they send as it is to the EC2
1:34:07
instance without checking any application header or session and the budget presented layer of OSI layer
1:34:14
they're not creating any session it means NLB is not working as a proxy or reverse proxy for you the way I
1:34:20
explained you in my last classes about other load balancers okay it means any traffic come from the
1:34:27
client the edges send it only difference between router here is they have cap load balancing there's extra things what
1:34:33
router doesn't do for you as such. So any traffic come up as it is they send
1:34:39
to this client next time they send this one this one this one like a load balancer but here they are not reading any
1:34:47
application headers okay that that is the reason that is the
1:34:54
reason right means they're not creating any session to the client as it is they are sending the packet to the issued
1:35:01
instance that is reason there's no meaning of the security group in the ENLB
1:35:06
And that is the reason guys okay this is instance should have a capability
1:35:13
capability to connect from outside world. So in this issue instances we have to
1:35:20
properly write a security group for the client. So instance guys if the security
1:35:27
group is blocking the client request from outside world they won't able to connect.
1:35:33
Okay, want able to connect. Okay, but this design is not the right design. So
1:35:39
not advisable to connect in directly to NLB.
1:35:45
Okay, otherwise a lot of issue come up. It mean any instance running in the private world won't able to connect. Client is actually directly connecting
1:35:51
to instance. So any issu in running in the private world won't able to connect and any every issued instance in this
1:35:58
world should have allow all the access of internet the way you normally use a
1:36:04
normal instances that is reason okay this diagram is not at all advisable and that is reason guys
1:36:10
this is not at all usable diagram the diagram that is right diagram is what I explained you and this is what the
1:36:17
tactical we did so the setup would be client is connected NLB B
1:36:23
N L N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N N L behind the NLB we have ALB
1:36:29
ALB and then we have instances no this kind of diagram explained
1:36:34
okay so in this case client is coming to NLP and they're sending
1:36:39
request here or here and here without checking their application headers
1:36:45
without creating a connection as a proxy connections so there's no use of security group it means Client is
1:36:51
directly connected to ALB. So client field client field they're directly connect to
1:36:57
ALB and that is the reason guys here in the LB we allowing all the clients all the clients all the clients
1:37:05
okay and because they're not checking any application header or they're not creating any sessions that that is one
1:37:12
of the reason why NLB is super faster and having very low latency.
1:37:18
Okay. And that is reason guys in NLB we don't have we don't have any um you know um what I
1:37:28
say any security group implement okay so what good I think so you asked
1:37:34
me this question that's thank you very much for this for asking this great question so that everybody can get the idea what external we will do for you uh
1:37:43
egress only puja we will definitely discuss in the upcoming class there's some smaller topics then PPC in this way
1:37:49
I skip this topic because some of the topic has some basic requirement of um
1:37:56
of uh uh load balancer so I thought first to cover this when again go back
1:38:02
to VPC this egress only and some more concept like transit gateway those things we'll discuss and upcoming
1:38:08
classes okay so
1:38:16
how you research deeply Okay, we'll definitely discuss something on them that way. Okay guys, see you uh tomorrow
1:38:23
uh with some more concept of autoscaling group and the cloud. My take you good
1:38:28
and good night. Take the class on integration of panda with AWS. I use this is I think one of
1:38:35
the task I have given I will give you definitely give the hint in my upcoming classes okay to you how to integrate
1:38:42
your local pen drive to AWS cloud. Okay. This is one task I think I given in my
1:38:47
initial classes. Okay. So, um that's all guys. See you tomorrow
1:38:54
with some more on take care. Good night.


# 12.1 Step-01- Introduction to Ingress Basics

-: Welcome back.As part of this section we are going to learnabout Kubernetes Ingress basics.The first thing we need to know about Ingress is,what all key items involvedinside the Ingress service manifest, right?So the one important thing is Ingress annotations.Ingress annotations are nothingbut the load balancer settings,which we are going to provision using this Ingress service.And another important thing is inside the Ingress spec,the first item which we need to define is Ingress class nameto which this Ingress service need to be associated toor belongs to.By default if you already created Ingress classand set that is default equal to true.So then we really don't need to define Ingress class nameinside of our Ingress service manifest.If not, we need to definitely define this.And in Ingress spec,additionally, you can define Ingress routing rulesand also default backends.So all these things we are going to practically implementand then see in various scenarios from Ingres perspective.Additionally, there will be a annotation referenceand there will be close to 30 plus Ingress annotationsas on today available for ourKubernetes AWS Load Balancer related Ingress.So these are the settings here.So, ALB Ingress Kubernetes,I will load balancer name, group name, tags, IP addressand then your load balancer type,which is nothing but scheme.Internal load balancer are internet facing load balancer,and where your load balancer need to be deployed to.Means like which subnets,and if you want to specifically associate,instead of default security groups,any additional security groups.So you can use thisand then provide the security group ID.So like this,there'll be huge amount of annotations available for uswhich can be defined as settingsfor your load balancer,inside the Kubernetes service manifest.So now let's come back here,and we discussed the key items involved hereand also reviewed on a very high levelwhat all annotations we are going to have.And for complete 30 annotations if you want to review,so review this reference linkand you'll get the complete pictureon what all these are and why they will be used for.And let's come back here,and we are going to do two demos as part of this section.One is Ingress service with a default backend,and the other is Ingress service with Ingress rules.So that we get the complete handon how to define the default backendand also how to define a simple Ingress rules.So that's the reason we have split itinto two demos so that we get the complete clarityon understanding and implementing those two use cases.And let's understand the network designfor the default backend.So, in AWS Cloud we have created the EKS cluster,and which as part of thatwhen we have created these EKS cluster using EKS CTL,so it also created a VPCand also created a publicand private subnets and also NAT gateway.And from private subnetthe outbound communication goes where NAT gatewayto our E case cluster control plane.And additionally, if you see herewe have also created a EKS worker nodes.We have created two worker nodes in the private subnets,we call it as a private node group.And we deployed our simple application NGINX app onedeployment in our private node group,and which will create the pods for us.And now this respective deploymentwill be fronted with the NGINX app one node port service.And this node port service, right?Will be associated to the Ingress resource, right?So you'll deploy Ingress resourceand inside the Ingress resource default backendyou are going to associate this node port service.And whenever user accesses your DNS URL,ALB DNS URL slash app one slash index.html,and it is going to get the requestto this application load balancer.And inside the default backend you have the referenceto your node port service,which is in your Kubernetes cluster.And from there it will go to your respective pod.And if you see here, you can see in the Ingress spec,from spec only I have copied here.And Ingress class name,you have defined whatever the Ingress class you have definedthat my AWS Ingress class.So which means this respective Ingress service,whatever you are going to deploy is going to be associatedto your Ingress controller,which is AWS ALB Ingress controller.And you can see we have definedthe default backend and service,and the name of the services app one NGINXnode port service.So, which means the request comingto this Ingress serviceare this application load balancer,goes to the default backend,which is nothing but this node port service.And from there request will be routedto the application pod.And now this is with the default backend.Now let's see with the Ingress rules.So whenever you define the Ingress rules,so it is going to look like this.So earlier you have seen the default backend here,in the spec you'll find something called rules.And in HTTP and in paths,and in path you set slash.Anything with slash go to app one NGINXand node port service.Which means anything with slash star,anything under the root contextit will go to the NGINX node port service,and this node port servicewill forward it to the, your NGINX app one.So this is what is the high level thingwhich we are going to implement with our two demos.And in addition to thatwe also need to understand something called,how AWS Load Balancer controller workson a high level, right?So this is the picture,I have brought it from this reference link available for usand we are going to discuss about thisand understand multiple things here.So if you see here, these are the AWS resourcesand here you can see this is the Kubernetes cluster,and this is the Kubernetes APA server.And you already deployed your ALB Ingress controller,and you see you have the Kubernetes API serverand also you can see the worker nodes here,you have three nodes here.And if you see here we have three apps,A comma B comma C, you can see here, right?So we have pod A,pod B,and pod C.So, each application has three pods here,pod C related third pod is not depicted here,but let's consider you have three worker nodesand three pods per app here.And now these three podshas a ALB context path based routing implemented,which means this pod A, right?So, pod A, whenever you have the slash star root contextthen the request will go to pod A.And when you have the slash productsrequest will go to pod B.And when you have slash accounts,whenever in your URL, right?So, abc.com/accounts, the request will go to pod C,which is nothing but your application C.So that's about the applicationwhich is implemented or deployed here.So let's assume that way.Now let's go to the next level,which is node port service here, right?So, for every applicationyou'll have its own node port service, right?So, pod A, you have the node port service,pod B, you have the node port service.In same way for pod Cyou don't have the node port service.So we'll discuss this later.But for now, so, for pod A,this is the node port serviceand whenever the request comes to slash star,so it will go to that respect your target groupin the load balancer, application load balancer.And from there it will go to the node port service Aand it will serve to the pod A related.Means like it will get the content from pod Aand display to the user.And same way for slash productsyou have the target group service B,which goes to your node port service B.And from pod B the request will be servedto the user, right?Now these two, whatever you are seeing, the pod A,and then port B is using,means like these applications are usingthat traffic mode instance type.So which means that traffic mode instance type is nothing,but you are going to use the node port service,which means these nodes are registeredto your target group in the load balancer,and those nodes,related node port service will be usedto send the traffic to your pod.But when coming to traffic mode IP, right?So which is the third application,which is the application Cwhere the rule is slash accounts.So here directly in this target groupthis pod related IP is present.So when you go to your load balancerand verify for this target group, which is pod A, pod B,you'll find that your nodes are registered there.But here you'll find directly the pod IP isassociated with it.And this target group C, right?Which is mode of type IP,traffic mode of type IP is primarily usedfor fargate related workloads,on a high level we need to understand about that.Now, so let's understand this,you have deployed three applicationsand three deployments and those related pods created,and three node port services created.And here comes the important thingwhenever you deploy the Ingress service.So this Ingress controller will check for the APA server,any Ingress services were deployed for me.And if deployed it will takeand then it will check for the APA serverand then deploy that Ingress service for us.And that Ingress servicewill create a application load balancerwith listener type as HTTP or HTTPS,and also create all these rules for usand also create the target groups for us.So that's about the high level,about how all this is going to work.We are going to see this traffic mode IPimplementation in detail during the fargate demos also.And in these Ingress demoswe are going to anyway, see the objects like target groups,how the node ports are registered thereand all those things in detailin a practical implementation.So there we get the clarity about this picture in detail.So not only in this basic demobut we'll have the context part basic demo,and also hosted our basic demo.At every point we are going to discussabout this traffic mode instance and then IP.So we don't need to worry about that,we have only seen the picture,we didn't see the real implementation.So we are going to see in eachand every demo,and we'll understand there in detail.So I'll see you in the next lecture.Until then, bye-bye.
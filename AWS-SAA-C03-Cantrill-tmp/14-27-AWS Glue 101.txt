Welcome back and in this lesson I want to talk about AWS Glue.
Glue is an interesting product which starts to feature more in the AWS exams and more in real world projects which I've been exposed to.
Now I'm only going to be talking about it in terms of the architectural theory in this lesson because anything more is well beyond the scope of this course.
So let's just jump in and take a look.
AWS Glue is a serverless ETL or Extract, Transform and Load system.
There's another product within AWS called Data Pipeline which can also do ETL processes but this uses compute within your account.
Specifically it creates EMR clusters to perform the tasks.
Glue is serverless. AWS provide and manage all of the resources as part of the managed service.
Now at a high level Glue is used to move data and transform data between a source and destination.
And these sources and destinations are databases, streams or other stores of data such as S3.
If you want to take source data and restructure it or enrich it then you can use a Glue job to handle that in a serverless way.
Glue also crawls data sources and generates the AWS Glue data catalog which I'll cover in more detail next.
Glue supports a range of data locations.
Source data stores such as S3, RDS and any JDBC compatible databases such as Redshift or others and DynamoDB fall under this category.
We've also got source streams such as Kinesis Data Streams and Apache Kafka and then we've got data targets which include S3, RDS and again any JDBC compatible databases.
So that's AWS Glue at a high level. Now let's quickly focus on data catalog.
AWS Glue provides a data catalog and if you've never heard that term a data catalog is a collection of metadata combined with data management and search tools.
Essentially it's persistent metadata about data sources within a region.
The AWS Glue data catalog provides one unique data catalog in every region of every AWS account and it helps avoid data silos
because rather than data being hidden away somewhere managed by a particular team and not visible to any other teams in the organization
it makes this metadata, the data structure, available to be browsed and then brought into other systems using the ETL features of Glue.
So it's something that improves the visibility of data across an organization.
Now various AWS data related products can use Glue for ETL and catalog services, things like Athena, Redshift Spectrum, EMR, AWS Lake Formation, they all use data catalog in some way.
And the way data is discovered is by configuring crawlers and giving them credentials and then pointing them at sources and letting them go to work.
Visually this is how the components of Glue fit together.
Let's start with the data catalog functionality.
So we have some data sources on the left, S3, RDS, maybe some JDBC compatible stores, DynamoDB, Kinesis, Kafka and much more.
So we configure data crawlers which connect to these stores.
They connect, they determine schemas, they create metadata and all of this information goes into a data catalog
which means that rather than those data stores being siloed we now have visibility of them across the organization.
So this data catalog can be connected to by users of the AWS account and so all members of a business can get value from all of the data by using it in other areas than the area that it was gathered in.
So it essentially publicizes data from across an organization.
It makes it visible.
It allows a finance team to use data that's gathered by different teams within the organization.
Now the other components of Glue are Glue jobs and the data catalog is also used as part of Glue jobs.
Glue jobs are extract, transform and load jobs.
So data is extracted from a source and then loaded into a destination and in the middle Glue can perform transformation using a script which you create.
Now Glue is serverless and as such you don't need to manage the compute which is used to perform the transformation.
Instead AWS maintain a pool of resources and these are used to perform the transform tasks when required and you're only billed for the resources which you consume.
Now Glue jobs can be started manually or invoked in an event driven way using events from other sources or scheduled events within EventBridge.
And that's pretty much what you need to understand about Glue for the exam.
It's an extract, transform and load or ETL service and a data catalog service which is serverless and it forms part of the data and data analytics services provided by AWS.
Historically the ETL part of this has been done using data pipeline and so in exam questions you will generally only have one or the other.
So either data pipeline or Glue.
If you see both then look for keywords such as serverless, ad hoc or cost effective and if you see these you should pick Glue rather than data pipeline.
So data pipeline does offer some additional functionality versus Glue but over time it's my expectation that the Glue product will replace the functionality offered by data pipeline.
At this point though that's everything I wanted to cover in this lesson so go ahead and complete the lesson and then when you're ready I'll look forward to you joining me in the next.

Welcome back, and in this lesson I want to talk about Amazon Athena.
This product is one of those hidden gems available within AWS,
which are really valuable as long as you understand the features that it provides.
So let's quickly jump in and explore the architecture.
So what is Athena?
Well, it's a serverless, interactive querying service.
Put simply, it means that you can take data stored within S3
and perform ad hoc queries on that data,
paying for only the amount of data consumed while running the query
and the storage used within S3 to store the original data.
It has no base monthly cost, no per minute or per minute.
Athena is how it handles the structured, semi-structured, and even unstructured data that it uses.
Athena uses a process called Schema on Read,
and the way that I want you to imagine this is like a window or a lens
through which you see the data in a certain way,
but where the original data is unchanged.
Your original data stored on S3 is never changed.
It remains on S3 in its original form.
The Schema, which you define in advance,
modifies data in flight as it's read through the Schema.
So it translates the original, unmodified source data
into a table-like structure as it's read through the Schema.
So as you query the data, the original data is read, left unmodified,
and the translation only happens within the product during the querying process.
I can't stress this enough.
The original data is maintained in its unmodified state within S3.
Normally with databases, you create tables and you have to load data into those tables.
The data needs to be in the format of the tables,
or you need to perform ETL processes,
which stands for Extract, Transform and Load.
With Athena, this isn't required.
You define how you want the data to look in the form of a Schema,
and in a non-modifying way, data is loaded through this on the fly,
and then any output can be sent to other AWS services.
Now let's look at this visually,
because it's going to be easier to understand if you see the architecture.
So Athena starts with the source data, which is stored on S3,
and conceptually, this is read-only.
It's never modified.
Now the product supports a wide range of data formats,
and this is growing all the time.
Some examples include XML, JSON, comma and tab separated values,
Avro, Parquet, Ork, and even custom application log formats,
such as Apache and AWS services,
such as CloudTrail, VPC flow logs, and more.
So this data on S3 is fixed.
It doesn't get changed,
and that's probably one of the services' most fundamental concepts
that you need to understand,
and it's why I've repeated it probably ten times already in this lesson.
So inside the product, you create a Schema,
and in this Schema, you're essentially defining tables.
These tables define how to get from the format of the original source data
to a table-like structure.
So unlike a traditional database where a table is the final structure,
in Athena, you're defining a way to take the original data
and present it in a way that you want,
which allows you to run queries against these tables.
It's almost like a recipe.
You're defining how to convert from ingredients to a final meal.
It's a method to get from the source data
to the structure that you want to be able to query.
So these tables within Athena don't actually contain data
like a traditional database product.
They contain information, directives,
on how to convert the source data to be able to query on it.
So this Schema is used at the time of querying when data is read,
and this is why it's called Schema on Read.
The data is conceptually streamed through the Schema while being queried.
So it can be queried in a relational-style way
using normal SQL-like queries,
and then the output can be displayed on the console,
saved, or output to other AWS tools.
And all of the time for this whole process,
there's no base or constant cost.
You just pay for the amount of data consumed by the query,
and you can even optimize the original data set
to reduce the amount of data that has to be used for individual queries.
The key thing to understand about Athena going into the exam
is that it has no infrastructure.
You don't need to think about setting up any database infrastructure in advance.
You don't need to think about data manipulation in advance,
and you don't need to load data in advance.
Keep those things in mind when going into the exam.
They will help inform you when Athena is the right choice and when it's not.
So Athena is great in situations where loading or transforming of data isn't desired,
where you have data already on S3 in a source or raw format,
and you need to query it without doing any loading or transformation.
In the demo lesson, which is coming up next,
you'll see an example of using a large data set, the OpenStreetMap data.
If you needed to load and transform that prior to use,
it would massively reduce its utility.
A benefit of Athena is how you don't need to do any loading
or transformation of data in advance,
and this makes it ideal for ad hoc or occasional queries of data in S3.
Why?
Well, because you don't need any servers running in advance
and you don't need to think in advance about loading or transformation.
You have a business need and immediately run a query.
Athena is also useful if you're a cost-conscious business.
It's great because it's serverless.
You pay for any data read as part of a query.
There are no base costs and no upfront costs.
Again, think ad hoc, sporadic and cost-effective.
Athena is also the preferred solution,
especially in the exam for any queries which involve AWS service logs
because it has native support of VPC flow logs,
cloud trail logs, elastic load balancer logs, cost reports and much more.
And it can also query data from the Glue data catalog
and supports web server logs.
And again, these are keywords to look for in the exam.
A newer feature of Athena is called Athena Federated Query.
Now be really careful with this one because I don't want you being confused.
For most situations, if you see SQL mentioned or NoSQL mentioned
or any specific database product,
then the answer to that question is likely not to be Athena.
But Athena now has the capability to query non S3 data sources.
Athena uses data source connectors that run on AWS Lambda to perform federated queries.
So a data source connector is basically a piece of code
that can translate between a target data source,
which isn't S3 and Athena.
So you can think of a connector as almost like an extension to Athena's querying engine.
So you've got pre-built connectors which exist for data sources
like CloudWatch Logs, DynamoDB, DocumentDB, Amazon RDS
and even other JDBC compliant relational data sources
such as MySQL, Postgres and many more.
So Athena Federated Query really is a feature
which is going to massively improve the utility of the product.
Now that's all of the theory that you need to be aware of for the product
as well as some of the key use cases that you might see in the exam.
So at this point, go ahead, finish this lesson and then when you're ready,
I look forward to you joining me in the next.

# 22.3 Step-02- Review kubernetes manifest - Deployment and Service with NLB Annotation

-: Welcome back.Let's go to our GitHub repository now.And we are in section19, which is ELB network load balancers.So we are adding this as part of a new section now,so that's the reason we have added it at the endof the course, even though we are going to have these videoswhenever we complete this section 08 and then 09,after that you'll have the section 19 related videosbecause, so that is the order you need to watch,which is nothing but.So first you'll learn the 08 new ELB applicationsload balancer related things,which means all the Ingress related 14 demosyou'll complete.And after that you'll complete yourFargate related demosand then you'll come back to this one which is section 19.Where is it?So it is here and you are going to complete this six demos.So now let's come back hereand we are in 1901LBC and LB basics.So what is LBC is nothing but load balancer controller.So the naming also I've given ELB network load balancerswith LBC.LBC means load balancer controller.So we'll go inside this,and if you see here as part of introductory sectionwe already understood what we are going to implement, right?And what exactly is the cloud provider load balancercontroller legacy,are what is the latest load balancer controllerlatest and all those things.So as part of step two, we are going to review ourNGINX app three deployment.So let's go to our Visual Studio Code hereand we are in section 19.And in section 19 we are in1901LBCNLBbasics.And there in the cube manifest we are reviewingthe 01 NGINX app three deployment.So this is again our standard NGINX deployment.And as part of our Ingres demos.our application load balancer demoswe already learned all these things in detail,which means we have app one deploymentand NodePort service,app two deployment and NodePort service,app three deployment and NodePort service.So from there we have brought this app three deploymentrelated manifest.So standard deployment manifest.And now we'll move to the next stepwhich is nothing, but we'll review the 02 LBCNLB loadbalancersservice.yaml.So here, if you see here the name, right?So the name of yourload balancer we are going to put as base 6 LBC network LB.And you can see API version is V1, kind is service.So you are going to create a load balancer NLB, right?Using the Kubernetes service manifest, right?That's the reason before going to in metadatawe have reviewed the name as basics LBC network LB,and we leave these annotationsand we'll go here further spec, right?So API version kind metadataand spec are the high level items.and API version is V1, and kind is service.And in metadata you have the name basics, LBC network LB,and in the spec you have the type as load balancer.So which means you are creating a load balancer serviceand selector isapp, app three NGINX.So any request coming to this serviceshould go to the pods which has the selector labelapp three Nginx.And if you go here, you have the same thing.In selector match labels of your deploymentyou'll find the app three Nginx.So which means any request coming to this servicewill go to that respective portsof that respective deployment.And this is the service port and this is the target port,right?So here only you have defined your listener pod.We don't need to define anything in the annotations here.So whatever you define the port herethat respective listener will be created.So let's go back and understand this.So you can see here the listener 80, right?So it is created because you have the port 80.So if you define here something, right?So some 443, right?And target port is 80 is your backend port.But whenever you define the portyour listener will get created in the network load balancer.And whenever you define the target portit'll create new target groups.So just understand.So whenever you define target port, it creates target groupinNLB.And whenever you define portit creates new listenerin NLB.So this is, in the next demowhenever we deal with SSL you'll clearly understand,but it's a high level thing just to seewhat it is going to create.So port is 80 and target port our backend port is 80,our pod is listening on port 80,the container inside the pod.So that is good.So now let's come back and review these annotations.So you have the traffic routing, health checkpart settings, access control, and then resource stacks.So all these things we have took from herein our AWS load balancer controller,and in the guideand in service you'll find something called annotations,right?So here you'll find all the related annotationsrelated toNLB.So now let's come back hereand start discussing about that traffic routingrelated annotations.So the first thing is you have provided the namefor your load balancer name.So standard as our Ingres load balancer name.So which is basics LBC network LB is by load balancer namewith which it creates in my AWS Management Consoleyou can see this.And this name is your, whenever you type QCTyou'll get SVC the name of your service Kubernetes object.So that one is this one.So now this load balancer type we have discussed extensivelyin our introduction.So we are going to give externalbecause this service need to be associatedwith our LBC, load balancer controller latest, right?And this is the AWS load balancer NLB target type.So you're going to use the instance.So whenever you use the instance, right.Specifies the target type to configure your NLB.You can choose either instance or IP.So we are using the instancewhich meansworker related nodes.NodePorts will be registered as the targets here.Worker nodes will be registered as targets herewith the NodePorts.Okay.And now, another important annotation hereis AWS load balancer subnets.So if you don't define thisit is going to automatically take it.But if you are in need of specifying specific subnets,so this is called AWS load balancer subnetsis a custom subnet discovery.So you can provide your subnet ideas hereand accordingly in those subnets only this NLBwill be created.And now, so we don't need to go to that specific levelbecause we don't have any requirement that way.So it'll automatically go and then createin the available subnets for us in the public subnet, right?So now another important thing hereis health check settings.So from health check settings perspectiveso you can define your protocol history TP TCPR,history TPS.So my backend is listening on port 80which is a history TP.So I can directly use TCP hereand don't need to put all this path and all those things.But my backend I should have a proper health check thing.So that's the reason I have used history TP traffic portand in my backend in the root context/index.htmlwill be my context health check path for me.And these thresholds I have defined, defaults.That's the thing.And if you see here from access control perspective,so this load balancer source rangeswill tell us specifies the CIDRthat are allowed to access the network load balancer.So I have put it.Because I'm creating a internet facing load balancer,I have put the entire internet rangeso that anyone can access my network load balancer.And another thing is AWS load balancer scheme.So this is the annotationwhich decides whether your load balanceris a internal load balancerwhich creates in the private subnets of your VPC,or internet facing load balancer,which creates in a public subnet of your VPC,and they can be accessible via internet.So we are creating first the internet facing one.So we use this as internet facing.And these are the standard resource tagsyou can define.So AWS load balancer additional resource tagfor your network load balancer.So this completes the review of your annotationsand your Kubernetes service manifest.So in our next lecture we are going to deploythese things and test it.So I'll see you in the next lecture.Until then, bye-bye. Thank you.
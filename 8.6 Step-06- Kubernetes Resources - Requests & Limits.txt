# 8.6 Step-06- Kubernetes Resources - Requests & Limits

Lecturer: Welcome back.In this lecture,we are going to implement requests sending limits,which is nothing but resources for our containerinside the port, right?So, if you see here on a very high-level,we can specify how much each container in a portneeds the resources like CPU and then memory.When we provide this information in our port,the scheduler uses this informationto decide which note to place this port on.In simple terms, so once we provide this information,so scheduler will find outon which node I have the equivalent resourceswhatever provided is available,and based on that, it'll go ahead and then schedule it.So when you specify a resource limit for a container,the Kubelet enforces those limitsso that the running container is not allowed to usemore than the resource, the limit we have set.In addition to that, the Kubelet also results at leastthe requested amount of that system resourcespecifically for that container use.So these two are very important.So if we have some critical container,we are going to run on Kuberneteswhich should always have that set of CPU and then memory.So, using these resources like requests and then limitfor your respective containerwhich is so critical application,so you can reserve the memory and CPU what it needs.In addition to that, in high traffic conditionsit might increase to 500 (indistinct) memoryand then 100,000 EMA of CPU,so then automatically you can even provide that limits.But it should not cross more than this,so like that you can even provide these things.So 1000m is equal to one VCPU core, okay?So we have provided 0.5 CPU, which is nothingbut 500 M in the same way memory also 128 MI we have givenwhich is nothing but maybe bytes.Okay?So 128 maybe byte is equal to 135 megabytes.Usually we'll say 1 0 2 4 nbr 100 nbrfire nbr, right?So in the same way you can define here maybe bytes, okay?So I have provided 128 maybe bytesof memory for my application and CPU I have provided 500 Mwhich is nothing, but that means milli CPU.And I also provided the limit that pharmamy user management microservice applicationI should not give more than 500 MIoff memory and one core CPU one v CPU.So now if you see we are using two T3 missions here, right?So if you go ahead and then provide the limitUS five CPU means like 5,000 M, right?So based on our limit onlyit'll go ahead and then schedule, right?So our 8,000 CPU.So, and if my reso, if my respectto two P three missions doesn't have thatthen automatically the port will go under pending state.Okay? So it'll not come and then create it.So that's the reason always whenever we arevaluing our resources requestswith the memory CPU limits and then requests.So we need to ensurethat what is my cluster size and then all those things.But the other hand here is whenever we goto the auto scaling concepts, right?So horizontal part or vertical part or cluster autoscaleswhenever you enable those things.So these things really doesn't matterwhich means once you define these thingsfor your specific things which are criticaland already you enable the auto scaling stuff there.So whenever things reaches the limits automaticallythe cluster will auto scalewith notes and in addition to thatit'll also scale whatever the resources it is required.So based on that, usually it'll not have an issue.But if you are using small clustersand then if you have trouble right in defining those thingsso then obviously you need to be very carefulabout what you are definingand then how much your application is going to consume.So with that set we can go aheadand then define these things in our application, right?So which is nothing but resources, requests, memory, CPUand then limits memory CPU, okay?So this is part of our container definition.So which is nothing but which should be under environmentsame level, which is liveness probes, readiness probes.And it should be here also at the same level, okay?So which is nothing but resources.And under that we'll have two things.One is request and the other is limits.Okay? Under request we are going to have CPUand memory, right?And under limits also we are going to have CPUand memory and you can copyand paste whatever is there available here, right?So memory is going to be 128 MI, right?And CPU is 500 M, okay?So in the same way here also the CPU is goingto be 100 M, right?And this one is going to be 500 MI, okayso for this demo I'm going to put thisand then later I'm going to remove this resource requestin the next lectures means likein all the templates I'm going to remove these things.Why? Because I really don't want to block my clusterrelated resources for 500 meanslike half CPU and then 128 MIfor this respective user management microservice only.So if it want to takehow much it want to take, it can take it.But if I want to scale this right means likeif I scale to 10 and then automatically my clusterwhatever these two P three medium servers might gointo pending state.So that's the reason I'm going to remove.And the next templates, whatever you seein the next sections of here, whatever you seethese might not be there but you really don't need to worry.We learned it in this sectionand then after that we removed it.Okay? So let's have it that way.Okay, so let me save it, right?So we have savor this one and now what we are goingto do here is we'll go backto our create gate objects and then test it.So let's go back to our terminal.So I am in zero, we'll go to zero five sectionand then 0 5, 0 4 section we need to gowhich is request and then limits and I'll clearand Q CT apply high for F and then cube manifests.Okay? So and then everything should get createdand then ideally we should not have any issue.So why?Because our cluster has that level of capacity.So, and then we can watch the ports hereand it will take a while to get the containermy scale container gets created and thenfrom in container it need to goto liveness and then readiness probesall those things will take, right?So until it is ready, I'll pause the video.So our part is running now user management part.So let me come back out of thisand then I can secure parts and then all our running.So we can go to browser and then verify.And our application is up and running.So one thing we can check here is kubectland then get notes and then let's see our node, right?So kubectl and then describe one of the noderight to understand what we havehow the resources are distributed for that node, right?So I just need to provide that describe node here.So let me do that, right?Okay. So if you see here, so for my scalewe didn't define any CPU requests are CPU limits, okay?For cube system, AWS node already it is definedwhich is system related stuff, okay?Or for cube system cube proxy also 100MF CPU is reserved for them.Okay? In the same way, let's see ourin our default name space we have somethingcalled user management microservice.Okay? So let me make this smaller and then see what happens.Okay?So I just reduce the font to understand little bit clear.So you can see in the default name space wehave user management microservice.So we have requested 500 M meanslike my request is 500 M and my limit is one.So what is this?25%? And then what is this?51% is from this node of 25% of this node.I am, I have already requestedand then I'm going to, that is resortfor this respective too user management microservice, okay?And it's limitedI'm going to use one CPU, which is nothing.But if you see here for that T3 medium, so if you come hereright? No, not this one.Okay? Yeah.So if you come here for the T3 mediumso you have something called two V CPUand then four gbf memory.So out of two V C P, one V C P, you have already resortfor this user management microservice.What it states for us is already you are using 51%of the CPU from this respective note.So that's what it is trying to tell us.In the same way128 MI I am using as a request, which is nothingbut three percent is already resolvedfrom the entire four gb.And in addition to that 500 MIwhich is 14% is result for this limit.Okay, So how much is the limit here?It is 4G ib, out of which this much it is resort.It is saying in the same way, if you see herethis is the overall for this node.In the same way for the other node also we'll have, rightSo in that line, so whenever we are defining the requestsand then limits for our respective containerswe need to ensure that proper planning is required and thenif my cluster will sustain in high load conditions or not.And considering the cluster level resourceswhat it consumes, like whatever the cube systemor whatever is present in the cube systemlike in future you might install external DNSor L being risk controller.A lot of other things will comeinto the picture which are system related.So for all those things, considering we need to ensurethat how much this cluster can allocateand then accordingly we need to decide.So this completes the understanding of resourcesand requests and then we have also implemented it.So let's go ahead and then delete them now.So let me paste it and then delete it.And let's also go back for our previous font.Okay? So in our next lecture we'll focus on name spaces.So I'll see you in the next lecture and then bye bye.Thank you.
# 4.20 Step-17- Kubernetes Services - Demo

-: Welcome back.In this lecture we are going to do theKubernetes services demo.So let's see what we are going to implement as part of that.So in a Kubernetes clusterwe are going to do a backend deployment.So we have a simple springboot REST serviceshello world service.So we are going to deploy it.As soon as we create the deployment,automatically it's equivalent replica setand then pod gets created.So once that is donewe are going to createthe backend app related cluster IP servicesusing kubectl expose.So once we do that,so we'll go ahead and then create the frontend deployment.So in frontend we are going to create a Nginx podand in that Nginx podwe'll have a proxy to this respectivecluster IP service of backendwhich is nothing but my backend service.Now for the users to access our applicationwe'll also deploy the frontend app NodePort serviceso that users will be able to access it.So let's go to our GitHub repoand we'll go to our 05 services with kubectl, right?So introductory sectionwe already discussed in our previous lecture.So let's go onto our step twowhich is cluster IP service backend application setup.So let's deploy a simple backend applicationand then front it with a cluster IP.So the application we are going to use isa simple springboot REST application.Just a hello world, REST application.So what we need to do, if you want to deploy a applicationwe just need to create a deploymentand then front it with a service.So, kubectl create deployment,my backend REST app and the image of that, right?So let me copy this, go to my terminal and then paste it.So it should create our respective application, right?So we can say pods, to see our pod is running.Yes. And if you wantyou can even say, logs -f, okay, kubectl logs -f,and then check the logs of our springboot application.It should be up running now.Started your hello world application in three secondson port 8080.Okay, So if you see here also we have exposedmeans like we are going to expose as a servicewith the port 8080, right?And the target port is also 8080.So we really don't need to mention target port 8080but for our convenience means likefollowing a standard, so I just put it.In addition to thatyou really don't need to provide when you are doing,when you're creating a service using kubectlimperative command expose, right?So you really don't need to providetype is equal to cluster IP here.Reason is cluster IP services by default created bymeans like its a default service, okay?So we really don't need to specify thatif it is a type is equal to NodePort,yes we need to specify,but for cluster IP, we really don't need to specify it.So kubectl, expose deployment, my backend REST app,port, target port, and my service name, my backend service,the service name is my backend service. Okay?So now everything is created, kubectl get svc.So my backend stuff is completed now.So now I need to create a frontend Nginx reverse proxyand then that Nginx proxy should proxy to thismy backend service.So for that purpose I prebuilt the containerand then put it here.So if you go to our NodePort serviceso in my Nginx conf,I have put in the proxy pass,my backend service:8080 as the port,whatever we are seeing, right?My backend service and then port is 8080, right?So if it is not in default namespaceand then some other namespaces or somethingagain we need to give the full cluster DNS namewhich is svc.default.svc.local,all those stuff we need to give.But as we are running in that default namespace only, okay?kubectl get ns, right?We'll list the namespaces.This is a different concept, which we look into it laterbut currently we are in the default namespace.We really don't need to provideany full cluster DNS host name here.So that's the reason to make it very simple for youand not to confuse too much.So I just gave whatever is my cluster IP service name herethe same thing I have provided, right?And then I have pre-built the image and then put it ready.So in our docker hub,so we can directly use it and then run these commandsand then everything should work for you. Okay?So and no, no, noI want to create my own reverse proxy related docker image.Okay? Yes, you can do it.So I have provided the steps and the source herekube frontend Nginx.If you click on that, so you'll, it'll take you to00 docker images, 03 kube frontend Nginx. Okay?So prerequisite is you should have your docker accountand then you can create your docker file like this.Everything is present in this v1 release, the docker fileand which is nothing butfrom Nginx you're taking your source image as Nginxand you're copying the default.conf,whatever is there in the current directoryto etc Nginx.conf.d right?So if you're seeing one releaseyou'll see that default.conf also hereinside that you can see proxy passbackend cluster IP service name and then port.That's what you have put it here, okay?So the same thing and you can go hereand then review these things and then after that you canyou can go into this v1 release folder, right?Cd2 v1 release and from there you can build adocker build -d and your docker hub idand the kube frontend Nginx column 1.0.0and take the files from the current directory dot okay?And then push that to your dock hub idand then you can start using it if you want. Okay?So but for for me, like you can leverage thisthis current whatever the docker imageand then you can continue,but it's up to you.Just I have given why? Because it is Nginx, right?So I didn't give any steps forrelated to springboot related application.Why? Because again, it might confuse youand then create complex stuff.But here for Nginx it's a simple thing, right?So you can try out your docker skills therewith those stepsand then come back and then leverage that hereso that you'll be more confident.So for that purposeI gave the detailed steps for kube frontend Nginx building.Okay? So now lot of things we discuss it.So let's go ahead and then create the frontend deploymentand then create the frontend expose that as a service, okay?kubectl create deploymentmy frontend Nginx app is my deployment nameand the image is kube -frontend Nginx. Okay?So let's take this and we are here, okay?Created, right?And now let's go ahead and then expose it, right?(keys clanging)So clear, kubectl get pods,both pods should be running now and get svc.We should have two services related to backend serviceand then frontend service with NodePortand then NodePort ID.So if you want to access your applicationso you can say get nodes and -o wide, right?And take the public IP hereand 32209 is our port.So let's go to the browserand say, okay,and /hello, right?
(keys clanging)Sorry. So the IP:32209 is my portand then /hello is the context, right?So, so we got the response, so let me make it bigger.And if you see it here, 32209 is our node pod portand then /hello.So that is the thing.So the same thing, we have done it 32209and the context is /hello. Good.So now what we are going to do isso we are going to scale our backend applicationsso that how the load balancing happens.And then you can even see different values here.Where is this?Here, right?So this container id, right?So this is going to change continuously.So whenever you refresh the browserso let's test thatfor our convenience, okay?So, kubectl scale --replicas is equal to 10and my backend application, okay?So I'm scaling my backend application.So let's go here and then scale it.So now, kubectl get pods, my backend should be10 backends, I should have, right?So it's coming up.So let's, okay, so all are up and running.So now let's go ahead and then test that now, okay?So where is this?Here, right?So I'll keep saying refresh, right? Right.Okay, so we can refresh it, something, okay.See, you can see this is changing continuously,(keys clanging)H60MV now.
(keys clanging)So it's load balancing across all the backends, right?9gvfm, wnzz.So like this, you are seeing all the containers are up nowand then healthy, we are not even seeing that error. Okay?So, vfmwg, okay?So you can see how it is going on.So that, that's about it.So we have completed our services demo successfullyand one thing here iswe really didn't look into load balancerand then external concepts here.So these things we will look intoas part of our series of courseswhatever we are doing for AWS, Azure and then Google Cloud.So in those things we will extensively look into this stuff.So I'll see you in the next lecture.Until then, bye bye. Thank you.
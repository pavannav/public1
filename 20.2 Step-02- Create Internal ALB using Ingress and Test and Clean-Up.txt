# 20.2 Step-02- Create Internal ALB using Ingress and Test and Clean-Up

-: Welcome back.Let's go to our Github repositoryand we are in 0-8 new LB application load balancersand we are entering intothe section 0-8-14 Ingress internal LB.And inside that you'll find two folders.One is Kube manifest and Kube manifest curl,which is nothing but we are going to deploy the curl podand curl pod related Kube manifest.We have put it separate.So as part of introductory sectionwe already understood about we are going to createa internal application load balancerusing Kubernetes English manifestand also test it with the curl pod.So we'll go to our visual studio codeand review the Kubernetes manifest.So let's go back to our visual studio code hereand we are in 0-8-14 Ingress internal LB.And if you see the Kube manifest so 0-1, 0-2, 0-3,you will have the app 1, app 2, app 3 deploymentand NodePort services.And 0-4 you'll have the LB Ingress internal LB.So the name of the Ingress resourceis going to be ingress internal LB demo.And name of the load balanceris going to be Ingress internal LB.And if you see here we don't have any other things.This is a plain context, part based routing usecase which we have taken from that demo.So there is no SSL and there is nothing else.So we have added the create internal applicationload balancer.So we committed the internet facing schemeand then we have added internal.And these are health check settings.That's all, right?So there is nothing else.Very simple load balancer nameand the schema internal and health check settingsand then English class nameand as usual the default backendfor app 3 Nginx Nodeport service.And for app 1, it is going to be slash app 1 related rulesand for slash app 2, slash app 2 related rules.So now let's also review the curl pod ones, right?So in the curl pod this is just,it is going to directly create a podfor a CAPA version of kind podand it is going to create a curl pod for us.So it'll download the curl pod and run it.So now let's come back hereand go back to our GitHub repositoryand go ahead and then deploy the Kube manifests.So we'll say here 0-8 N 14 Ingress internal load balancer.So we already discussed about this.So whenever you have the scheme as internal,it is going to create the internal load balancer for us.So I'll say Kube CTL, apply hyphen F and Kube manifest.So this should createthe app 1 app 2 app 3 application deploymentsand also the 3 NodePort services.In addition to that it should create a Ingress servicewith the internal load balancer.So if I say Kube CTL get ports,Nginx ports 1,2,3 should be displayed here.And we'll also say Kube CTL get SVCand Nginx related app 1, app 2, app 3related NodePort services should be displayed.And now we will run the command Cube CTL get Ingress.And you should see the Ingress servicecreated with internal.So this is our ingress internal LB is the name.But also Ingress ensurethat it also appended with internal hyphen.So if you come back hereand verify your load balancer name is Ingress internal LB.So only til here, right?But it also opened it with internal hyphento tell us that it is creating a internal load balancerfor us for the address, right?So in this one as usual the name became sameIngress internal LB demo.So this is the one, right?So that is good.So now let's come back here, right?And verify the listeners and ports and all those things.So let's go to load balances here.Ingress internal LB is getting createdand if you see on port 80,there is no 4-4-3 related annotations hereor any 4-4-3 related SSL annotationsand all those things for remote.It is a plain simple load balancer with port 80.And port 80 is a default setting.You really don't need to specify the listen ports for that.So now let's come back hereand go to this view our edit rules for port 80.And you can see slash app 1 should go to app 1 target groupapp 2 should go to app 2 target groupand default should go to app 3 target group.And also if you see herethis is the load balancer DNS name.So let's copy and do a, and let's look up for that, right?So it should have a internal name, right?So 190 to 168, 110 dot 94, 190 to 168, 77 dot 250.So this is from internal cluster,internal related subnet space,but not the external internet edge subnet space for us.So which means this one we cannot access it.So if I say curl, so it is not accessiblefor us from the internet.So that's about it.So now let's come back hereand if we want we can also verify our target groups, also.There is no change in NodePort service or deployments.So obviously those are going to be same,which means it'll have them,if you take the app 1 Nginx related target group.So two nodes were registered herewith those respective NodePortsand those are healthy, right?Why? Because we have used the NodePort service here, right?So the instance typeor the target type is NodePort by default.So automatically all the worker nodes registered here.So now let's come back hereand go to the curl pod to do the testing, right?So we have reviewed this.We'll go back here and then deploy the curl pod.So let's come back hereand Kube CTL apply hyphen F Kube manifest curl.So this should create the curl pod for us.So it has created, if I say Kube CTL get pods,curl pod should be running for us.See curl pod is running.So now we will connect to this curl pod, right?Kube CTL exit hyphen D curl pod,pod name and hyphen hyphen SH.And if you see here,this is we are inside the curl pod now.You see the terminal here, right?So we are in the curl pod. Or I'll exit.And first I'll clear this, right?And clear.And we'll come from the top.Let's wait for it and we'll connect to the curl pod now.And if I say host name, we are in the curl pod, right?So now let's come back hereand if you want you can say curl.And our outbound is open from our EKS clustervia NAT gateway for the private subnet.So which means if I say google dot com alsoit should be allowed for us, see?3-0-1 more. It is accessible for us.So now we will use the, this one to access our application.So this is our DNS name of my internal pod,internal load balancer. So I'll say curl.And this should get me that default pagewhich is Kubernetes fundamentals demowhich is the root context are the app 3 Nginx, right?So now if I say slash app 1 slash index dot htmlso it should give me the app 1, right?See where application name, app 1.It has been successful.And we'll also test the app 2 related thingwith the same curl command.So you can see app 2 is successful.So you have successfully created the internal load balancerand you have deployed a curl pod in the EKS clusterand from that EKS clusterbecause this internal load balanceris from the internal networks of EKS cluster.So obviously you are able to access thatand do the curl from this respective curl pod.So this is also successful for us.So now let's go back here and then clean up the stuff.So for cleaning up, we'll say Kube CTLdelete hyphen F Kube manifestand also delete hyphen F curl pod.So all our app 1, app 2, app 3and then Ingress related Kubernetes objects were deleted.So we'll also delete the Kube CTLand delete and hyphen Fand Kube manifests hyphen curl.So that whatever the curl pod we have deployedalso will be removed.So this completes the Ingress internal load balancer demo.I'll see you in the next lecture.Until then, bye bye.Thank you.